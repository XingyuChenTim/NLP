{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Inference With BERT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For this homework, we will work on (NLI)[https://nlp.stanford.edu/projects/snli/].\n",
    "\n",
    "The task is, give two sentences: a premise and a hypothesis, to classify the relation between them. We have three classes to describe this relationship.\n",
    "\n",
    "1. Entailment: the hypothesis follows from the fact that the premise is true\n",
    "2. Contradiction: the hypothesis contradicts the fact that the premise is true\n",
    "3. Neutral: There is not relationship between premise and hypothesis\n",
    "\n",
    "See below for examples\n",
    "\n",
    "![snli_task](media/snli_task.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's load the Stanford NLI dataset from the huggingface datasets hub using the datasets package\n",
    "\n",
    "### Explore the dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Imports for most of the notebook\n",
    "import torch\n",
    "from transformers import BertModel\n",
    "from transformers import AutoTokenizer\n",
    "from typing import Dict, List\n",
    "from util import get_snli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset snli (/Users/xingyuchen/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3583a14987d84af1932ed141a2e303fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split sizes (num_samples, num_labels):\n",
      " {'test': (10000, 3), 'train': (550152, 3), 'validation': (10000, 3)}\n",
      "\n",
      "Example:\n",
      " {'premise': 'A person on a horse jumps over a broken down airplane.', 'hypothesis': 'A person is training his horse for a competition.', 'label': 1}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"snli\")\n",
    "print(\"Split sizes (num_samples, num_labels):\\n\", dataset.shape)\n",
    "print(\"\\nExample:\\n\", dataset['train'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each example is a dictionary with the keys: (premise, hypothesis, label). \n",
    "\n",
    "#### Data Fields\n",
    " - premise: a string used to determine the truthfulness of the hypothesis\n",
    " - hypothesis: a string that may be true, false, or whose truth conditions may not be knowable when compared to the premise\n",
    " - label: an integer whose value may be either 0, indicating that the hypothesis entails the premise, 1, indicating that the premise and hypothesis neither entail nor contradict each other, or 2, indicating that the hypothesis contradicts the premise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset snli (/Users/xingyuchen/.cache/huggingface/datasets/snli/plain_text/1.0.0/1f60b67533b65ae0275561ff7828aad5ee4282d0e6f844fd148d05d3c6ea251b)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb143f4a185a47baa9fefb2efec2c15d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading Datapoints: 100%|██████████| 550152/550152 [00:16<00:00, 32839.24it/s]\n",
      "Reading Datapoints: 100%|██████████| 10000/10000 [00:00<00:00, 32119.83it/s]\n",
      "Reading Datapoints: 100%|██████████| 10000/10000 [00:00<00:00, 33953.32it/s]\n"
     ]
    }
   ],
   "source": [
    "from util import get_snli\n",
    "\n",
    "train_dataset, validation_dataset, test_dataset = get_snli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9999 999 999\n",
      "Counter({0: 3333, 1: 3333, 2: 3333})\n",
      "Counter({0: 333, 1: 333, 2: 333})\n",
      "Counter({0: 333, 1: 333, 2: 333})\n"
     ]
    }
   ],
   "source": [
    "## sub set stats\n",
    "from collections import Counter\n",
    "\n",
    "# num sample stats\n",
    "print(len(train_dataset), len(validation_dataset), len(test_dataset))\n",
    "\n",
    "# label distribution\n",
    "print(Counter([t['label'] for t in train_dataset]))\n",
    "print(Counter([t['label'] for t in validation_dataset]))\n",
    "print(Counter([t['label'] for t in test_dataset]))\n",
    "\n",
    "# We have a perfectly balanced dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We want a function to load samples from the huggingface dataset so that they can be batched and encoded for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's reimplement our tokenizer using the huggingface tokenizer.\n",
    "\n",
    "### Notice that our __call__ method (the one called when we call an instance of our class) takes both a premise batch and a hypothesis batch.\n",
    "### The HuggingFace BERT tokenizer knows to join these with the special sentence seperator token between them. We let HuggingFace do most of the work here for making batches of tokenized and encoded sentences. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': tensor([[  101,  2023,  2003,  1996, 18458,  1012,   102,  2023,  2003,  1996,\n",
      "         10744,   102,     0],\n",
      "        [  101,  2023,  2003,  2036,  1037, 18458,   102,  2023,  2003,  1037,\n",
      "          2117, 10744,   102]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-03 20:53:36.428210: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['[CLS] this is the premise. [SEP] this is the hypothesis [SEP] [PAD]',\n",
       " '[CLS] this is also a premise [SEP] this is a second hypothesis [SEP]']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nothing to do for this class!\n",
    "\n",
    "class BatchTokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the tokenizer\n",
    "\n",
    "        Args:\n",
    "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<P>\".\n",
    "        \"\"\"\n",
    "        self.hf_tokenizer = AutoTokenizer.from_pretrained(\"prajjwal1/bert-small\")\n",
    "    \n",
    "    def get_sep_token(self,):\n",
    "        return self.hf_tokenizer.sep_token\n",
    "    \n",
    "    def __call__(self, prem_batch: List[str], hyp_batch: List[str]) -> List[List[str]]:\n",
    "        \"\"\"Uses the huggingface tokenizer to tokenize and pad a batch.\n",
    "\n",
    "        We return a dictionary of tensors per the huggingface model specification.\n",
    "\n",
    "        Args:\n",
    "            batch (List[str]): A List of sentence strings\n",
    "\n",
    "        Returns:\n",
    "            Dict: The dictionary of token specifications provided by HuggingFace\n",
    "        \"\"\"\n",
    "        # The HF tokenizer will PAD for us, and additionally combine \n",
    "        # The two sentences deimited by the [SEP] token.\n",
    "        enc = self.hf_tokenizer(\n",
    "            prem_batch,\n",
    "            hyp_batch,\n",
    "            padding=True,\n",
    "            return_token_type_ids=False,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "        return enc\n",
    "    \n",
    "\n",
    "# HERE IS AN EXAMPLE OF HOW TO USE THE BATCH TOKENIZER\n",
    "tokenizer = BatchTokenizer()\n",
    "x = tokenizer(*[[\"this is the premise.\", \"This is also a premise\"], [\"this is the hypothesis\", \"This is a second hypothesis\"]])\n",
    "print(x)\n",
    "tokenizer.hf_tokenizer.batch_decode(x[\"input_ids\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can batch the train, validation, and test data, and then run it through the tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_pairwise_input(dataset: List[Dict]) -> (List[str], List[str], List[int]):\n",
    "    \"\"\"\n",
    "    TODO: group all premises and corresponding hypotheses and labels of the datapoints\n",
    "    a datapoint as seen earlier is a dict of premis, hypothesis and label\n",
    "    \"\"\"\n",
    "    premises = []\n",
    "    hypothesis = []\n",
    "    label = []\n",
    "    for row in dataset:\n",
    "        x, y, z = row.values()\n",
    "        premises.append(x)\n",
    "        hypothesis.append(y)\n",
    "        label.append(z)\n",
    "    return premises, hypothesis, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_premises, train_hypotheses, train_labels = generate_pairwise_input(train_dataset)\n",
    "validation_premises, validation_hypotheses, validation_labels = generate_pairwise_input(validation_dataset)\n",
    "test_premises, test_hypotheses, test_labels = generate_pairwise_input(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(lst, n):\n",
    "    \"\"\"Yield successive n-sized chunks from lst.\"\"\"\n",
    "    for i in range(0, len(lst), n):\n",
    "        yield lst[i:i + n]\n",
    "\n",
    "def chunk_multi(lst1, lst2, n):\n",
    "    for i in range(0, len(lst1), n):\n",
    "        yield lst1[i: i + n], lst2[i: i + n]\n",
    "        \n",
    "# Notice that since we use huggingface, we tokenize and\n",
    "# encode in all at once!\n",
    "tokenizer = BatchTokenizer()\n",
    "batch_size = 4\n",
    "train_input_batches = [b for b in chunk_multi(train_premises, train_hypotheses, batch_size)]\n",
    "# Tokenize + encode\n",
    "train_input_batches = [tokenizer(*batch) for batch in train_input_batches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's batch the labels, ensuring we get them in the same order as the inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_labels(labels: List[int]) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): List of all labels in the batch\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    return torch.LongTensor([int(l) for l in labels])\n",
    "\n",
    "\n",
    "train_label_batches = [b for b in chunk(train_labels, batch_size)]\n",
    "train_label_batches = [encode_labels(batch) for batch in train_label_batches]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we implement the model. Notice the TODO and the optional TODO (read why you may want to do this one.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NLIClassifier(torch.nn.Module):\n",
    "    def __init__(self, output_size: int, hidden_size: int):\n",
    "        super().__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # Initialize BERT, which we use instead of a single embedding layer.\n",
    "        self.bert = BertModel.from_pretrained(\"prajjwal1/bert-small\")\n",
    "        # TODO [OPTIONAL]: Updating all BERT parameters can be slow and memory intensive. \n",
    "        # Freeze them if training is too slow. Notice that the learning\n",
    "        # rate should probably be smaller in this case.\n",
    "        \n",
    "        # Uncommenting out the below 2 lines means only our classification layer will be updated.\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        self.bert_hidden_dimension = self.bert.config.hidden_size\n",
    "        # TODO: Add an extra hidden layer in the classifier, projecting\n",
    "        #      from the BERT hidden dimension to hidden size.\n",
    "        self.hidden_layer = torch.nn.Linear(self.bert_hidden_dimension, self.hidden_size)\n",
    "        # TODO: Add a relu nonlinearity to be used in the forward method\n",
    "        #      https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        \n",
    "        self.classifier = torch.nn.Linear(self.hidden_size, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "\n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: Dict\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the contextualized embedding for each input symbol\n",
    "        # We no longer need an LSTM, since BERT encodes context and \n",
    "        # gives us a single vector describing the sequence in the form of the [CLS] token.\n",
    "        encoded_sequence = self.bert(**symbols)\n",
    "        # TODO: Get the [CLS] token using the `pooler_output` from \n",
    "        #      The BertModel output. See here: https://huggingface.co/docs/transformers/model_doc/bert#transformers.BertModel\n",
    "        #      and check the returns for the forward method.\n",
    "        # We want to return a tensor of the form batch_size x 1 x bert_hidden_dimension\n",
    "        last_hidden = encoded_sequence.pooler_output[:, None, :]\n",
    "        return last_hidden\n",
    "        \n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: Dict,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"_summary_\n",
    "\n",
    "        Args:\n",
    "            symbols (Dict): The Dict of token specifications provided by the HuggingFace tokenizer\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: _description_\n",
    "        \"\"\"\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        output = self.hidden_layer(encoded_sents)\n",
    "        output = self.relu(output)\n",
    "        output = self.classifier(output)\n",
    "        return self.log_softmax(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For making predictions at test time\n",
    "def predict(model: torch.nn.Module, sents: torch.Tensor) -> List:\n",
    "    logits = model(sents)\n",
    "    return list(torch.argmax(logits, axis=2).squeeze().numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation metrics: Macro F1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import logical_and, sum as t_sum\n",
    "import numpy as np\n",
    "\n",
    "def precision(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Precision is True Positives / All Positives Predictions\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(pred_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def recall(predicted_labels, true_labels, which_label=1):\n",
    "    \"\"\"\n",
    "    Recall is True Positives / All Positive Labels\n",
    "    \"\"\"\n",
    "    pred_which = np.array([pred == which_label for pred in predicted_labels])\n",
    "    true_which = np.array([lab == which_label for lab in true_labels])\n",
    "    denominator = t_sum(true_which)\n",
    "    if denominator:\n",
    "        return t_sum(logical_and(pred_which, true_which))/denominator\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def f1_score(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    which_label: int\n",
    "):\n",
    "    \"\"\"\n",
    "    F1 score is the harmonic mean of precision and recall\n",
    "    \"\"\"\n",
    "    P = precision(predicted_labels, true_labels, which_label=which_label)\n",
    "    R = recall(predicted_labels, true_labels, which_label=which_label)\n",
    "    if P and R:\n",
    "        return 2*P*R/(P+R)\n",
    "    else:\n",
    "        return 0.\n",
    "\n",
    "\n",
    "def macro_f1(\n",
    "    predicted_labels: List[int],\n",
    "    true_labels: List[int],\n",
    "    possible_labels: List[int]\n",
    "):\n",
    "    scores = [f1_score(predicted_labels, true_labels, l) for l in possible_labels]\n",
    "    # Macro, so we take the uniform avg.\n",
    "    return sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "import random\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_sents,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    loss_func = torch.nn.NLLLoss()\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features).squeeze(1)\n",
    "            loss = loss_func(preds, labels)\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        all_preds = []\n",
    "        all_labels = []\n",
    "        for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n",
    "            pred = predict(model, sents)\n",
    "            all_preds.extend(pred)\n",
    "            all_labels.extend(list(labels.numpy()))\n",
    "\n",
    "        dev_f1 = macro_f1(all_preds, all_labels, list(set(all_labels)))\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at prajjwal1/bert-small were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# You can increase epochs if need be\n",
    "epochs = 10\n",
    "# TODO: Find a good learning rate\n",
    "LR = 0.0005\n",
    "\n",
    "possible_labels = len(set(train_labels))\n",
    "model = NLIClassifier(output_size=possible_labels, hidden_size = 64)\n",
    "optimizer = torch.optim.AdamW(model.parameters(), LR)\n",
    "\n",
    "validation_input_batches = [b for b in chunk_multi(validation_premises, validation_hypotheses, batch_size)]\n",
    "# Tokenize + encode\n",
    "validation_input_batches = [tokenizer(*batch) for batch in validation_input_batches]\n",
    "validation_batch_labels = [b for b in chunk(validation_labels, batch_size)]\n",
    "validation_batch_labels = [encode_labels(batch) for batch in validation_batch_labels]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/yzh9j02x7bxd463cl1x0_2lh0000gn/T/ipykernel_21469/408791926.py:18: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for features, labels in tqdm(batches):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9df6a589cdb64f76be0bad3ad615c213",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 1.078682099223137\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/yzh9j02x7bxd463cl1x0_2lh0000gn/T/ipykernel_21469/408791926.py:33: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sents, labels in tqdm(zip(dev_sents, dev_labels), total=len(dev_sents)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11a1752433fc46c1b3f98bb3bfddae0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.3961114104765758\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f9fbc30a0794975af6f7ea3082fa254",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss: 1.0384947150826453\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4785cd74ec4456dafb7eb296efd3ebb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.43722834832583457\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d346f8bc5de04bd4b6199e5c92a5eeee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2, loss: 1.0189619132041932\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85cb0104349d427cb2ab053a5466c303",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.45177991732135503\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32f38fcf833b43b0b47799dc814451db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3, loss: 1.0068106312036513\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f975abb3f74386b45aa101bdca06e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4595075784196594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af3370b16e1f4312b1d75087c63a045d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4, loss: 0.9973996498465538\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f2f04c76e310456f89ff0925fab59454",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4715147180501213\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60eb02e68bef4e0e9e6c587d75983821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5, loss: 0.9899630133390427\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7c468ceeed421dbd0165dcbf118595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4829240022221357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a32fb01e4514c41ab6a2cfe2df7cec3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6, loss: 0.9836426736235618\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96da351f805a4e16b4007990d1278f22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.48121076978999605\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d917273c92694fde91bde32ff291baa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7, loss: 0.9784472920656204\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c989eee820f24c2ba45c1747a4d99ef8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.48489830961978936\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d38fff5e619d4291b8909cc04326c4d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8, loss: 0.9726479669570923\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0bdb8069c08d4305b3c67e160e270cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.48397059252223357\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc9a9a7ab6604ad9831f92f7bbfedd76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2500 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9, loss: 0.9676756937742234\n",
      "Evaluating dev...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f49fb1daa34a759fcaec92c02c6b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.4831066903376536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NLIClassifier(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 512, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 512)\n",
       "      (token_type_embeddings): Embedding(2, 512)\n",
       "      (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (key): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (value): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "              (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=512, out_features=2048, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=2048, out_features=512, bias=True)\n",
       "            (LayerNorm): LayerNorm((512,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (hidden_layer): Linear(in_features=512, out_features=64, bias=True)\n",
       "  (relu): ReLU()\n",
       "  (classifier): Linear(in_features=64, out_features=3, bias=True)\n",
       "  (log_softmax): LogSoftmax(dim=2)\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(\n",
    "    epochs,\n",
    "    train_input_batches,\n",
    "    train_label_batches,\n",
    "    validation_input_batches,\n",
    "    validation_batch_labels,\n",
    "    optimizer,\n",
    "    model, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/yzh9j02x7bxd463cl1x0_2lh0000gn/T/ipykernel_21469/2551025514.py:16: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for sents, labels in tqdm(zip(test_input_batches, test_batch_labels), total=len(test_input_batches)):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e92dc1153c4f12bd5fa6062e852a96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/250 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dev F1 0.45765762206965377\n"
     ]
    }
   ],
   "source": [
    "# TODO: Get a final macro F1 on the test set.\n",
    "# You should be able to mimic what we did with the validaiton set.\n",
    "\n",
    "# test_premises, test_hypotheses, test_labels\n",
    "\n",
    "\n",
    "test_input_batches = [b for b in chunk_multi(test_premises, test_hypotheses, batch_size)]\n",
    "# Tokenize + encode\n",
    "test_input_batches = [tokenizer(*batch) for batch in test_input_batches]\n",
    "test_batch_labels = [b for b in chunk(test_labels, batch_size)]\n",
    "test_batch_labels = [encode_labels(batch) for batch in test_batch_labels]\n",
    "\n",
    "\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "for sents, labels in tqdm(zip(test_input_batches, test_batch_labels), total=len(test_input_batches)):\n",
    "    pred = predict(model, sents)\n",
    "    all_preds.extend(pred)\n",
    "    all_labels.extend(list(labels.numpy()))\n",
    "\n",
    "dev_f1 = macro_f1(all_preds, all_labels, list(set(all_labels)))\n",
    "print(f\"Dev F1 {dev_f1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Written Assignment\n",
    "\n",
    "### 1. Describe the task and what capability is required to solve it.\n",
    "Given two sentences: a premise and a hypothesis, classify the relationship between them. Three relationship: Entailment, contradiction, neutral. The dataset has these three values for training. We use HuggingFace BERT tokenizer to tokenize and encode the sentences in batch. For NLI Classifier, we add layers to the model such as ReLU, Linear, LogSoftmax. For encode texrt we use pooler_output from the bertmodel output, which is the last layer hidden-state of the first token of the sequence (classification token) after further processing through the layers used for the auxiliary pretraining task. Then we just hyperparameter tuning for model to get relatively good f1-score. \n",
    "\n",
    "### 2. How does the method of encoding sequences of words in our model differ here, compared to the word embeddings in HW 4. What is different? Why benefit does this method have?\n",
    "\n",
    "The differences are: 1. we dont need LSTM to encode context and packed the seqence from the LSTM output. The BERT model already encode context and gives us a single vector describing the sequence in the form of the token. 2. We  need to preprocess the word embedding in HW4 to get a tensor that indexes the last non-PAD position in each tensor in the batch. However, in BERT we just reshape the dimension to the required output shape. \n",
    "The benefits are we dont need to preprocess the embeddings on our own method and no need to change the dimension of output from model just reshape them. Make the code clean and process quicker.\n",
    "\n",
    "\n",
    "### 3. Discuss your results. Did you do any hyperparameter tuning? Did the model solve the task?\n",
    "I did hyperparameter tuning for hidden_size and learning rate, the result is showed below, the model solve the task:\n",
    "\n",
    "epoch = 10  \n",
    "batch size = 8  \n",
    "hidden size = 128  \n",
    "\n",
    "|             | loss   | dev    | test   |\n",
    "|-------------|--------|--------|--------|\n",
    "| lr = 0.001  | **0.9846** | **0.5019** | 0.4429 |\n",
    "| lr = 0.002  | 1.0997 | 0.1666 | 0.1666 |\n",
    "| lr = 0.005  | 1.0469 | 0.4377 | 0.4612 |\n",
    "| lr = 0.01   | 1.1041 | 0.1666 | 0.1666 |\n",
    "| lr = 0.0001 | 0.9863 | 0.4141 | 0.3910 |\n",
    "| lr = 0.0005 | 0.9856 | 0.4998 | **0.4929** |\n",
    "\n",
    "epoch = 10  \n",
    "learning rate = 0.0005  \n",
    "hidden size = 128  \n",
    "\n",
    "|                 | loss   | dev    | test   |\n",
    "|-----------------|--------|--------|--------|\n",
    "| batch_size = 8  | 0.9856 | 0.4998 | 0.4929 |\n",
    "| batch_size = 16 | 1.0051 | 0.4897 | 0.4888 |\n",
    "| batch_size = 4  | **0.9756** | **0.5024** | **0.4958** |\n",
    "\n",
    "\n",
    "epoch = 10  \n",
    "learning rate = 0.0005  \n",
    "batch_size = 4  \n",
    "\n",
    "|                   | loss   | dev    | test   |\n",
    "|-------------------|--------|--------|--------|\n",
    "| hidden_size = 256 | **0.9554** | 0.4554 | 0.4408 |\n",
    "| hidden_size = 64  | 0.9676 | 0.4831 | 0.4576 |\n",
    "| hidden_size = 128 | 0.9756 | **0.5024** | **0.4958** |\n",
    "\n",
    "For the best result for now is: \n",
    "epoch = 10    \n",
    "learning rate = 0.0005    \n",
    "batch_size = 4   \n",
    "hidden_size = 128  \n",
    "\n",
    "| loss   | dev    | test   |\n",
    "|--------|--------|--------|\n",
    "| 0.9756 | 0.5024 | 0.4958 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
