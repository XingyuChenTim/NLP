{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e9710c0",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Linear Regression with Pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f6a87b3",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Linear Regression is the task of predicting the value of a variable (y) depending on another variable (x) by fitting a linear curve using a set of existing datapoints (X, Y). \n",
    "\n",
    "\n",
    "The goal is to come up with the equation $y = Wx + b$ that \"fits\" the datapoints (X, Y) the \"best\". $W, b$ are the parameters of this equation that we need to \"learn\"\n",
    "\n",
    "$x$ is also called input features and it can be of arbitrary dimension. Typically, the $y$ for an $x$ is a single value\n",
    "\n",
    "### Linear Least Squares (https://en.wikipedia.org/wiki/Linear_least_squares)\n",
    "\n",
    "![Linear Regression](https://upload.wikimedia.org/wikipedia/commons/b/b0/Linear_least_squares_example2.svg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f26acbd8",
   "metadata": {
    "pycharm": {
     "is_executing": true,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c27b305",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Create dummy data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588c9e8a",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the synthetic input as 20 datapoints with feature length = 1\n",
    "# this is so that we can visualize the datpoints easier\n",
    "\n",
    "X = np.array(list(range(0, 100, 5))).reshape((-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1023f448",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "input_shape = X.shape\n",
    "N = X.shape[0]\n",
    "m = X.shape[1]\n",
    "\n",
    "print(\"Shape of the input:\", input_shape)\n",
    "print(\"Number of samples (N):\", N)\n",
    "print(\"Feature length (m):\", m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2974bd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# create the synthetic set of labels by adding noise to a straight line\n",
    "\n",
    "def foo(x, m=2, c=10, mu=20, sigma=15):\n",
    "    num_x = np.array(x)\n",
    "    return m*num_x + c + np.random.normal(mu, sigma, num_x.shape)\n",
    "\n",
    "y = np.array([foo(x) for x in X])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f8eec",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(X, y)\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "202d46ae",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Fit a line to the data\n",
    "\n",
    "Now the goal is to \"fit\" the datapoints with a straight line that could be used to predict the \"y\" value of new samples. The way we achieve this task is by finding the line which minimizes the Mean Squared Error (MSE) loss for the datapoints\n",
    "\n",
    "Note that this has a closed form solution, which can be used when you have a small number of coefficients. Since we are working with potentially many coefficients, we optimize with gradient descent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ae6885d",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class LinearRegressor(torch.nn.Module):\n",
    "    def __init__(self, feature_len):\n",
    "        super(LinearRegressor, self).__init__()\n",
    "        # This will hold the parameters of the model: W (Weights) and b (bias or intercept)\n",
    "        self.linear = torch.nn.Linear(feature_len, 1)\n",
    "        self.linear.weight.data *= 0\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a78a6d3",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def train(X, y, learning_rate=0.01, batch_size=10, n_iters=10):\n",
    "    \"\"\"\n",
    "    Train a linear regressor using the provided X, y dataset.\n",
    "    The steps involved in training are as follows:\n",
    "        1. Instantiate a regressor model using the input's feature len\n",
    "        2. Instantiate an SGD optimizer for the parameters of the regressor using the learning_rate\n",
    "        3. Do training for n_iters number of times\n",
    "        4. Split dataset into batches of size `batch_size`\n",
    "        5. Refresh the gradients of the regressor\n",
    "        6. Run the forward function of regressor to get the prediction of the input batch\n",
    "        7. Calculate the MSE Loss\n",
    "        8. Run backpropogation to calculate the gradients\n",
    "        9. Update the parameters with the gradients\n",
    "    \"\"\"\n",
    "    input_shape = X.shape\n",
    "    N = X.shape[0]\n",
    "    m = X.shape[1]\n",
    "    \n",
    "    # 1. Instantiate a regressor model using the input's feature len\n",
    "    regressor = LinearRegressor(m)\n",
    "    \n",
    "    def plot_curves():\n",
    "        plt.scatter(X, y)\n",
    "        plt.plot(X, predict(regressor, X), color='red')\n",
    "    \n",
    "    plot_curves()\n",
    "    \n",
    "    # 2. Instantiate an SGD optimizer for the parameters of the regressor using the learning_rate\n",
    "    optimizer = torch.optim.SGD(regressor.parameters(), lr=learning_rate)\n",
    "    \n",
    "    # 3. Do this for n_iters number of times\n",
    "    for iter_ in range(n_iters):\n",
    "        iteration_loss = 0.\n",
    "        # 4. Split dataset into batches of size `batch_size`\n",
    "        for i in range(0, N, batch_size):\n",
    "            # PyTorch requires the input and output to be tensors\n",
    "            x_batch = torch.FloatTensor(X[i:i+batch_size])\n",
    "            y_batch = torch.FloatTensor(y[i:i+batch_size])\n",
    "            \n",
    "            # 5. Refresh the gradients of the regressor\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # 6. Run the forward function of regressor to get the prediction of the input batch\n",
    "            # Note: Don't use the predict funtion here as the predict function ignores gradients\n",
    "            y_pred = regressor(x_batch)\n",
    "            \n",
    "            # 7. Calculate the MSE Loss\n",
    "            loss = torch.mean((y_pred - y_batch)**2)\n",
    "            \n",
    "            # 8. Run backpropogation to calculate the gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 9. Update the Weights (W) with the gradients (Delta) as W = W + (lr * Delta)\n",
    "            optimizer.step()\n",
    "            \n",
    "            # store the accumulated loss for the iteration\n",
    "            iteration_loss += loss.detach().numpy()\n",
    "            \n",
    "        print(\"Epoch\", iter_, \"Loss:\", iteration_loss)\n",
    "        plot_curves()\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('y')\n",
    "    return regressor\n",
    "            \n",
    "def predict(regressor, x):\n",
    "    with torch.no_grad():  # don't need gradients during prediction\n",
    "        return regressor(torch.FloatTensor(x))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "113cdd41",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#trained_regressor = train(X, y, learning_rate=0.0001)\n",
    "trained_regressor = train(X, y, learning_rate=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e66ad060",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#  DON'T EDIT THIS!!\n",
    "\n",
    "def compare(x, regressor):\n",
    "#     print('true y:', foo(x))\n",
    "#     print('predicted y:', predict(regressor, x).detach().numpy())\n",
    "    return foo(x), predict(regressor, x).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42ea293",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We can use the trained regressor for predicing the \"y\" value for \"unseen\" X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "55ef89f2",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predictions: [[644.75104]\n",
      " [744.0788 ]]\n",
      "All Tests Ran Successfully!\n"
     ]
    }
   ],
   "source": [
    "#  DON'T EDIT THIS!!\n",
    "\n",
    "unseen_x = np.array([[260], [300]])\n",
    "true_y, pred_y = compare(unseen_x, trained_regressor)\n",
    "\n",
    "print(\"predictions:\", pred_y)\n",
    "\n",
    "assert pred_y[0] < 650 and pred_y[0] > 600\n",
    "assert pred_y[1] < 750 and pred_y[1] > 700\n",
    "\n",
    "print('All Tests Ran Successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0de2cd",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
