{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming Assignment (20 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you will solve an irony detection task: given a tweet, your job is to classify whether it is ironic or not.\n",
    "\n",
    "You will implement a new classifier that does not rely on feature engineering as in previous homeworks. Instead, you will use pretrained word embeddings downloaded from using the `irony.py` script as your input feature vectors. Then, you will encode your sequence of word embeddings with an (already implemented) LSTM and classify based on its final hidden state.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# This is so that you don't have to restart the kernel everytime you edit hmm.py\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "We will use the dataset from SemEval-2018: https://github.com/Cyvhee/SemEval2018-Task3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-01 17:42:32.367018: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from irony import load_datasets\n",
    "\n",
    "train_sentences, train_labels, test_sentences, test_labels, label2i = load_datasets()\n",
    "\n",
    "# TODO: Split train into train/dev"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline: Naive Bayes\n",
    "\n",
    "We have provided the solution for the Naive Bayes part from HW2 in [bayes.py](bayes.py)\n",
    "\n",
    "There are two implementations: NaiveBayesHW2 is what was expected from HW2. However, we will use a more effecient implementation of it that uses vector operations to calculate the probabilities. Please go through it if you would like to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Vectorizing Text: 100%|██████████| 3834/3834 [00:00<00:00, 9158.57it/s]\n",
      "Vectorizing Text: 100%|██████████| 3834/3834 [00:00<00:00, 10912.28it/s]\n",
      "Vectorizing Text: 100%|██████████| 784/784 [00:00<00:00, 13658.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline: Naive Bayes Classifier\n",
      "F1-score Ironic: 0.6402966625463535\n",
      "Avg F1-score: 0.6284487265300938\n"
     ]
    }
   ],
   "source": [
    "from irony import run_nb_baseline\n",
    "\n",
    "run_nb_baseline()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1: Implement avg_f1_score() in [util.py](util.py). Then re-run the above cell  (2 Points)\n",
    "\n",
    "So the micro F1-score for the test set of the Ironic Class using a Naive Bayes Classifier is **0.64**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression with Word2Vec  (Total: 18 Points)\n",
    "\n",
    "Unlike sentiment, Irony is very subjective, and there is no word list for ironic and non-ironic tweets. This makes hand-engineering features tedious, therefore, we will use word embeddings as input to the classifier, and make the model automatically extract features aka learn weights for the embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizer for Tweets\n",
    "\n",
    "\n",
    "Tweets are very different from normal document text. They have emojis, hashtags and bunch of other special character. Therefore, we need to create a suitable tokenizer for this kind of text.\n",
    "\n",
    "Additionally, as described in class, we also need to have a consistent input length of the text document in order for the neural networks built over it to work correctly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Create a Tokenizer with Padding (5 Points)\n",
    "\n",
    "Our Tokenizer class is meant for tokenizing and padding batches of inputs. This is done\n",
    "before we encode text sequences as torch Tensors.\n",
    "\n",
    "Update the following class by completing the todo statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Optional, Tuple\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "\n",
    "class Tokenizer:\n",
    "    \"\"\"Tokenizes and pads a batch of input sentences.\"\"\"\n",
    "\n",
    "    def __init__(self, pad_symbol: Optional[str] = \"<PAD>\"):\n",
    "        \"\"\"Initializes the tokenizer\n",
    "\n",
    "        Args:\n",
    "            pad_symbol (Optional[str], optional): The symbol for a pad. Defaults to \"<PAD>\".\n",
    "        \"\"\"\n",
    "        self.pad_symbol = pad_symbol\n",
    "        self.nlp = spacy.load(\"en_core_web_sm\")\n",
    "    \n",
    "    def __call__(self, batch: List[str]) -> List[List[str]]:\n",
    "        \"\"\"Tokenizes each sentence in the batch, and pads them if necessary so\n",
    "        that we have equal length sentences in the batch.\n",
    "\n",
    "        Args:\n",
    "            batch (List[str]): A List of sentence strings\n",
    "\n",
    "        Returns:\n",
    "            List[List[str]]: A List of equal-length token Lists.\n",
    "        \"\"\"\n",
    "        batch = self.tokenize(batch)\n",
    "        batch = self.pad(batch)\n",
    "\n",
    "        return batch\n",
    "\n",
    "    def tokenize(self, sentences: List[str]) -> List[List[str]]:\n",
    "        \"\"\"Tokenizes the List of string sentences into a Lists of tokens using spacy tokenizer.\n",
    "\n",
    "        Args:\n",
    "            sentences (List[str]): The input sentence.\n",
    "\n",
    "        Returns:\n",
    "            List[str]: The tokenized version of the sentence.\n",
    "        \"\"\"\n",
    "        # TODO: Tokenize the input with spacy.\n",
    "        # TODO: Make sure the start token is the special <SOS> token and the end token\n",
    "        #       is the special <EOS> token\n",
    "        tokenized_sentences = []\n",
    "        for sentence in sentences:\n",
    "            tokenized_sentence = ['<SOS>']\n",
    "            sentence = self.nlp(sentence)\n",
    "            for token in sentence:\n",
    "                tokenized_sentence.append(token.text)\n",
    "            tokenized_sentence.append('<EOS>')\n",
    "            tokenized_sentences.append(tokenized_sentence)\n",
    "        return tokenized_sentences\n",
    "\n",
    "    def pad(self, batch: List[List[str]]) -> List[List[str]]:\n",
    "        \"\"\"Appends pad symbols to each tokenized sentence in the batch such that\n",
    "        every List of tokens is the same length. This means that the max length sentence\n",
    "        will not be padded.\n",
    "\n",
    "        Args:\n",
    "            batch (List[List[str]]): Batch of tokenized sentences.\n",
    "\n",
    "        Returns:\n",
    "            List[List[str]]: Batch of padded tokenized sentences. \n",
    "        \"\"\"\n",
    "        # TODO: For each sentence in the batch, append the special <P>\n",
    "        #       symbol to it n times to make all sentences equal length\n",
    "        pad_max = max([len(l) for l in batch])\n",
    "        for sentence in batch:\n",
    "            sentence.extend(['<PAD>'] * (pad_max - len(sentence)))\n",
    "        return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the vocabulary of the dataset: use both training and test sets here\n",
    "\n",
    "SPECIAL_TOKENS = ['<UNK>', '<PAD>', '<SOS>', '<EOS>']\n",
    "\n",
    "all_data = train_sentences + test_sentences\n",
    "my_tokenizer = Tokenizer()\n",
    "\n",
    "tokenized_data = my_tokenizer.tokenize(all_data)\n",
    "vocab = sorted(set([w for ws in tokenized_data + [SPECIAL_TOKENS] for w in ws]))\n",
    "\n",
    "with open('vocab.txt', 'w') as vf:\n",
    "    vf.write('\\n'.join(vocab))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embeddings\n",
    "\n",
    "We use GloVe embeddings https://nlp.stanford.edu/projects/glove/. But these do not necessarily have all of the tokens that will occur in tweets! Hoad the GloVe embeddings, pruning them to only those words in vocab.txt. This is to reduce the memory and runtime of your model.\n",
    "\n",
    "Then, find the out-of-vocabulary words (oov) and add them to the encoding dictionary and the embeddings matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dowload the gloVe vectors for Twitter tweets. This will download a file called glove.twitter.27B.zip\n",
    "\n",
    "# ! wget https://nlp.stanford.edu/data/glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unzip glove.twitter.27B.zip\n",
    "# if there is an error, please download the zip file again\n",
    "\n",
    "# ! unzip glove.twitter.27B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what files are there:\n",
    "\n",
    "# ! ls . | grep \"glove.*.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this assignment, we will use glove.twitter.27B.50d.txt which has 50 dimensional word vectors\n",
    "# Feel free to experiment with vectors of other sizes\n",
    "\n",
    "embeddings_path = 'glove.twitter.27B.50d.txt'\n",
    "vocab_path = \"./vocab.txt\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a custom Embedding Layer\n",
    "\n",
    "Now the GloVe file has vectors for about 1.2 million words. However, we only need the vectors for a very tiny fraction of words -> the unique words that are there in the classification corpus. Some of the next tasks will be to create a custom embedding layer that has the vectors for this small set of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2: Extracting word vectors from GloVe (3 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import torch\n",
    "\n",
    "\n",
    "def read_pretrained_embeddings(\n",
    "    embeddings_path: str,\n",
    "    vocab_path: str\n",
    ") -> Tuple[Dict[str, int], torch.FloatTensor]:\n",
    "    \"\"\"Read the embeddings matrix and make a dict hashing each word.\n",
    "\n",
    "    Note that we have provided the entire vocab for train and test, so that for practical purposes\n",
    "    we can simply load those words in the vocab, rather than all 27B embeddings\n",
    "\n",
    "    Args:\n",
    "        embeddings_path (str): _description_\n",
    "        vocab_path (str): _description_\n",
    "\n",
    "    Returns:\n",
    "        Tuple[Dict[str, int], torch.FloatTensor]: _description_\n",
    "    \"\"\"\n",
    "    word2i = {}\n",
    "    vectors = []\n",
    "    \n",
    "    with open(vocab_path, encoding='utf8') as vf:\n",
    "        vocab = set([w.strip() for w in vf.readlines()]) \n",
    "    \n",
    "#     print('vocab we have', vocab)\n",
    "    print(f\"Reading embeddings from {embeddings_path}...\")\n",
    "    with open(embeddings_path, \"r\") as f:\n",
    "        i = 0\n",
    "        for line in f:\n",
    "            word, *weights = line.rstrip().split(\" \")\n",
    "            # TODO: Build word2i and vectors such that\n",
    "            #       each word points to the index of its vector,\n",
    "            #       and only words that exist in `vocab` are in our embeddings\n",
    "            if word in vocab:\n",
    "                word2i[word] = i\n",
    "                vectors.insert(i, torch.Tensor([float(x) for x in weights]))\n",
    "                i += 1\n",
    "    return word2i, torch.stack(vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3: Get GloVe Out of Vocabulary (oov) words (0 Points)\n",
    "\n",
    "The task is to find the words in the Irony corpus that are not in the GloVe Word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_oovs(vocab_path: str, word2i: Dict[str, int]) -> List[str]:\n",
    "    \"\"\"Find the vocab items that do not exist in the glove embeddings (in word2i).\n",
    "    Return the List of such (unique) words.\n",
    "\n",
    "    Args:\n",
    "        vocab_path: List of batches of sentences.\n",
    "        word2i (Dict[str, int]): _description_\n",
    "\n",
    "    Returns:\n",
    "        List[str]: _description_\n",
    "    \"\"\"\n",
    "    with open(vocab_path, encoding='utf8') as vf:\n",
    "        vocab = set([w.strip() for w in vf.readlines()])\n",
    "    \n",
    "    glove_and_vocab = set(word2i.keys())\n",
    "    vocab_and_not_glove = vocab - glove_and_vocab\n",
    "    return list(vocab_and_not_glove)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4: Update the embeddings with oov words (3 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intialize_new_embedding_weights(num_embeddings: int, dim: int) -> torch.FloatTensor:\n",
    "    \"\"\"xavier initialization for the embeddings of words in train, but not in gLove.\n",
    "\n",
    "    Args:\n",
    "        num_embeddings (int): _description_\n",
    "        dim (int): _description_\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: _description_\n",
    "    \"\"\"\n",
    "#     TODO: Initialize a num_embeddings x dim matrix with xiavier initiialization\n",
    "#          That is, a normal distribution with mean 0 and standard deviation of dim^-0.5\n",
    "    w = torch.empty(num_embeddings, dim)\n",
    "    return torch.nn.init.xavier_normal_(w)\n",
    "\n",
    "\n",
    "def update_embeddings(\n",
    "    glove_word2i: Dict[str, int],\n",
    "    glove_embeddings: torch.FloatTensor,\n",
    "    oovs: List[str]\n",
    ") -> Tuple[Dict[str, int], torch.FloatTensor]:\n",
    "    # TODO: Add the oov words to the dict, assigning a new index to each\n",
    "\n",
    "    # TODO: Concatenate a new row to embeddings for each oov\n",
    "    #       initialize those new rows with `intialize_new_embedding_weights`\n",
    "\n",
    "    # TODO: Return the tuple of the dictionary and the new embeddings matrix\n",
    "    index = len(glove_word2i)\n",
    "    row = 0\n",
    "    for word in oovs:\n",
    "        glove_word2i[word] = index\n",
    "        index += 1\n",
    "        row += 1 \n",
    "    x = intialize_new_embedding_weights(row, glove_embeddings.size(dim=1))\n",
    "    glove_embeddings = torch.cat((glove_embeddings, x), 0)\n",
    "    return  glove_word2i, glove_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading embeddings from glove.twitter.27B.50d.txt...\n"
     ]
    }
   ],
   "source": [
    "glove_word2i, glove_embeddings = read_pretrained_embeddings(\n",
    "    embeddings_path,\n",
    "    vocab_path\n",
    ")\n",
    "\n",
    "# Find the out-of-vocabularies\n",
    "oovs = get_oovs(vocab_path, glove_word2i)\n",
    "\n",
    "# Add the oovs from training data to the word2i encoding, and as new rows\n",
    "# to the embeddings matrix\n",
    "word2i, embeddings = update_embeddings(glove_word2i, glove_embeddings, oovs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoding words to integers: DO NOT EDIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use these functions to encode your batches before you call the train loop.\n",
    "\n",
    "def encode_sentences(batch: List[List[str]], word2i: Dict[str, int]) -> torch.LongTensor:\n",
    "    \"\"\"Encode the tokens in each sentence in the batch with a dictionary\n",
    "\n",
    "    Args:\n",
    "        batch (List[List[str]]): The padded and tokenized batch of sentences.\n",
    "        word2i (Dict[str, int]): The encoding dictionary.\n",
    "\n",
    "    Returns:\n",
    "        torch.LongTensor: The tensor of encoded sentences.\n",
    "    \"\"\"\n",
    "    UNK_IDX = word2i[\"<UNK>\"]\n",
    "    tensors = []\n",
    "    for sent in batch:\n",
    "        tensors.append(torch.LongTensor([word2i.get(w, UNK_IDX) for w in sent]))\n",
    "        \n",
    "    return torch.stack(tensors)\n",
    "\n",
    "\n",
    "def encode_labels(labels: List[int]) -> torch.FloatTensor:\n",
    "    \"\"\"Turns the batch of labels into a tensor\n",
    "\n",
    "    Args:\n",
    "        labels (List[int]): List of all labels in the batch\n",
    "\n",
    "    Returns:\n",
    "        torch.FloatTensor: Tensor of all labels in the batch\n",
    "    \"\"\"\n",
    "    return torch.LongTensor([int(l) for l in labels])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "vocab_path = \"./vocab.txt\"\n",
    "\n",
    "\n",
    "def make_batches(sequences: List[str], batch_size: int) -> List[List[str]]:\n",
    "    \"\"\"Yield batch_size chunks from sequences.\"\"\"\n",
    "    # TODO\n",
    "    samples = sequences\n",
    "    batches = []\n",
    "    for i in range(0, len(samples), batch_size):\n",
    "        batches.append(samples[i:i+batch_size])\n",
    "    return batches\n",
    "\n",
    "# TODO: Set your preferred batch size\n",
    "batch_size = 16\n",
    "tokenizer = Tokenizer()\n",
    "\n",
    "# We make batches now and use those.\n",
    "encode_tokenized_batch_train_sentences = []\n",
    "encode_tokenized_batch_train_labels = []\n",
    "encode_tokenized_batch_dev_sentences = []\n",
    "encode_tokenized_batch_dev_labels = []\n",
    "\n",
    "# Note: Labels need to be batched in the same way to ensure\n",
    "# We have train sentence and label batches lining up.\n",
    "for batch in make_batches(train_sentences, batch_size):\n",
    "    encode_tokenized_batch_train_sentences.append(encode_sentences(tokenizer(batch), word2i))\n",
    "\n",
    "for batch in make_batches(train_labels, batch_size):\n",
    "    encode_tokenized_batch_train_labels.append(encode_labels(batch))\n",
    "\n",
    "for batch in make_batches(test_sentences, batch_size):\n",
    "    encode_tokenized_batch_dev_sentences.append(encode_sentences(tokenizer(batch), word2i))\n",
    "\n",
    "for batch in make_batches(test_labels, batch_size):\n",
    "    encode_tokenized_batch_dev_labels.append(encode_labels(batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling   ( 7 Points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "# Notice there is a single TODO in the model\n",
    "class IronyDetector(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        hidden_dim: int,\n",
    "        embeddings_tensor: torch.FloatTensor,\n",
    "        pad_idx: int,\n",
    "        output_size: int,\n",
    "        dropout_val: float = 0.3,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.pad_idx = pad_idx\n",
    "        self.dropout_val = dropout_val\n",
    "        self.output_size = output_size\n",
    "        # TODO: Initialize the embeddings from the weights matrix.\n",
    "        #       Check the documentation for how to initialize an embedding layer\n",
    "        #       from a pretrained embedding matrix. \n",
    "        #       Be careful to set the `freeze` parameter!\n",
    "        #       Docs are here: https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding.from_pretrained\n",
    "        self.embeddings = torch.nn.Embedding.from_pretrained(embeddings_tensor)\n",
    "        # Dropout regularization\n",
    "        # https://jmlr.org/papers/v15/srivastava14a.html\n",
    "        self.dropout_layer = torch.nn.Dropout(p=self.dropout_val, inplace=False)\n",
    "        # Bidirectional 2-layer LSTM. Feel free to try different parameters.\n",
    "        # https://colah.github.io/posts/2015-08-Understanding-LSTMs/\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            self.input_dim,\n",
    "            self.hidden_dim,\n",
    "            num_layers=2,\n",
    "            dropout=dropout_val,\n",
    "            batch_first=True,\n",
    "            bidirectional=True,\n",
    "        )\n",
    "        # For classification over the final LSTM state.\n",
    "        self.classifier = torch.nn.Linear(hidden_dim*2, self.output_size)\n",
    "        self.log_softmax = torch.nn.LogSoftmax(dim=2)\n",
    "    \n",
    "    def encode_text(\n",
    "        self,\n",
    "        symbols: torch.Tensor\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"Encode the (batch of) sequence(s) of token symbols with an LSTM.\n",
    "            Then, get the last (non-padded) hidden state for each symbol and return that.\n",
    "\n",
    "        Args:\n",
    "            symbols (torch.Tensor): The batch size x sequence length tensor of input tokens\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The final hiddens tate of the LSTM, which represents an encoding of\n",
    "                the entire sentence\n",
    "        \"\"\"\n",
    "        # First we get the embedding for each input symbol\n",
    "        embedded = self.embeddings(symbols)\n",
    "        embedded = self.dropout_layer(embedded)\n",
    "        # Packs embedded source symbols into a PackedSequence.\n",
    "        # This is an optimization when using padded sequences with an LSTM\n",
    "        lens = (symbols != self.pad_idx).sum(dim=1).to(\"cpu\")\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(\n",
    "            embedded, lens, batch_first=True, enforce_sorted=False\n",
    "        )\n",
    "        # -> batch_size x seq_len x encoder_dim, (h0, c0).\n",
    "        packed_outs, (H, C) = self.lstm(packed)\n",
    "        encoded, _ = torch.nn.utils.rnn.pad_packed_sequence(\n",
    "            packed_outs,\n",
    "            batch_first=True,\n",
    "            padding_value=self.pad_idx,\n",
    "            total_length=None,\n",
    "        )\n",
    "        # Now we have the representation of eahc token encoded by the LSTM.\n",
    "        encoded, (H, C) = self.lstm(embedded)\n",
    "   \n",
    "        # This part looks tricky. All we are doing is getting a tensor\n",
    "        # That indexes the last non-PAD position in each tensor in the batch.\n",
    "        last_enc_out_idxs = lens - 1\n",
    "        # -> B x 1 x 1.\n",
    "        last_enc_out_idxs = last_enc_out_idxs.view([encoded.size(0)] + [1, 1])\n",
    "        # -> 1 x 1 x encoder_dim. This indexes the last non-padded dimension.\n",
    "        last_enc_out_idxs = last_enc_out_idxs.expand(\n",
    "            [-1, -1, encoded.size(-1)]\n",
    "        )\n",
    "        # Get the final hidden state in the LSTM\n",
    "        last_hidden = torch.gather(encoded, 1, last_enc_out_idxs)\n",
    "        return last_hidden\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        symbols: torch.Tensor,\n",
    "    ) -> torch.Tensor:\n",
    "        encoded_sents = self.encode_text(symbols)\n",
    "        output = self.classifier(encoded_sents)\n",
    "        print(output)\n",
    "        print(self.log_softmax(output))\n",
    "        return self.log_softmax(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model: torch.nn.Module, dev_sequences: List[torch.Tensor]):\n",
    "    preds = []\n",
    "    # TODO: Get the predictions for the dev_sequences using the model\n",
    "    for dev_sequence in dev_sequences:\n",
    "        preds.append(torch.argmax(model(dev_sequence).squeeze(1), dim = 1))\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "import random\n",
    "from util import avg_f1_score, f1_score\n",
    "\n",
    "\n",
    "def training_loop(\n",
    "    num_epochs,\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    dev_features,\n",
    "    dev_labels,\n",
    "    optimizer,\n",
    "    model,\n",
    "):\n",
    "    print(\"Training...\")\n",
    "    loss_func = torch.nn.NLLLoss()\n",
    "    batches = list(zip(train_features, train_labels))\n",
    "    random.shuffle(batches)\n",
    "    dev_labels = np.vstack(ten.numpy() for ten in dev_labels).flatten()\n",
    "    for i in range(num_epochs):\n",
    "        losses = []\n",
    "        for features, labels in tqdm(batches):\n",
    "            # Empty the dynamic computation graph\n",
    "            optimizer.zero_grad()\n",
    "            preds = model(features).squeeze(1)\n",
    "            loss = loss_func(preds, labels)\n",
    "            # Backpropogate the loss through our model\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "        \n",
    "        print(f\"epoch {i}, loss: {sum(losses)/len(losses)}\")\n",
    "        # Estimate the f1 score for the development set\n",
    "        print(\"Evaluating dev...\")\n",
    "        preds = predict(model, dev_features)\n",
    "        preds= np.vstack(ten.numpy() for ten in preds).flatten()\n",
    "        dev_f1 = f1_score(preds, dev_labels, label2i['1'])\n",
    "        dev_avg_f1 = avg_f1_score(preds, dev_labels, list(label2i.values()))\n",
    "        print(f\"Dev F1 {dev_f1}\")\n",
    "        print(f\"Avf Dev F1 {dev_avg_f1}\")\n",
    "        \n",
    "    # Return the trained model\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3l/yzh9j02x7bxd463cl1x0_2lh0000gn/T/ipykernel_38503/2389766617.py:20: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  dev_labels = np.vstack(ten.numpy() for ten in dev_labels).flatten()\n",
      "/var/folders/3l/yzh9j02x7bxd463cl1x0_2lh0000gn/T/ipykernel_38503/2389766617.py:23: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  for features, labels in tqdm(batches):\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "289ad0a2de7a4eada279716df38b1163",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/240 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0407, -0.0259]],\n",
      "\n",
      "        [[ 0.0900, -0.0073]],\n",
      "\n",
      "        [[ 0.0530, -0.0468]],\n",
      "\n",
      "        [[ 0.0732, -0.0174]],\n",
      "\n",
      "        [[ 0.0371, -0.0481]],\n",
      "\n",
      "        [[ 0.0575, -0.0139]],\n",
      "\n",
      "        [[ 0.0744, -0.0142]],\n",
      "\n",
      "        [[ 0.0906,  0.0018]],\n",
      "\n",
      "        [[ 0.0570, -0.0400]],\n",
      "\n",
      "        [[ 0.0513, -0.0498]],\n",
      "\n",
      "        [[ 0.0544, -0.0400]],\n",
      "\n",
      "        [[ 0.0841, -0.0406]],\n",
      "\n",
      "        [[ 0.0924, -0.0079]],\n",
      "\n",
      "        [[ 0.0570, -0.0472]],\n",
      "\n",
      "        [[ 0.0324, -0.0328]],\n",
      "\n",
      "        [[ 0.0631, -0.0331]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6604, -0.7270]],\n",
      "\n",
      "        [[-0.6457, -0.7430]],\n",
      "\n",
      "        [[-0.6445, -0.7443]],\n",
      "\n",
      "        [[-0.6489, -0.7394]],\n",
      "\n",
      "        [[-0.6514, -0.7367]],\n",
      "\n",
      "        [[-0.6581, -0.7295]],\n",
      "\n",
      "        [[-0.6499, -0.7384]],\n",
      "\n",
      "        [[-0.6497, -0.7385]],\n",
      "\n",
      "        [[-0.6458, -0.7428]],\n",
      "\n",
      "        [[-0.6438, -0.7450]],\n",
      "\n",
      "        [[-0.6470, -0.7415]],\n",
      "\n",
      "        [[-0.6327, -0.7575]],\n",
      "\n",
      "        [[-0.6442, -0.7446]],\n",
      "\n",
      "        [[-0.6424, -0.7466]],\n",
      "\n",
      "        [[-0.6611, -0.7262]],\n",
      "\n",
      "        [[-0.6462, -0.7424]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0375, -0.0296]],\n",
      "\n",
      "        [[ 0.0510, -0.0122]],\n",
      "\n",
      "        [[ 0.0318, -0.0306]],\n",
      "\n",
      "        [[ 0.0387, -0.0168]],\n",
      "\n",
      "        [[ 0.1118,  0.0130]],\n",
      "\n",
      "        [[ 0.0732, -0.0143]],\n",
      "\n",
      "        [[ 0.0770,  0.0008]],\n",
      "\n",
      "        [[ 0.0410, -0.0424]],\n",
      "\n",
      "        [[ 0.0326, -0.0231]],\n",
      "\n",
      "        [[ 0.0206, -0.0309]],\n",
      "\n",
      "        [[ 0.0791, -0.0002]],\n",
      "\n",
      "        [[ 0.0662, -0.0134]],\n",
      "\n",
      "        [[ 0.0528, -0.0053]],\n",
      "\n",
      "        [[ 0.0352, -0.0325]],\n",
      "\n",
      "        [[ 0.0330, -0.0515]],\n",
      "\n",
      "        [[ 0.0596, -0.0331]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6602, -0.7273]],\n",
      "\n",
      "        [[-0.6621, -0.7252]],\n",
      "\n",
      "        [[-0.6624, -0.7249]],\n",
      "\n",
      "        [[-0.6658, -0.7213]],\n",
      "\n",
      "        [[-0.6450, -0.7438]],\n",
      "\n",
      "        [[-0.6503, -0.7379]],\n",
      "\n",
      "        [[-0.6557, -0.7320]],\n",
      "\n",
      "        [[-0.6523, -0.7357]],\n",
      "\n",
      "        [[-0.6657, -0.7214]],\n",
      "\n",
      "        [[-0.6677, -0.7192]],\n",
      "\n",
      "        [[-0.6543, -0.7336]],\n",
      "\n",
      "        [[-0.6542, -0.7337]],\n",
      "\n",
      "        [[-0.6645, -0.7226]],\n",
      "\n",
      "        [[-0.6598, -0.7276]],\n",
      "\n",
      "        [[-0.6518, -0.7363]],\n",
      "\n",
      "        [[-0.6479, -0.7406]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0379, -0.0063]],\n",
      "\n",
      "        [[ 0.0282, -0.0163]],\n",
      "\n",
      "        [[ 0.1015,  0.0040]],\n",
      "\n",
      "        [[ 0.0395, -0.0420]],\n",
      "\n",
      "        [[ 0.0384, -0.0127]],\n",
      "\n",
      "        [[ 0.0057, -0.0311]],\n",
      "\n",
      "        [[ 0.0556, -0.0322]],\n",
      "\n",
      "        [[ 0.0537, -0.0183]],\n",
      "\n",
      "        [[ 0.0385, -0.0383]],\n",
      "\n",
      "        [[ 0.0512, -0.0113]],\n",
      "\n",
      "        [[ 0.0428, -0.0228]],\n",
      "\n",
      "        [[ 0.0402, -0.0367]],\n",
      "\n",
      "        [[ 0.1076,  0.0119]],\n",
      "\n",
      "        [[ 0.0374, -0.0456]],\n",
      "\n",
      "        [[ 0.0468, -0.0198]],\n",
      "\n",
      "        [[ 0.0486, -0.0037]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6713, -0.7155]],\n",
      "\n",
      "        [[-0.6711, -0.7157]],\n",
      "\n",
      "        [[-0.6456, -0.7431]],\n",
      "\n",
      "        [[-0.6532, -0.7347]],\n",
      "\n",
      "        [[-0.6679, -0.7190]],\n",
      "\n",
      "        [[-0.6749, -0.7117]],\n",
      "\n",
      "        [[-0.6502, -0.7380]],\n",
      "\n",
      "        [[-0.6578, -0.7298]],\n",
      "\n",
      "        [[-0.6555, -0.7323]],\n",
      "\n",
      "        [[-0.6624, -0.7249]],\n",
      "\n",
      "        [[-0.6609, -0.7265]],\n",
      "\n",
      "        [[-0.6554, -0.7323]],\n",
      "\n",
      "        [[-0.6465, -0.7421]],\n",
      "\n",
      "        [[-0.6525, -0.7355]],\n",
      "\n",
      "        [[-0.6604, -0.7270]],\n",
      "\n",
      "        [[-0.6673, -0.7196]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0342, -0.0283]],\n",
      "\n",
      "        [[ 0.0574, -0.0418]],\n",
      "\n",
      "        [[ 0.0277, -0.0639]],\n",
      "\n",
      "        [[ 0.0528, -0.0447]],\n",
      "\n",
      "        [[ 0.0908, -0.0098]],\n",
      "\n",
      "        [[ 0.0505, -0.0237]],\n",
      "\n",
      "        [[ 0.0695, -0.0194]],\n",
      "\n",
      "        [[ 0.0810, -0.0077]],\n",
      "\n",
      "        [[ 0.0795, -0.0214]],\n",
      "\n",
      "        [[ 0.0548, -0.0289]],\n",
      "\n",
      "        [[ 0.0288, -0.0487]],\n",
      "\n",
      "        [[ 0.0469, -0.0273]],\n",
      "\n",
      "        [[ 0.0716, -0.0370]],\n",
      "\n",
      "        [[ 0.0517, -0.0254]],\n",
      "\n",
      "        [[ 0.0411, -0.0375]],\n",
      "\n",
      "        [[ 0.0515, -0.0167]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6624, -0.7249]],\n",
      "\n",
      "        [[-0.6448, -0.7440]],\n",
      "\n",
      "        [[-0.6484, -0.7400]],\n",
      "\n",
      "        [[-0.6456, -0.7430]],\n",
      "\n",
      "        [[-0.6441, -0.7447]],\n",
      "\n",
      "        [[-0.6567, -0.7310]],\n",
      "\n",
      "        [[-0.6497, -0.7386]],\n",
      "\n",
      "        [[-0.6498, -0.7385]],\n",
      "\n",
      "        [[-0.6440, -0.7449]],\n",
      "\n",
      "        [[-0.6522, -0.7359]],\n",
      "\n",
      "        [[-0.6551, -0.7327]],\n",
      "\n",
      "        [[-0.6568, -0.7309]],\n",
      "\n",
      "        [[-0.6403, -0.7489]],\n",
      "\n",
      "        [[-0.6553, -0.7324]],\n",
      "\n",
      "        [[-0.6546, -0.7332]],\n",
      "\n",
      "        [[-0.6596, -0.7278]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0460, -0.0363]],\n",
      "\n",
      "        [[ 0.0280, -0.0418]],\n",
      "\n",
      "        [[ 0.0288, -0.0317]],\n",
      "\n",
      "        [[ 0.0738, -0.0200]],\n",
      "\n",
      "        [[ 0.0437, -0.0427]],\n",
      "\n",
      "        [[ 0.0610, -0.0184]],\n",
      "\n",
      "        [[ 0.0729, -0.0129]],\n",
      "\n",
      "        [[ 0.0742, -0.0277]],\n",
      "\n",
      "        [[ 0.0583, -0.0143]],\n",
      "\n",
      "        [[ 0.0778, -0.0309]],\n",
      "\n",
      "        [[ 0.0460, -0.0483]],\n",
      "\n",
      "        [[ 0.0552, -0.0268]],\n",
      "\n",
      "        [[ 0.0507, -0.0361]],\n",
      "\n",
      "        [[ 0.0499, -0.0364]],\n",
      "\n",
      "        [[ 0.0227, -0.0427]],\n",
      "\n",
      "        [[ 0.0621, -0.0265]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6529, -0.7351]],\n",
      "\n",
      "        [[-0.6588, -0.7287]],\n",
      "\n",
      "        [[-0.6634, -0.7239]],\n",
      "\n",
      "        [[-0.6474, -0.7411]],\n",
      "\n",
      "        [[-0.6509, -0.7373]],\n",
      "\n",
      "        [[-0.6542, -0.7336]],\n",
      "\n",
      "        [[-0.6512, -0.7370]],\n",
      "\n",
      "        [[-0.6435, -0.7454]],\n",
      "\n",
      "        [[-0.6575, -0.7301]],\n",
      "\n",
      "        [[-0.6403, -0.7489]],\n",
      "\n",
      "        [[-0.6471, -0.7414]],\n",
      "\n",
      "        [[-0.6530, -0.7350]],\n",
      "\n",
      "        [[-0.6507, -0.7375]],\n",
      "\n",
      "        [[-0.6509, -0.7372]],\n",
      "\n",
      "        [[-0.6609, -0.7264]],\n",
      "\n",
      "        [[-0.6498, -0.7384]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0231, -0.0178]],\n",
      "\n",
      "        [[ 0.0336, -0.0096]],\n",
      "\n",
      "        [[ 0.0510, -0.0323]],\n",
      "\n",
      "        [[ 0.0292, -0.0392]],\n",
      "\n",
      "        [[ 0.0434, -0.0139]],\n",
      "\n",
      "        [[ 0.1113, -0.0147]],\n",
      "\n",
      "        [[ 0.0576, -0.0391]],\n",
      "\n",
      "        [[ 0.0603, -0.0088]],\n",
      "\n",
      "        [[ 0.0341, -0.0318]],\n",
      "\n",
      "        [[ 0.0485, -0.0296]],\n",
      "\n",
      "        [[ 0.0343, -0.0279]],\n",
      "\n",
      "        [[ 0.0311, -0.0472]],\n",
      "\n",
      "        [[ 0.0839,  0.0010]],\n",
      "\n",
      "        [[ 0.0316, -0.0362]],\n",
      "\n",
      "        [[ 0.0143, -0.0357]],\n",
      "\n",
      "        [[ 0.0705, -0.0155]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6729, -0.7138]],\n",
      "\n",
      "        [[-0.6717, -0.7150]],\n",
      "\n",
      "        [[-0.6523, -0.7357]],\n",
      "\n",
      "        [[-0.6596, -0.7279]],\n",
      "\n",
      "        [[-0.6649, -0.7222]],\n",
      "\n",
      "        [[-0.6321, -0.7581]],\n",
      "\n",
      "        [[-0.6460, -0.7427]],\n",
      "\n",
      "        [[-0.6592, -0.7283]],\n",
      "\n",
      "        [[-0.6607, -0.7267]],\n",
      "\n",
      "        [[-0.6549, -0.7330]],\n",
      "\n",
      "        [[-0.6625, -0.7247]],\n",
      "\n",
      "        [[-0.6548, -0.7330]],\n",
      "\n",
      "        [[-0.6526, -0.7354]],\n",
      "\n",
      "        [[-0.6598, -0.7276]],\n",
      "\n",
      "        [[-0.6685, -0.7184]],\n",
      "\n",
      "        [[-0.6511, -0.7371]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0939,  0.0001]],\n",
      "\n",
      "        [[ 0.0325, -0.0359]],\n",
      "\n",
      "        [[ 0.0322, -0.0503]],\n",
      "\n",
      "        [[ 0.0359, -0.0063]],\n",
      "\n",
      "        [[ 0.0506, -0.0127]],\n",
      "\n",
      "        [[ 0.0465, -0.0271]],\n",
      "\n",
      "        [[ 0.0104, -0.0375]],\n",
      "\n",
      "        [[ 0.0266, -0.0185]],\n",
      "\n",
      "        [[ 0.0240, -0.0361]],\n",
      "\n",
      "        [[ 0.0232, -0.0291]],\n",
      "\n",
      "        [[ 0.0200, -0.0203]],\n",
      "\n",
      "        [[ 0.0338, -0.0245]],\n",
      "\n",
      "        [[ 0.0424, -0.0123]],\n",
      "\n",
      "        [[ 0.0311, -0.0130]],\n",
      "\n",
      "        [[ 0.0212, -0.0153]],\n",
      "\n",
      "        [[ 0.0540, -0.0118]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6474, -0.7411]],\n",
      "\n",
      "        [[-0.6595, -0.7279]],\n",
      "\n",
      "        [[-0.6527, -0.7353]],\n",
      "\n",
      "        [[-0.6723, -0.7144]],\n",
      "\n",
      "        [[-0.6620, -0.7253]],\n",
      "\n",
      "        [[-0.6570, -0.7306]],\n",
      "\n",
      "        [[-0.6695, -0.7174]],\n",
      "\n",
      "        [[-0.6708, -0.7160]],\n",
      "\n",
      "        [[-0.6635, -0.7237]],\n",
      "\n",
      "        [[-0.6674, -0.7196]],\n",
      "\n",
      "        [[-0.6732, -0.7135]],\n",
      "\n",
      "        [[-0.6644, -0.7228]],\n",
      "\n",
      "        [[-0.6661, -0.7209]],\n",
      "\n",
      "        [[-0.6714, -0.7154]],\n",
      "\n",
      "        [[-0.6751, -0.7115]],\n",
      "\n",
      "        [[-0.6608, -0.7266]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0456, -0.0006]],\n",
      "\n",
      "        [[ 0.0344,  0.0070]],\n",
      "\n",
      "        [[ 0.0806,  0.0069]],\n",
      "\n",
      "        [[ 0.0497, -0.0285]],\n",
      "\n",
      "        [[ 0.0438,  0.0010]],\n",
      "\n",
      "        [[ 0.0187,  0.0008]],\n",
      "\n",
      "        [[ 0.0248, -0.0228]],\n",
      "\n",
      "        [[ 0.0790,  0.0010]],\n",
      "\n",
      "        [[ 0.0233,  0.0094]],\n",
      "\n",
      "        [[ 0.0179, -0.0225]],\n",
      "\n",
      "        [[ 0.0209, -0.0298]],\n",
      "\n",
      "        [[-0.0127, -0.0505]],\n",
      "\n",
      "        [[ 0.0455, -0.0250]],\n",
      "\n",
      "        [[ 0.0183, -0.0215]],\n",
      "\n",
      "        [[ 0.0398, -0.0080]],\n",
      "\n",
      "        [[ 0.0334, -0.0317]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6703, -0.7165]],\n",
      "\n",
      "        [[-0.6796, -0.7069]],\n",
      "\n",
      "        [[-0.6570, -0.7307]],\n",
      "\n",
      "        [[-0.6548, -0.7330]],\n",
      "\n",
      "        [[-0.6719, -0.7148]],\n",
      "\n",
      "        [[-0.6843, -0.7021]],\n",
      "\n",
      "        [[-0.6696, -0.7173]],\n",
      "\n",
      "        [[-0.6549, -0.7329]],\n",
      "\n",
      "        [[-0.6862, -0.7001]],\n",
      "\n",
      "        [[-0.6731, -0.7136]],\n",
      "\n",
      "        [[-0.6681, -0.7188]],\n",
      "\n",
      "        [[-0.6744, -0.7123]],\n",
      "\n",
      "        [[-0.6585, -0.7290]],\n",
      "\n",
      "        [[-0.6734, -0.7132]],\n",
      "\n",
      "        [[-0.6695, -0.7173]],\n",
      "\n",
      "        [[-0.6611, -0.7262]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0110, -0.0237]],\n",
      "\n",
      "        [[ 0.0177, -0.0092]],\n",
      "\n",
      "        [[-0.0079, -0.0313]],\n",
      "\n",
      "        [[ 0.0348,  0.0004]],\n",
      "\n",
      "        [[ 0.0203, -0.0165]],\n",
      "\n",
      "        [[ 0.0186,  0.0016]],\n",
      "\n",
      "        [[ 0.0395,  0.0174]],\n",
      "\n",
      "        [[-0.0190, -0.0494]],\n",
      "\n",
      "        [[ 0.0247,  0.0094]],\n",
      "\n",
      "        [[ 0.0381, -0.0088]],\n",
      "\n",
      "        [[ 0.0551, -0.0122]],\n",
      "\n",
      "        [[ 0.0044, -0.0320]],\n",
      "\n",
      "        [[ 0.0290,  0.0002]],\n",
      "\n",
      "        [[ 0.0080, -0.0205]],\n",
      "\n",
      "        [[ 0.0281,  0.0137]],\n",
      "\n",
      "        [[ 0.0619,  0.0088]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6759, -0.7106]],\n",
      "\n",
      "        [[-0.6797, -0.7067]],\n",
      "\n",
      "        [[-0.6815, -0.7049]],\n",
      "\n",
      "        [[-0.6761, -0.7105]],\n",
      "\n",
      "        [[-0.6749, -0.7117]],\n",
      "\n",
      "        [[-0.6847, -0.7017]],\n",
      "\n",
      "        [[-0.6822, -0.7043]],\n",
      "\n",
      "        [[-0.6781, -0.7085]],\n",
      "\n",
      "        [[-0.6855, -0.7008]],\n",
      "\n",
      "        [[-0.6699, -0.7169]],\n",
      "\n",
      "        [[-0.6601, -0.7274]],\n",
      "\n",
      "        [[-0.6751, -0.7115]],\n",
      "\n",
      "        [[-0.6789, -0.7076]],\n",
      "\n",
      "        [[-0.6790, -0.7075]],\n",
      "\n",
      "        [[-0.6860, -0.7004]],\n",
      "\n",
      "        [[-0.6670, -0.7200]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0351, -0.0083]],\n",
      "\n",
      "        [[ 0.0361,  0.0241]],\n",
      "\n",
      "        [[ 0.0029, -0.0003]],\n",
      "\n",
      "        [[ 0.0007, -0.0044]],\n",
      "\n",
      "        [[ 0.0017, -0.0087]],\n",
      "\n",
      "        [[-0.0143, -0.0251]],\n",
      "\n",
      "        [[ 0.0378,  0.0061]],\n",
      "\n",
      "        [[ 0.0124, -0.0015]],\n",
      "\n",
      "        [[ 0.0160, -0.0046]],\n",
      "\n",
      "        [[-0.0106, -0.0212]],\n",
      "\n",
      "        [[ 0.0061, -0.0363]],\n",
      "\n",
      "        [[ 0.0165, -0.0051]],\n",
      "\n",
      "        [[ 0.0088, -0.0141]],\n",
      "\n",
      "        [[ 0.0411,  0.0085]],\n",
      "\n",
      "        [[ 0.0070, -0.0167]],\n",
      "\n",
      "        [[ 0.0020, -0.0009]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6717, -0.7151]],\n",
      "\n",
      "        [[-0.6872, -0.6992]],\n",
      "\n",
      "        [[-0.6916, -0.6947]],\n",
      "\n",
      "        [[-0.6906, -0.6957]],\n",
      "\n",
      "        [[-0.6880, -0.6984]],\n",
      "\n",
      "        [[-0.6877, -0.6986]],\n",
      "\n",
      "        [[-0.6774, -0.7091]],\n",
      "\n",
      "        [[-0.6862, -0.7001]],\n",
      "\n",
      "        [[-0.6829, -0.7035]],\n",
      "\n",
      "        [[-0.6879, -0.6985]],\n",
      "\n",
      "        [[-0.6722, -0.7146]],\n",
      "\n",
      "        [[-0.6824, -0.7040]],\n",
      "\n",
      "        [[-0.6817, -0.7047]],\n",
      "\n",
      "        [[-0.6770, -0.7096]],\n",
      "\n",
      "        [[-0.6814, -0.7051]],\n",
      "\n",
      "        [[-0.6917, -0.6946]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0336, -0.0042]],\n",
      "\n",
      "        [[ 0.0208,  0.0213]],\n",
      "\n",
      "        [[-0.0110,  0.0009]],\n",
      "\n",
      "        [[-0.0074, -0.0074]],\n",
      "\n",
      "        [[ 0.0162,  0.0086]],\n",
      "\n",
      "        [[-0.0161, -0.0001]],\n",
      "\n",
      "        [[ 0.0094, -0.0024]],\n",
      "\n",
      "        [[-0.0131, -0.0096]],\n",
      "\n",
      "        [[ 0.0155,  0.0120]],\n",
      "\n",
      "        [[-0.0184, -0.0135]],\n",
      "\n",
      "        [[ 0.0525,  0.0281]],\n",
      "\n",
      "        [[ 0.0133, -0.0024]],\n",
      "\n",
      "        [[ 0.0004,  0.0165]],\n",
      "\n",
      "        [[ 0.0530,  0.0343]],\n",
      "\n",
      "        [[-0.0073,  0.0092]],\n",
      "\n",
      "        [[ 0.0140,  0.0032]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6745, -0.7122]],\n",
      "\n",
      "        [[-0.6934, -0.6929]],\n",
      "\n",
      "        [[-0.6991, -0.6872]],\n",
      "\n",
      "        [[-0.6932, -0.6931]],\n",
      "\n",
      "        [[-0.6894, -0.6969]],\n",
      "\n",
      "        [[-0.7011, -0.6852]],\n",
      "\n",
      "        [[-0.6872, -0.6991]],\n",
      "\n",
      "        [[-0.6949, -0.6914]],\n",
      "\n",
      "        [[-0.6914, -0.6949]],\n",
      "\n",
      "        [[-0.6956, -0.6907]],\n",
      "\n",
      "        [[-0.6810, -0.7054]],\n",
      "\n",
      "        [[-0.6853, -0.7011]],\n",
      "\n",
      "        [[-0.7012, -0.6851]],\n",
      "\n",
      "        [[-0.6839, -0.7025]],\n",
      "\n",
      "        [[-0.7014, -0.6849]],\n",
      "\n",
      "        [[-0.6878, -0.6986]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0421,  0.0215]],\n",
      "\n",
      "        [[-0.0031, -0.0205]],\n",
      "\n",
      "        [[-0.0159, -0.0306]],\n",
      "\n",
      "        [[ 0.0497,  0.0116]],\n",
      "\n",
      "        [[ 0.0004, -0.0067]],\n",
      "\n",
      "        [[-0.0198, -0.0116]],\n",
      "\n",
      "        [[ 0.0144, -0.0059]],\n",
      "\n",
      "        [[-0.0025,  0.0012]],\n",
      "\n",
      "        [[ 0.0284,  0.0090]],\n",
      "\n",
      "        [[-0.0168,  0.0352]],\n",
      "\n",
      "        [[ 0.0045,  0.0254]],\n",
      "\n",
      "        [[ 0.0100, -0.0061]],\n",
      "\n",
      "        [[ 0.0005,  0.0141]],\n",
      "\n",
      "        [[-0.0195, -0.0049]],\n",
      "\n",
      "        [[ 0.0329, -0.0016]],\n",
      "\n",
      "        [[ 0.0100, -0.0063]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6829, -0.7035]],\n",
      "\n",
      "        [[-0.6845, -0.7019]],\n",
      "\n",
      "        [[-0.6858, -0.7006]],\n",
      "\n",
      "        [[-0.6743, -0.7124]],\n",
      "\n",
      "        [[-0.6896, -0.6967]],\n",
      "\n",
      "        [[-0.6973, -0.6891]],\n",
      "\n",
      "        [[-0.6831, -0.7033]],\n",
      "\n",
      "        [[-0.6950, -0.6913]],\n",
      "\n",
      "        [[-0.6835, -0.7029]],\n",
      "\n",
      "        [[-0.7195, -0.6675]],\n",
      "\n",
      "        [[-0.7037, -0.6828]],\n",
      "\n",
      "        [[-0.6851, -0.7012]],\n",
      "\n",
      "        [[-0.7000, -0.6864]],\n",
      "\n",
      "        [[-0.7005, -0.6859]],\n",
      "\n",
      "        [[-0.6760, -0.7105]],\n",
      "\n",
      "        [[-0.6850, -0.7013]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0385,  0.0270]],\n",
      "\n",
      "        [[ 0.0320, -0.0065]],\n",
      "\n",
      "        [[-0.0065, -0.0275]],\n",
      "\n",
      "        [[-0.0047,  0.0237]],\n",
      "\n",
      "        [[ 0.0569,  0.0544]],\n",
      "\n",
      "        [[ 0.0199,  0.0240]],\n",
      "\n",
      "        [[ 0.0175, -0.0094]],\n",
      "\n",
      "        [[ 0.0068, -0.0028]],\n",
      "\n",
      "        [[ 0.0330,  0.0043]],\n",
      "\n",
      "        [[ 0.0379, -0.0268]],\n",
      "\n",
      "        [[ 0.0485,  0.0292]],\n",
      "\n",
      "        [[ 0.0183, -0.0013]],\n",
      "\n",
      "        [[ 0.0462,  0.0211]],\n",
      "\n",
      "        [[-0.0080,  0.0101]],\n",
      "\n",
      "        [[ 0.0195,  0.0058]],\n",
      "\n",
      "        [[ 0.0043, -0.0049]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6874, -0.6989]],\n",
      "\n",
      "        [[-0.6741, -0.7126]],\n",
      "\n",
      "        [[-0.6827, -0.7037]],\n",
      "\n",
      "        [[-0.7075, -0.6790]],\n",
      "\n",
      "        [[-0.6919, -0.6944]],\n",
      "\n",
      "        [[-0.6952, -0.6911]],\n",
      "\n",
      "        [[-0.6798, -0.7067]],\n",
      "\n",
      "        [[-0.6883, -0.6980]],\n",
      "\n",
      "        [[-0.6789, -0.7076]],\n",
      "\n",
      "        [[-0.6613, -0.7260]],\n",
      "\n",
      "        [[-0.6835, -0.7029]],\n",
      "\n",
      "        [[-0.6834, -0.7030]],\n",
      "\n",
      "        [[-0.6807, -0.7058]],\n",
      "\n",
      "        [[-0.7022, -0.6841]],\n",
      "\n",
      "        [[-0.6863, -0.7000]],\n",
      "\n",
      "        [[-0.6885, -0.6978]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0022, -0.0117]],\n",
      "\n",
      "        [[ 0.0161,  0.0065]],\n",
      "\n",
      "        [[-0.0370, -0.0269]],\n",
      "\n",
      "        [[-0.0021,  0.0031]],\n",
      "\n",
      "        [[ 0.0426, -0.0063]],\n",
      "\n",
      "        [[ 0.0271,  0.0065]],\n",
      "\n",
      "        [[ 0.0158, -0.0030]],\n",
      "\n",
      "        [[ 0.0085, -0.0021]],\n",
      "\n",
      "        [[ 0.0116,  0.0163]],\n",
      "\n",
      "        [[ 0.0422,  0.0166]],\n",
      "\n",
      "        [[ 0.0054,  0.0182]],\n",
      "\n",
      "        [[ 0.0053, -0.0206]],\n",
      "\n",
      "        [[ 0.0437,  0.0445]],\n",
      "\n",
      "        [[ 0.0108,  0.0213]],\n",
      "\n",
      "        [[ 0.0318, -0.0239]],\n",
      "\n",
      "        [[ 0.0320, -0.0210]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6862, -0.7002]],\n",
      "\n",
      "        [[-0.6884, -0.6979]],\n",
      "\n",
      "        [[-0.6982, -0.6881]],\n",
      "\n",
      "        [[-0.6957, -0.6906]],\n",
      "\n",
      "        [[-0.6690, -0.7179]],\n",
      "\n",
      "        [[-0.6829, -0.7035]],\n",
      "\n",
      "        [[-0.6838, -0.7026]],\n",
      "\n",
      "        [[-0.6879, -0.6984]],\n",
      "\n",
      "        [[-0.6955, -0.6908]],\n",
      "\n",
      "        [[-0.6804, -0.7061]],\n",
      "\n",
      "        [[-0.6995, -0.6868]],\n",
      "\n",
      "        [[-0.6803, -0.7062]],\n",
      "\n",
      "        [[-0.6935, -0.6928]],\n",
      "\n",
      "        [[-0.6984, -0.6879]],\n",
      "\n",
      "        [[-0.6657, -0.7214]],\n",
      "\n",
      "        [[-0.6670, -0.7200]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0248,  0.0094]],\n",
      "\n",
      "        [[-0.0121, -0.0261]],\n",
      "\n",
      "        [[ 0.0233, -0.0101]],\n",
      "\n",
      "        [[ 0.0082,  0.0173]],\n",
      "\n",
      "        [[-0.0278, -0.0092]],\n",
      "\n",
      "        [[ 0.0233,  0.0311]],\n",
      "\n",
      "        [[ 0.0092, -0.0220]],\n",
      "\n",
      "        [[ 0.0305,  0.0079]],\n",
      "\n",
      "        [[ 0.0340,  0.0298]],\n",
      "\n",
      "        [[-0.0184, -0.0155]],\n",
      "\n",
      "        [[-0.0410, -0.0212]],\n",
      "\n",
      "        [[ 0.0242,  0.0166]],\n",
      "\n",
      "        [[-0.0132,  0.0032]],\n",
      "\n",
      "        [[ 0.0057, -0.0013]],\n",
      "\n",
      "        [[-0.0108, -0.0070]],\n",
      "\n",
      "        [[-0.0104, -0.0195]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6855, -0.7009]],\n",
      "\n",
      "        [[-0.6862, -0.7002]],\n",
      "\n",
      "        [[-0.6766, -0.7100]],\n",
      "\n",
      "        [[-0.6977, -0.6886]],\n",
      "\n",
      "        [[-0.7025, -0.6839]],\n",
      "\n",
      "        [[-0.6971, -0.6892]],\n",
      "\n",
      "        [[-0.6777, -0.7089]],\n",
      "\n",
      "        [[-0.6819, -0.7045]],\n",
      "\n",
      "        [[-0.6911, -0.6952]],\n",
      "\n",
      "        [[-0.6946, -0.6917]],\n",
      "\n",
      "        [[-0.7031, -0.6833]],\n",
      "\n",
      "        [[-0.6894, -0.6969]],\n",
      "\n",
      "        [[-0.7014, -0.6850]],\n",
      "\n",
      "        [[-0.6897, -0.6966]],\n",
      "\n",
      "        [[-0.6951, -0.6912]],\n",
      "\n",
      "        [[-0.6886, -0.6977]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0065, -0.0061]],\n",
      "\n",
      "        [[ 0.0350,  0.0428]],\n",
      "\n",
      "        [[ 0.0058, -0.0137]],\n",
      "\n",
      "        [[-0.0146, -0.0207]],\n",
      "\n",
      "        [[ 0.0251,  0.0182]],\n",
      "\n",
      "        [[-0.0209, -0.0247]],\n",
      "\n",
      "        [[-0.0137, -0.0081]],\n",
      "\n",
      "        [[ 0.0387, -0.0040]],\n",
      "\n",
      "        [[ 0.0280,  0.0098]],\n",
      "\n",
      "        [[ 0.0052,  0.0138]],\n",
      "\n",
      "        [[ 0.0298, -0.0035]],\n",
      "\n",
      "        [[ 0.0167,  0.0047]],\n",
      "\n",
      "        [[ 0.0279, -0.0126]],\n",
      "\n",
      "        [[ 0.0221, -0.0107]],\n",
      "\n",
      "        [[-0.0245, -0.0173]],\n",
      "\n",
      "        [[ 0.0198,  0.0096]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6933, -0.6930]],\n",
      "\n",
      "        [[-0.6971, -0.6892]],\n",
      "\n",
      "        [[-0.6834, -0.7030]],\n",
      "\n",
      "        [[-0.6901, -0.6962]],\n",
      "\n",
      "        [[-0.6897, -0.6966]],\n",
      "\n",
      "        [[-0.6912, -0.6951]],\n",
      "\n",
      "        [[-0.6959, -0.6904]],\n",
      "\n",
      "        [[-0.6720, -0.7147]],\n",
      "\n",
      "        [[-0.6841, -0.7023]],\n",
      "\n",
      "        [[-0.6974, -0.6889]],\n",
      "\n",
      "        [[-0.6766, -0.7100]],\n",
      "\n",
      "        [[-0.6871, -0.6992]],\n",
      "\n",
      "        [[-0.6731, -0.7136]],\n",
      "\n",
      "        [[-0.6769, -0.7097]],\n",
      "\n",
      "        [[-0.6968, -0.6895]],\n",
      "\n",
      "        [[-0.6881, -0.6983]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0018, -0.0117]],\n",
      "\n",
      "        [[ 0.0185,  0.0099]],\n",
      "\n",
      "        [[ 0.0053, -0.0269]],\n",
      "\n",
      "        [[ 0.0268,  0.0156]],\n",
      "\n",
      "        [[-0.0082,  0.0190]],\n",
      "\n",
      "        [[ 0.0014, -0.0102]],\n",
      "\n",
      "        [[ 0.0307,  0.0348]],\n",
      "\n",
      "        [[ 0.0371, -0.0061]],\n",
      "\n",
      "        [[ 0.0281,  0.0232]],\n",
      "\n",
      "        [[ 0.0083,  0.0072]],\n",
      "\n",
      "        [[ 0.0328,  0.0302]],\n",
      "\n",
      "        [[ 0.0022, -0.0073]],\n",
      "\n",
      "        [[ 0.0009, -0.0054]],\n",
      "\n",
      "        [[ 0.0029, -0.0081]],\n",
      "\n",
      "        [[ 0.0428,  0.0260]],\n",
      "\n",
      "        [[ 0.0451,  0.0186]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6864, -0.6999]],\n",
      "\n",
      "        [[-0.6889, -0.6974]],\n",
      "\n",
      "        [[-0.6771, -0.7094]],\n",
      "\n",
      "        [[-0.6876, -0.6988]],\n",
      "\n",
      "        [[-0.7069, -0.6796]],\n",
      "\n",
      "        [[-0.6874, -0.6990]],\n",
      "\n",
      "        [[-0.6952, -0.6911]],\n",
      "\n",
      "        [[-0.6718, -0.7150]],\n",
      "\n",
      "        [[-0.6907, -0.6956]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.6919, -0.6944]],\n",
      "\n",
      "        [[-0.6884, -0.6979]],\n",
      "\n",
      "        [[-0.6900, -0.6963]],\n",
      "\n",
      "        [[-0.6877, -0.6987]],\n",
      "\n",
      "        [[-0.6848, -0.7016]],\n",
      "\n",
      "        [[-0.6800, -0.7065]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0178, -0.0341]],\n",
      "\n",
      "        [[ 0.0177, -0.0102]],\n",
      "\n",
      "        [[ 0.0063, -0.0058]],\n",
      "\n",
      "        [[ 0.0188, -0.0111]],\n",
      "\n",
      "        [[-0.0034, -0.0237]],\n",
      "\n",
      "        [[ 0.0472,  0.0528]],\n",
      "\n",
      "        [[ 0.0008, -0.0199]],\n",
      "\n",
      "        [[-0.0005, -0.0097]],\n",
      "\n",
      "        [[ 0.0050,  0.0040]],\n",
      "\n",
      "        [[ 0.0117, -0.0022]],\n",
      "\n",
      "        [[ 0.0134,  0.0046]],\n",
      "\n",
      "        [[-0.0108, -0.0271]],\n",
      "\n",
      "        [[ 0.0340,  0.0230]],\n",
      "\n",
      "        [[ 0.0244,  0.0006]],\n",
      "\n",
      "        [[ 0.0113, -0.0091]],\n",
      "\n",
      "        [[-0.0013,  0.0049]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6676, -0.7194]],\n",
      "\n",
      "        [[-0.6793, -0.7072]],\n",
      "\n",
      "        [[-0.6871, -0.6992]],\n",
      "\n",
      "        [[-0.6783, -0.7082]],\n",
      "\n",
      "        [[-0.6830, -0.7034]],\n",
      "\n",
      "        [[-0.6960, -0.6903]],\n",
      "\n",
      "        [[-0.6829, -0.7035]],\n",
      "\n",
      "        [[-0.6885, -0.6978]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.6862, -0.7001]],\n",
      "\n",
      "        [[-0.6888, -0.6975]],\n",
      "\n",
      "        [[-0.6850, -0.7014]],\n",
      "\n",
      "        [[-0.6877, -0.6987]],\n",
      "\n",
      "        [[-0.6813, -0.7051]],\n",
      "\n",
      "        [[-0.6830, -0.7034]],\n",
      "\n",
      "        [[-0.6963, -0.6900]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0381,  0.0267]],\n",
      "\n",
      "        [[ 0.0175, -0.0274]],\n",
      "\n",
      "        [[ 0.0506,  0.0230]],\n",
      "\n",
      "        [[ 0.0073,  0.0084]],\n",
      "\n",
      "        [[-0.0172, -0.0115]],\n",
      "\n",
      "        [[ 0.0172, -0.0020]],\n",
      "\n",
      "        [[ 0.0223,  0.0169]],\n",
      "\n",
      "        [[ 0.0080,  0.0044]],\n",
      "\n",
      "        [[ 0.0039,  0.0172]],\n",
      "\n",
      "        [[-0.0132, -0.0201]],\n",
      "\n",
      "        [[ 0.0051, -0.0242]],\n",
      "\n",
      "        [[ 0.0388,  0.0267]],\n",
      "\n",
      "        [[-0.0011, -0.0301]],\n",
      "\n",
      "        [[ 0.0500,  0.0054]],\n",
      "\n",
      "        [[-0.0175, -0.0091]],\n",
      "\n",
      "        [[ 0.0448,  0.0070]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6875, -0.6989]],\n",
      "\n",
      "        [[-0.6710, -0.7158]],\n",
      "\n",
      "        [[-0.6794, -0.7071]],\n",
      "\n",
      "        [[-0.6937, -0.6926]],\n",
      "\n",
      "        [[-0.6960, -0.6903]],\n",
      "\n",
      "        [[-0.6836, -0.7028]],\n",
      "\n",
      "        [[-0.6904, -0.6959]],\n",
      "\n",
      "        [[-0.6914, -0.6949]],\n",
      "\n",
      "        [[-0.6998, -0.6865]],\n",
      "\n",
      "        [[-0.6897, -0.6966]],\n",
      "\n",
      "        [[-0.6786, -0.7079]],\n",
      "\n",
      "        [[-0.6871, -0.6992]],\n",
      "\n",
      "        [[-0.6787, -0.7078]],\n",
      "\n",
      "        [[-0.6711, -0.7157]],\n",
      "\n",
      "        [[-0.6973, -0.6890]],\n",
      "\n",
      "        [[-0.6744, -0.7122]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0094, -0.0057]],\n",
      "\n",
      "        [[-0.0048, -0.0201]],\n",
      "\n",
      "        [[ 0.0500,  0.0271]],\n",
      "\n",
      "        [[ 0.0166, -0.0106]],\n",
      "\n",
      "        [[-0.0057, -0.0347]],\n",
      "\n",
      "        [[ 0.0260,  0.0034]],\n",
      "\n",
      "        [[ 0.0083, -0.0024]],\n",
      "\n",
      "        [[-0.0145, -0.0106]],\n",
      "\n",
      "        [[ 0.0178,  0.0014]],\n",
      "\n",
      "        [[ 0.0511,  0.0310]],\n",
      "\n",
      "        [[ 0.0114, -0.0072]],\n",
      "\n",
      "        [[ 0.0146, -0.0175]],\n",
      "\n",
      "        [[ 0.0520,  0.0337]],\n",
      "\n",
      "        [[ 0.0106,  0.0095]],\n",
      "\n",
      "        [[ 0.0149, -0.0215]],\n",
      "\n",
      "        [[ 0.0093, -0.0098]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6856, -0.7008]],\n",
      "\n",
      "        [[-0.6856, -0.7008]],\n",
      "\n",
      "        [[-0.6818, -0.7047]],\n",
      "\n",
      "        [[-0.6796, -0.7068]],\n",
      "\n",
      "        [[-0.6788, -0.7077]],\n",
      "\n",
      "        [[-0.6819, -0.7045]],\n",
      "\n",
      "        [[-0.6878, -0.6985]],\n",
      "\n",
      "        [[-0.6951, -0.6912]],\n",
      "\n",
      "        [[-0.6850, -0.7014]],\n",
      "\n",
      "        [[-0.6832, -0.7032]],\n",
      "\n",
      "        [[-0.6839, -0.7025]],\n",
      "\n",
      "        [[-0.6772, -0.7093]],\n",
      "\n",
      "        [[-0.6840, -0.7023]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.6751, -0.7115]],\n",
      "\n",
      "        [[-0.6837, -0.7027]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 2.5586e-02,  1.5736e-02]],\n",
      "\n",
      "        [[ 3.4855e-02,  1.2600e-02]],\n",
      "\n",
      "        [[ 5.9008e-02,  1.1786e-02]],\n",
      "\n",
      "        [[-1.2750e-02, -1.1323e-02]],\n",
      "\n",
      "        [[ 1.3934e-02,  6.4633e-03]],\n",
      "\n",
      "        [[ 8.4291e-03, -9.4337e-03]],\n",
      "\n",
      "        [[ 7.0727e-03, -2.4671e-02]],\n",
      "\n",
      "        [[ 5.3848e-03, -3.1706e-03]],\n",
      "\n",
      "        [[-5.8686e-03, -1.6416e-02]],\n",
      "\n",
      "        [[ 4.3284e-02, -5.8688e-05]],\n",
      "\n",
      "        [[ 2.8555e-03, -2.5469e-02]],\n",
      "\n",
      "        [[ 1.7775e-02,  1.3342e-03]],\n",
      "\n",
      "        [[ 1.2845e-02, -2.5360e-02]],\n",
      "\n",
      "        [[ 3.0064e-03, -1.3160e-02]],\n",
      "\n",
      "        [[ 1.5323e-02, -5.4276e-03]],\n",
      "\n",
      "        [[ 2.9925e-02,  5.3593e-03]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6882, -0.6981]],\n",
      "\n",
      "        [[-0.6821, -0.7043]],\n",
      "\n",
      "        [[-0.6698, -0.7170]],\n",
      "\n",
      "        [[-0.6939, -0.6924]],\n",
      "\n",
      "        [[-0.6894, -0.6969]],\n",
      "\n",
      "        [[-0.6843, -0.7021]],\n",
      "\n",
      "        [[-0.6774, -0.7091]],\n",
      "\n",
      "        [[-0.6889, -0.6974]],\n",
      "\n",
      "        [[-0.6879, -0.6984]],\n",
      "\n",
      "        [[-0.6717, -0.7151]],\n",
      "\n",
      "        [[-0.6791, -0.7074]],\n",
      "\n",
      "        [[-0.6850, -0.7014]],\n",
      "\n",
      "        [[-0.6742, -0.7124]],\n",
      "\n",
      "        [[-0.6851, -0.7013]],\n",
      "\n",
      "        [[-0.6828, -0.7036]],\n",
      "\n",
      "        [[-0.6809, -0.7055]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0319, -0.0035]],\n",
      "\n",
      "        [[-0.0040, -0.0095]],\n",
      "\n",
      "        [[ 0.0058,  0.0017]],\n",
      "\n",
      "        [[-0.0091, -0.0109]],\n",
      "\n",
      "        [[ 0.0011, -0.0157]],\n",
      "\n",
      "        [[ 0.0197, -0.0147]],\n",
      "\n",
      "        [[ 0.0181,  0.0067]],\n",
      "\n",
      "        [[-0.0081, -0.0236]],\n",
      "\n",
      "        [[ 0.0142,  0.0048]],\n",
      "\n",
      "        [[ 0.0137, -0.0009]],\n",
      "\n",
      "        [[ 0.0381,  0.0025]],\n",
      "\n",
      "        [[ 0.0535,  0.0263]],\n",
      "\n",
      "        [[-0.0223, -0.0420]],\n",
      "\n",
      "        [[ 0.0027,  0.0102]],\n",
      "\n",
      "        [[ 0.0142, -0.0170]],\n",
      "\n",
      "        [[ 0.0006,  0.0002]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6756, -0.7110]],\n",
      "\n",
      "        [[-0.6904, -0.6959]],\n",
      "\n",
      "        [[-0.6911, -0.6952]],\n",
      "\n",
      "        [[-0.6922, -0.6940]],\n",
      "\n",
      "        [[-0.6848, -0.7016]],\n",
      "\n",
      "        [[-0.6761, -0.7105]],\n",
      "\n",
      "        [[-0.6875, -0.6989]],\n",
      "\n",
      "        [[-0.6854, -0.7009]],\n",
      "\n",
      "        [[-0.6884, -0.6979]],\n",
      "\n",
      "        [[-0.6858, -0.7005]],\n",
      "\n",
      "        [[-0.6755, -0.7111]],\n",
      "\n",
      "        [[-0.6797, -0.7068]],\n",
      "\n",
      "        [[-0.6834, -0.7030]],\n",
      "\n",
      "        [[-0.6969, -0.6894]],\n",
      "\n",
      "        [[-0.6776, -0.7089]],\n",
      "\n",
      "        [[-0.6929, -0.6933]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0009, -0.0100]],\n",
      "\n",
      "        [[-0.0025, -0.0048]],\n",
      "\n",
      "        [[ 0.0260, -0.0274]],\n",
      "\n",
      "        [[ 0.0135, -0.0056]],\n",
      "\n",
      "        [[ 0.0232,  0.0169]],\n",
      "\n",
      "        [[-0.0367, -0.0263]],\n",
      "\n",
      "        [[ 0.0035,  0.0201]],\n",
      "\n",
      "        [[-0.0170, -0.0313]],\n",
      "\n",
      "        [[-0.0088, -0.0037]],\n",
      "\n",
      "        [[ 0.0287,  0.0433]],\n",
      "\n",
      "        [[ 0.0270,  0.0070]],\n",
      "\n",
      "        [[-0.0065, -0.0257]],\n",
      "\n",
      "        [[-0.0029, -0.0296]],\n",
      "\n",
      "        [[ 0.0264,  0.0401]],\n",
      "\n",
      "        [[ 0.0517,  0.0288]],\n",
      "\n",
      "        [[-0.0187, -0.0023]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6886, -0.6977]],\n",
      "\n",
      "        [[-0.6920, -0.6943]],\n",
      "\n",
      "        [[-0.6668, -0.7202]],\n",
      "\n",
      "        [[-0.6836, -0.7028]],\n",
      "\n",
      "        [[-0.6900, -0.6963]],\n",
      "\n",
      "        [[-0.6984, -0.6880]],\n",
      "\n",
      "        [[-0.7014, -0.6849]],\n",
      "\n",
      "        [[-0.6860, -0.7003]],\n",
      "\n",
      "        [[-0.6957, -0.6906]],\n",
      "\n",
      "        [[-0.7005, -0.6859]],\n",
      "\n",
      "        [[-0.6832, -0.7032]],\n",
      "\n",
      "        [[-0.6836, -0.7028]],\n",
      "\n",
      "        [[-0.6799, -0.7066]],\n",
      "\n",
      "        [[-0.7000, -0.6863]],\n",
      "\n",
      "        [[-0.6818, -0.7046]],\n",
      "\n",
      "        [[-0.7014, -0.6850]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0213,  0.0003]],\n",
      "\n",
      "        [[ 0.0066,  0.0080]],\n",
      "\n",
      "        [[-0.0176, -0.0143]],\n",
      "\n",
      "        [[ 0.0026, -0.0258]],\n",
      "\n",
      "        [[ 0.0228, -0.0171]],\n",
      "\n",
      "        [[-0.0034, -0.0122]],\n",
      "\n",
      "        [[ 0.0112, -0.0101]],\n",
      "\n",
      "        [[ 0.0629,  0.0366]],\n",
      "\n",
      "        [[-0.0268, -0.0255]],\n",
      "\n",
      "        [[ 0.0266, -0.0121]],\n",
      "\n",
      "        [[ 0.0002, -0.0238]],\n",
      "\n",
      "        [[ 0.0578,  0.0253]],\n",
      "\n",
      "        [[-0.0205, -0.0158]],\n",
      "\n",
      "        [[-0.0154, -0.0282]],\n",
      "\n",
      "        [[ 0.0115,  0.0297]],\n",
      "\n",
      "        [[-0.0004,  0.0049]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6828, -0.7037]],\n",
      "\n",
      "        [[-0.6939, -0.6924]],\n",
      "\n",
      "        [[-0.6948, -0.6915]],\n",
      "\n",
      "        [[-0.6790, -0.7075]],\n",
      "\n",
      "        [[-0.6734, -0.7133]],\n",
      "\n",
      "        [[-0.6887, -0.6976]],\n",
      "\n",
      "        [[-0.6826, -0.7038]],\n",
      "\n",
      "        [[-0.6801, -0.7064]],\n",
      "\n",
      "        [[-0.6938, -0.6925]],\n",
      "\n",
      "        [[-0.6740, -0.7126]],\n",
      "\n",
      "        [[-0.6812, -0.7052]],\n",
      "\n",
      "        [[-0.6770, -0.7095]],\n",
      "\n",
      "        [[-0.6955, -0.6908]],\n",
      "\n",
      "        [[-0.6868, -0.6996]],\n",
      "\n",
      "        [[-0.7023, -0.6841]],\n",
      "\n",
      "        [[-0.6958, -0.6905]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0092,  0.0014]],\n",
      "\n",
      "        [[ 0.0589,  0.0324]],\n",
      "\n",
      "        [[ 0.0396,  0.0183]],\n",
      "\n",
      "        [[ 0.0070, -0.0145]],\n",
      "\n",
      "        [[ 0.0157, -0.0048]],\n",
      "\n",
      "        [[ 0.0590,  0.0190]],\n",
      "\n",
      "        [[-0.0161, -0.0386]],\n",
      "\n",
      "        [[-0.0040, -0.0072]],\n",
      "\n",
      "        [[ 0.0120, -0.0233]],\n",
      "\n",
      "        [[ 0.0609,  0.0114]],\n",
      "\n",
      "        [[ 0.0041, -0.0029]],\n",
      "\n",
      "        [[ 0.0109, -0.0032]],\n",
      "\n",
      "        [[ 0.0418,  0.0351]],\n",
      "\n",
      "        [[ 0.0567,  0.0234]],\n",
      "\n",
      "        [[ 0.0193,  0.0362]],\n",
      "\n",
      "        [[ 0.0059, -0.0127]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6893, -0.6970]],\n",
      "\n",
      "        [[-0.6800, -0.7065]],\n",
      "\n",
      "        [[-0.6825, -0.7039]],\n",
      "\n",
      "        [[-0.6824, -0.7040]],\n",
      "\n",
      "        [[-0.6829, -0.7035]],\n",
      "\n",
      "        [[-0.6733, -0.7133]],\n",
      "\n",
      "        [[-0.6819, -0.7045]],\n",
      "\n",
      "        [[-0.6915, -0.6948]],\n",
      "\n",
      "        [[-0.6756, -0.7110]],\n",
      "\n",
      "        [[-0.6687, -0.7182]],\n",
      "\n",
      "        [[-0.6897, -0.6966]],\n",
      "\n",
      "        [[-0.6861, -0.7002]],\n",
      "\n",
      "        [[-0.6898, -0.6965]],\n",
      "\n",
      "        [[-0.6766, -0.7099]],\n",
      "\n",
      "        [[-0.7017, -0.6847]],\n",
      "\n",
      "        [[-0.6839, -0.7025]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0286, -0.0093]],\n",
      "\n",
      "        [[ 0.0192,  0.0167]],\n",
      "\n",
      "        [[ 0.0010, -0.0122]],\n",
      "\n",
      "        [[-0.0050, -0.0313]],\n",
      "\n",
      "        [[-0.0138, -0.0144]],\n",
      "\n",
      "        [[ 0.0025,  0.0111]],\n",
      "\n",
      "        [[ 0.0127, -0.0183]],\n",
      "\n",
      "        [[ 0.0454,  0.0342]],\n",
      "\n",
      "        [[ 0.0270,  0.0296]],\n",
      "\n",
      "        [[ 0.0116, -0.0083]],\n",
      "\n",
      "        [[ 0.0024, -0.0079]],\n",
      "\n",
      "        [[ 0.0265, -0.0006]],\n",
      "\n",
      "        [[ 0.0049, -0.0276]],\n",
      "\n",
      "        [[ 0.0332,  0.0148]],\n",
      "\n",
      "        [[ 0.0262, -0.0154]],\n",
      "\n",
      "        [[-0.0072, -0.0389]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6744, -0.7122]],\n",
      "\n",
      "        [[-0.6919, -0.6944]],\n",
      "\n",
      "        [[-0.6866, -0.6998]],\n",
      "\n",
      "        [[-0.6801, -0.7064]],\n",
      "\n",
      "        [[-0.6928, -0.6934]],\n",
      "\n",
      "        [[-0.6975, -0.6888]],\n",
      "\n",
      "        [[-0.6778, -0.7087]],\n",
      "\n",
      "        [[-0.6876, -0.6988]],\n",
      "\n",
      "        [[-0.6944, -0.6919]],\n",
      "\n",
      "        [[-0.6833, -0.7031]],\n",
      "\n",
      "        [[-0.6880, -0.6983]],\n",
      "\n",
      "        [[-0.6797, -0.7068]],\n",
      "\n",
      "        [[-0.6770, -0.7095]],\n",
      "\n",
      "        [[-0.6840, -0.7024]],\n",
      "\n",
      "        [[-0.6726, -0.7142]],\n",
      "\n",
      "        [[-0.6774, -0.7091]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0578,  0.0262]],\n",
      "\n",
      "        [[ 0.0078, -0.0058]],\n",
      "\n",
      "        [[ 0.0346,  0.0160]],\n",
      "\n",
      "        [[-0.0009, -0.0080]],\n",
      "\n",
      "        [[-0.0079, -0.0134]],\n",
      "\n",
      "        [[ 0.0076, -0.0030]],\n",
      "\n",
      "        [[ 0.0151,  0.0150]],\n",
      "\n",
      "        [[ 0.0194,  0.0021]],\n",
      "\n",
      "        [[ 0.0095,  0.0182]],\n",
      "\n",
      "        [[ 0.0295, -0.0069]],\n",
      "\n",
      "        [[ 0.0525,  0.0516]],\n",
      "\n",
      "        [[-0.0146,  0.0008]],\n",
      "\n",
      "        [[ 0.0295,  0.0164]],\n",
      "\n",
      "        [[ 0.0071, -0.0014]],\n",
      "\n",
      "        [[ 0.0375,  0.0199]],\n",
      "\n",
      "        [[ 0.0275, -0.0202]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6775, -0.7091]],\n",
      "\n",
      "        [[-0.6863, -0.7000]],\n",
      "\n",
      "        [[-0.6839, -0.7025]],\n",
      "\n",
      "        [[-0.6896, -0.6967]],\n",
      "\n",
      "        [[-0.6904, -0.6959]],\n",
      "\n",
      "        [[-0.6879, -0.6984]],\n",
      "\n",
      "        [[-0.6931, -0.6932]],\n",
      "\n",
      "        [[-0.6845, -0.7019]],\n",
      "\n",
      "        [[-0.6975, -0.6888]],\n",
      "\n",
      "        [[-0.6751, -0.7115]],\n",
      "\n",
      "        [[-0.6927, -0.6936]],\n",
      "\n",
      "        [[-0.7009, -0.6855]],\n",
      "\n",
      "        [[-0.6866, -0.6997]],\n",
      "\n",
      "        [[-0.6889, -0.6974]],\n",
      "\n",
      "        [[-0.6844, -0.7020]],\n",
      "\n",
      "        [[-0.6696, -0.7173]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0152, -0.0066]],\n",
      "\n",
      "        [[ 0.0502,  0.0296]],\n",
      "\n",
      "        [[-0.0247, -0.0267]],\n",
      "\n",
      "        [[ 0.0350, -0.0035]],\n",
      "\n",
      "        [[-0.0058, -0.0067]],\n",
      "\n",
      "        [[ 0.0180,  0.0118]],\n",
      "\n",
      "        [[ 0.0331,  0.0141]],\n",
      "\n",
      "        [[ 0.0370,  0.0100]],\n",
      "\n",
      "        [[ 0.0158, -0.0154]],\n",
      "\n",
      "        [[ 0.0383,  0.0114]],\n",
      "\n",
      "        [[ 0.0116,  0.0004]],\n",
      "\n",
      "        [[-0.0144, -0.0040]],\n",
      "\n",
      "        [[-0.0041, -0.0223]],\n",
      "\n",
      "        [[ 0.0196,  0.0069]],\n",
      "\n",
      "        [[-0.0096, -0.0130]],\n",
      "\n",
      "        [[ 0.0292, -0.0042]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6975, -0.6888]],\n",
      "\n",
      "        [[-0.6829, -0.7035]],\n",
      "\n",
      "        [[-0.6921, -0.6942]],\n",
      "\n",
      "        [[-0.6741, -0.7126]],\n",
      "\n",
      "        [[-0.6927, -0.6936]],\n",
      "\n",
      "        [[-0.6900, -0.6963]],\n",
      "\n",
      "        [[-0.6837, -0.7027]],\n",
      "\n",
      "        [[-0.6797, -0.7067]],\n",
      "\n",
      "        [[-0.6777, -0.7089]],\n",
      "\n",
      "        [[-0.6798, -0.7067]],\n",
      "\n",
      "        [[-0.6875, -0.6988]],\n",
      "\n",
      "        [[-0.6984, -0.6879]],\n",
      "\n",
      "        [[-0.6841, -0.7023]],\n",
      "\n",
      "        [[-0.6868, -0.6995]],\n",
      "\n",
      "        [[-0.6914, -0.6949]],\n",
      "\n",
      "        [[-0.6766, -0.7100]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-5.2648e-03, -8.8990e-03]],\n",
      "\n",
      "        [[-3.0667e-03, -2.2381e-02]],\n",
      "\n",
      "        [[ 3.9506e-02,  6.6914e-03]],\n",
      "\n",
      "        [[-5.6989e-03, -1.8727e-03]],\n",
      "\n",
      "        [[ 1.8200e-02,  2.2453e-02]],\n",
      "\n",
      "        [[ 4.9536e-02,  1.8733e-02]],\n",
      "\n",
      "        [[-1.0386e-02, -1.4860e-03]],\n",
      "\n",
      "        [[-2.2880e-02, -1.1761e-02]],\n",
      "\n",
      "        [[ 3.3839e-02,  2.4695e-03]],\n",
      "\n",
      "        [[-8.4438e-03,  1.2916e-03]],\n",
      "\n",
      "        [[-1.2063e-02, -8.5335e-05]],\n",
      "\n",
      "        [[ 6.1505e-06,  2.3693e-02]],\n",
      "\n",
      "        [[-1.2756e-02, -1.3845e-02]],\n",
      "\n",
      "        [[ 2.0039e-02, -8.4022e-03]],\n",
      "\n",
      "        [[ 1.5868e-02, -1.0047e-02]],\n",
      "\n",
      "        [[-1.3518e-02, -3.3558e-03]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6913, -0.6950]],\n",
      "\n",
      "        [[-0.6835, -0.7029]],\n",
      "\n",
      "        [[-0.6769, -0.7097]],\n",
      "\n",
      "        [[-0.6951, -0.6912]],\n",
      "\n",
      "        [[-0.6953, -0.6910]],\n",
      "\n",
      "        [[-0.6779, -0.7087]],\n",
      "\n",
      "        [[-0.6976, -0.6887]],\n",
      "\n",
      "        [[-0.6987, -0.6876]],\n",
      "\n",
      "        [[-0.6776, -0.7090]],\n",
      "\n",
      "        [[-0.6980, -0.6883]],\n",
      "\n",
      "        [[-0.6992, -0.6872]],\n",
      "\n",
      "        [[-0.7051, -0.6814]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.6790, -0.7075]],\n",
      "\n",
      "        [[-0.6803, -0.7062]],\n",
      "\n",
      "        [[-0.6982, -0.6881]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0073,  0.0168]],\n",
      "\n",
      "        [[ 0.0332, -0.0048]],\n",
      "\n",
      "        [[ 0.0594,  0.0151]],\n",
      "\n",
      "        [[-0.0031, -0.0098]],\n",
      "\n",
      "        [[ 0.0035,  0.0164]],\n",
      "\n",
      "        [[-0.0036,  0.0194]],\n",
      "\n",
      "        [[ 0.0316,  0.0248]],\n",
      "\n",
      "        [[ 0.0008,  0.0248]],\n",
      "\n",
      "        [[ 0.0279, -0.0050]],\n",
      "\n",
      "        [[-0.0003, -0.0085]],\n",
      "\n",
      "        [[ 0.0187,  0.0260]],\n",
      "\n",
      "        [[ 0.0109, -0.0178]],\n",
      "\n",
      "        [[-0.0236, -0.0026]],\n",
      "\n",
      "        [[ 0.0424,  0.0273]],\n",
      "\n",
      "        [[-0.0185,  0.0163]],\n",
      "\n",
      "        [[ 0.0205,  0.0050]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6979, -0.6884]],\n",
      "\n",
      "        [[-0.6744, -0.7123]],\n",
      "\n",
      "        [[-0.6712, -0.7156]],\n",
      "\n",
      "        [[-0.6898, -0.6965]],\n",
      "\n",
      "        [[-0.6996, -0.6867]],\n",
      "\n",
      "        [[-0.7047, -0.6817]],\n",
      "\n",
      "        [[-0.6898, -0.6965]],\n",
      "\n",
      "        [[-0.7053, -0.6812]],\n",
      "\n",
      "        [[-0.6768, -0.7097]],\n",
      "\n",
      "        [[-0.6890, -0.6973]],\n",
      "\n",
      "        [[-0.6968, -0.6895]],\n",
      "\n",
      "        [[-0.6789, -0.7076]],\n",
      "\n",
      "        [[-0.7037, -0.6827]],\n",
      "\n",
      "        [[-0.6856, -0.7007]],\n",
      "\n",
      "        [[-0.7107, -0.6759]],\n",
      "\n",
      "        [[-0.6854, -0.7010]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0182,  0.0094]],\n",
      "\n",
      "        [[ 0.0028, -0.0062]],\n",
      "\n",
      "        [[ 0.0145,  0.0207]],\n",
      "\n",
      "        [[ 0.0077,  0.0364]],\n",
      "\n",
      "        [[ 0.0139,  0.0122]],\n",
      "\n",
      "        [[ 0.0437,  0.0307]],\n",
      "\n",
      "        [[ 0.0037,  0.0063]],\n",
      "\n",
      "        [[-0.0216,  0.0240]],\n",
      "\n",
      "        [[-0.0220,  0.0046]],\n",
      "\n",
      "        [[-0.0055,  0.0226]],\n",
      "\n",
      "        [[-0.0169,  0.0024]],\n",
      "\n",
      "        [[-0.0325, -0.0056]],\n",
      "\n",
      "        [[-0.0134, -0.0009]],\n",
      "\n",
      "        [[-0.0080,  0.0117]],\n",
      "\n",
      "        [[ 0.0212,  0.0078]],\n",
      "\n",
      "        [[-0.0391, -0.0249]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6888, -0.6976]],\n",
      "\n",
      "        [[-0.6886, -0.6977]],\n",
      "\n",
      "        [[-0.6962, -0.6901]],\n",
      "\n",
      "        [[-0.7076, -0.6789]],\n",
      "\n",
      "        [[-0.6923, -0.6940]],\n",
      "\n",
      "        [[-0.6867, -0.6997]],\n",
      "\n",
      "        [[-0.6945, -0.6918]],\n",
      "\n",
      "        [[-0.7162, -0.6706]],\n",
      "\n",
      "        [[-0.7065, -0.6799]],\n",
      "\n",
      "        [[-0.7073, -0.6792]],\n",
      "\n",
      "        [[-0.7029, -0.6835]],\n",
      "\n",
      "        [[-0.7067, -0.6798]],\n",
      "\n",
      "        [[-0.6994, -0.6869]],\n",
      "\n",
      "        [[-0.7031, -0.6833]],\n",
      "\n",
      "        [[-0.6865, -0.6999]],\n",
      "\n",
      "        [[-0.7003, -0.6861]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0034,  0.0152]],\n",
      "\n",
      "        [[-0.0420, -0.0083]],\n",
      "\n",
      "        [[-0.0074,  0.0265]],\n",
      "\n",
      "        [[-0.0471, -0.0102]],\n",
      "\n",
      "        [[-0.0173,  0.0028]],\n",
      "\n",
      "        [[-0.0157, -0.0090]],\n",
      "\n",
      "        [[ 0.0052,  0.0055]],\n",
      "\n",
      "        [[-0.0302, -0.0046]],\n",
      "\n",
      "        [[ 0.0070,  0.0027]],\n",
      "\n",
      "        [[-0.0089,  0.0092]],\n",
      "\n",
      "        [[-0.0276, -0.0079]],\n",
      "\n",
      "        [[-0.0097,  0.0028]],\n",
      "\n",
      "        [[ 0.0296,  0.0141]],\n",
      "\n",
      "        [[-0.0107,  0.0193]],\n",
      "\n",
      "        [[ 0.0274,  0.0244]],\n",
      "\n",
      "        [[-0.0206, -0.0100]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7025, -0.6839]],\n",
      "\n",
      "        [[-0.7101, -0.6765]],\n",
      "\n",
      "        [[-0.7103, -0.6763]],\n",
      "\n",
      "        [[-0.7117, -0.6749]],\n",
      "\n",
      "        [[-0.7033, -0.6831]],\n",
      "\n",
      "        [[-0.6965, -0.6898]],\n",
      "\n",
      "        [[-0.6933, -0.6930]],\n",
      "\n",
      "        [[-0.7060, -0.6804]],\n",
      "\n",
      "        [[-0.6910, -0.6953]],\n",
      "\n",
      "        [[-0.7023, -0.6841]],\n",
      "\n",
      "        [[-0.7031, -0.6833]],\n",
      "\n",
      "        [[-0.6994, -0.6869]],\n",
      "\n",
      "        [[-0.6854, -0.7010]],\n",
      "\n",
      "        [[-0.7083, -0.6782]],\n",
      "\n",
      "        [[-0.6917, -0.6946]],\n",
      "\n",
      "        [[-0.6985, -0.6879]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0067,  0.0447]],\n",
      "\n",
      "        [[-0.0156,  0.0194]],\n",
      "\n",
      "        [[-0.0037, -0.0040]],\n",
      "\n",
      "        [[ 0.0114,  0.0332]],\n",
      "\n",
      "        [[-0.0020, -0.0131]],\n",
      "\n",
      "        [[-0.0170, -0.0112]],\n",
      "\n",
      "        [[-0.0097,  0.0045]],\n",
      "\n",
      "        [[-0.0437,  0.0026]],\n",
      "\n",
      "        [[-0.0364, -0.0074]],\n",
      "\n",
      "        [[-0.0215, -0.0039]],\n",
      "\n",
      "        [[-0.0424, -0.0059]],\n",
      "\n",
      "        [[-0.0508, -0.0032]],\n",
      "\n",
      "        [[-0.0339,  0.0150]],\n",
      "\n",
      "        [[-0.0193,  0.0086]],\n",
      "\n",
      "        [[ 0.0124,  0.0161]],\n",
      "\n",
      "        [[-0.0143,  0.0261]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7123, -0.6743]],\n",
      "\n",
      "        [[-0.7108, -0.6758]],\n",
      "\n",
      "        [[-0.6930, -0.6933]],\n",
      "\n",
      "        [[-0.7041, -0.6823]],\n",
      "\n",
      "        [[-0.6876, -0.6987]],\n",
      "\n",
      "        [[-0.6961, -0.6902]],\n",
      "\n",
      "        [[-0.7003, -0.6861]],\n",
      "\n",
      "        [[-0.7166, -0.6703]],\n",
      "\n",
      "        [[-0.7078, -0.6787]],\n",
      "\n",
      "        [[-0.7020, -0.6844]],\n",
      "\n",
      "        [[-0.7115, -0.6751]],\n",
      "\n",
      "        [[-0.7173, -0.6696]],\n",
      "\n",
      "        [[-0.7179, -0.6690]],\n",
      "\n",
      "        [[-0.7072, -0.6793]],\n",
      "\n",
      "        [[-0.6950, -0.6913]],\n",
      "\n",
      "        [[-0.7135, -0.6732]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0260,  0.0066]],\n",
      "\n",
      "        [[-0.0010,  0.0047]],\n",
      "\n",
      "        [[-0.0285, -0.0281]],\n",
      "\n",
      "        [[-0.0474, -0.0115]],\n",
      "\n",
      "        [[-0.0219,  0.0339]],\n",
      "\n",
      "        [[ 0.0059,  0.0212]],\n",
      "\n",
      "        [[-0.0146,  0.0111]],\n",
      "\n",
      "        [[-0.0065, -0.0084]],\n",
      "\n",
      "        [[-0.0106,  0.0205]],\n",
      "\n",
      "        [[-0.0037, -0.0119]],\n",
      "\n",
      "        [[-0.0194, -0.0111]],\n",
      "\n",
      "        [[-0.0257, -0.0054]],\n",
      "\n",
      "        [[ 0.0023,  0.0101]],\n",
      "\n",
      "        [[ 0.0193,  0.0141]],\n",
      "\n",
      "        [[-0.0155,  0.0173]],\n",
      "\n",
      "        [[-0.0256,  0.0486]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7096, -0.6770]],\n",
      "\n",
      "        [[-0.6960, -0.6903]],\n",
      "\n",
      "        [[-0.6934, -0.6929]],\n",
      "\n",
      "        [[-0.7113, -0.6753]],\n",
      "\n",
      "        [[-0.7214, -0.6656]],\n",
      "\n",
      "        [[-0.7008, -0.6856]],\n",
      "\n",
      "        [[-0.7061, -0.6804]],\n",
      "\n",
      "        [[-0.6922, -0.6941]],\n",
      "\n",
      "        [[-0.7088, -0.6777]],\n",
      "\n",
      "        [[-0.6890, -0.6973]],\n",
      "\n",
      "        [[-0.6973, -0.6890]],\n",
      "\n",
      "        [[-0.7033, -0.6831]],\n",
      "\n",
      "        [[-0.6970, -0.6893]],\n",
      "\n",
      "        [[-0.6906, -0.6957]],\n",
      "\n",
      "        [[-0.7097, -0.6769]],\n",
      "\n",
      "        [[-0.7310, -0.6567]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-2.8148e-05, -8.7837e-03]],\n",
      "\n",
      "        [[-2.2836e-02, -3.0081e-03]],\n",
      "\n",
      "        [[-4.7591e-02, -1.7421e-02]],\n",
      "\n",
      "        [[ 4.3820e-02,  2.4502e-03]],\n",
      "\n",
      "        [[-6.3327e-04,  4.6953e-02]],\n",
      "\n",
      "        [[-3.3841e-02,  2.1960e-03]],\n",
      "\n",
      "        [[ 1.6592e-05,  1.0316e-02]],\n",
      "\n",
      "        [[-1.2863e-02, -4.5071e-03]],\n",
      "\n",
      "        [[-3.2845e-03, -1.4691e-03]],\n",
      "\n",
      "        [[-9.9973e-03,  1.3659e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6888, -0.6975]],\n",
      "\n",
      "        [[-0.7031, -0.6833]],\n",
      "\n",
      "        [[-0.7083, -0.6782]],\n",
      "\n",
      "        [[-0.6727, -0.7140]],\n",
      "\n",
      "        [[-0.7172, -0.6696]],\n",
      "\n",
      "        [[-0.7113, -0.6753]],\n",
      "\n",
      "        [[-0.6983, -0.6880]],\n",
      "\n",
      "        [[-0.6973, -0.6890]],\n",
      "\n",
      "        [[-0.6941, -0.6922]],\n",
      "\n",
      "        [[-0.7050, -0.6814]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0106,  0.0164]],\n",
      "\n",
      "        [[-0.0330, -0.0153]],\n",
      "\n",
      "        [[ 0.0020, -0.0096]],\n",
      "\n",
      "        [[-0.0116, -0.0019]],\n",
      "\n",
      "        [[ 0.0270,  0.0187]],\n",
      "\n",
      "        [[ 0.0120,  0.0212]],\n",
      "\n",
      "        [[-0.0199, -0.0213]],\n",
      "\n",
      "        [[-0.0207, -0.0075]],\n",
      "\n",
      "        [[-0.0057,  0.0172]],\n",
      "\n",
      "        [[ 0.0208,  0.0319]],\n",
      "\n",
      "        [[-0.0030,  0.0084]],\n",
      "\n",
      "        [[ 0.0276,  0.0379]],\n",
      "\n",
      "        [[-0.0325, -0.0009]],\n",
      "\n",
      "        [[-0.0090, -0.0032]],\n",
      "\n",
      "        [[ 0.0212,  0.0394]],\n",
      "\n",
      "        [[ 0.0052,  0.0142]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7068, -0.6797]],\n",
      "\n",
      "        [[-0.7020, -0.6844]],\n",
      "\n",
      "        [[-0.6873, -0.6990]],\n",
      "\n",
      "        [[-0.6980, -0.6883]],\n",
      "\n",
      "        [[-0.6890, -0.6973]],\n",
      "\n",
      "        [[-0.6978, -0.6886]],\n",
      "\n",
      "        [[-0.6924, -0.6939]],\n",
      "\n",
      "        [[-0.6998, -0.6866]],\n",
      "\n",
      "        [[-0.7047, -0.6818]],\n",
      "\n",
      "        [[-0.6987, -0.6876]],\n",
      "\n",
      "        [[-0.6988, -0.6875]],\n",
      "\n",
      "        [[-0.6983, -0.6880]],\n",
      "\n",
      "        [[-0.7091, -0.6775]],\n",
      "\n",
      "        [[-0.6961, -0.6902]],\n",
      "\n",
      "        [[-0.7023, -0.6841]],\n",
      "\n",
      "        [[-0.6977, -0.6886]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0231, -0.0193]],\n",
      "\n",
      "        [[ 0.0033, -0.0089]],\n",
      "\n",
      "        [[-0.0237, -0.0153]],\n",
      "\n",
      "        [[ 0.0046, -0.0081]],\n",
      "\n",
      "        [[ 0.0346,  0.0105]],\n",
      "\n",
      "        [[-0.0076, -0.0264]],\n",
      "\n",
      "        [[ 0.0011, -0.0127]],\n",
      "\n",
      "        [[-0.0199,  0.0141]],\n",
      "\n",
      "        [[-0.0056, -0.0181]],\n",
      "\n",
      "        [[ 0.0185,  0.0168]],\n",
      "\n",
      "        [[ 0.0158, -0.0068]],\n",
      "\n",
      "        [[-0.0034,  0.0176]],\n",
      "\n",
      "        [[ 0.0021,  0.0094]],\n",
      "\n",
      "        [[-0.0134, -0.0153]],\n",
      "\n",
      "        [[ 0.0097, -0.0170]],\n",
      "\n",
      "        [[-0.0218, -0.0307]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6951, -0.6912]],\n",
      "\n",
      "        [[-0.6871, -0.6993]],\n",
      "\n",
      "        [[-0.6973, -0.6890]],\n",
      "\n",
      "        [[-0.6868, -0.6995]],\n",
      "\n",
      "        [[-0.6811, -0.7053]],\n",
      "\n",
      "        [[-0.6838, -0.7026]],\n",
      "\n",
      "        [[-0.6862, -0.7001]],\n",
      "\n",
      "        [[-0.7103, -0.6763]],\n",
      "\n",
      "        [[-0.6869, -0.6994]],\n",
      "\n",
      "        [[-0.6923, -0.6940]],\n",
      "\n",
      "        [[-0.6819, -0.7045]],\n",
      "\n",
      "        [[-0.7037, -0.6827]],\n",
      "\n",
      "        [[-0.6968, -0.6895]],\n",
      "\n",
      "        [[-0.6922, -0.6941]],\n",
      "\n",
      "        [[-0.6799, -0.7066]],\n",
      "\n",
      "        [[-0.6887, -0.6976]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0175,  0.0087]],\n",
      "\n",
      "        [[ 0.0101, -0.0086]],\n",
      "\n",
      "        [[ 0.0253,  0.0016]],\n",
      "\n",
      "        [[ 0.0015, -0.0338]],\n",
      "\n",
      "        [[ 0.0071, -0.0309]],\n",
      "\n",
      "        [[-0.0252, -0.0140]],\n",
      "\n",
      "        [[-0.0114, -0.0132]],\n",
      "\n",
      "        [[-0.0053, -0.0130]],\n",
      "\n",
      "        [[ 0.0205,  0.0254]],\n",
      "\n",
      "        [[-0.0062, -0.0073]],\n",
      "\n",
      "        [[ 0.0107, -0.0026]],\n",
      "\n",
      "        [[ 0.0016, -0.0003]],\n",
      "\n",
      "        [[ 0.0362,  0.0144]],\n",
      "\n",
      "        [[ 0.0085, -0.0031]],\n",
      "\n",
      "        [[ 0.0121,  0.0108]],\n",
      "\n",
      "        [[-0.0231, -0.0130]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6888, -0.6976]],\n",
      "\n",
      "        [[-0.6838, -0.7025]],\n",
      "\n",
      "        [[-0.6814, -0.7051]],\n",
      "\n",
      "        [[-0.6757, -0.7109]],\n",
      "\n",
      "        [[-0.6743, -0.7124]],\n",
      "\n",
      "        [[-0.6988, -0.6875]],\n",
      "\n",
      "        [[-0.6923, -0.6940]],\n",
      "\n",
      "        [[-0.6893, -0.6970]],\n",
      "\n",
      "        [[-0.6956, -0.6907]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.6865, -0.6998]],\n",
      "\n",
      "        [[-0.6922, -0.6941]],\n",
      "\n",
      "        [[-0.6823, -0.7041]],\n",
      "\n",
      "        [[-0.6874, -0.6989]],\n",
      "\n",
      "        [[-0.6925, -0.6938]],\n",
      "\n",
      "        [[-0.6982, -0.6881]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0068,  0.0057]],\n",
      "\n",
      "        [[ 0.0114, -0.0172]],\n",
      "\n",
      "        [[ 0.0260, -0.0021]],\n",
      "\n",
      "        [[ 0.0445, -0.0026]],\n",
      "\n",
      "        [[ 0.0128, -0.0263]],\n",
      "\n",
      "        [[-0.0015, -0.0105]],\n",
      "\n",
      "        [[ 0.0022, -0.0207]],\n",
      "\n",
      "        [[ 0.0600, -0.0001]],\n",
      "\n",
      "        [[ 0.0553,  0.0312]],\n",
      "\n",
      "        [[-0.0022, -0.0064]],\n",
      "\n",
      "        [[-0.0012, -0.0208]],\n",
      "\n",
      "        [[-0.0085, -0.0317]],\n",
      "\n",
      "        [[ 0.0114, -0.0097]],\n",
      "\n",
      "        [[ 0.0171,  0.0077]],\n",
      "\n",
      "        [[ 0.0129, -0.0020]],\n",
      "\n",
      "        [[ 0.0240, -0.0009]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6994, -0.6869]],\n",
      "\n",
      "        [[-0.6790, -0.7075]],\n",
      "\n",
      "        [[-0.6792, -0.7073]],\n",
      "\n",
      "        [[-0.6699, -0.7170]],\n",
      "\n",
      "        [[-0.6738, -0.7129]],\n",
      "\n",
      "        [[-0.6886, -0.6977]],\n",
      "\n",
      "        [[-0.6817, -0.7047]],\n",
      "\n",
      "        [[-0.6635, -0.7237]],\n",
      "\n",
      "        [[-0.6812, -0.7052]],\n",
      "\n",
      "        [[-0.6911, -0.6952]],\n",
      "\n",
      "        [[-0.6834, -0.7030]],\n",
      "\n",
      "        [[-0.6816, -0.7048]],\n",
      "\n",
      "        [[-0.6826, -0.7038]],\n",
      "\n",
      "        [[-0.6884, -0.6979]],\n",
      "\n",
      "        [[-0.6857, -0.7006]],\n",
      "\n",
      "        [[-0.6808, -0.7056]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0160,  0.0238]],\n",
      "\n",
      "        [[-0.0233, -0.0170]],\n",
      "\n",
      "        [[-0.0095, -0.0232]],\n",
      "\n",
      "        [[-0.0038, -0.0235]],\n",
      "\n",
      "        [[-0.0087, -0.0342]],\n",
      "\n",
      "        [[ 0.0186, -0.0174]],\n",
      "\n",
      "        [[ 0.0045, -0.0007]],\n",
      "\n",
      "        [[ 0.0182, -0.0063]],\n",
      "\n",
      "        [[ 0.0146, -0.0129]],\n",
      "\n",
      "        [[ 0.0348,  0.0235]],\n",
      "\n",
      "        [[ 0.0250, -0.0079]],\n",
      "\n",
      "        [[ 0.0094, -0.0051]],\n",
      "\n",
      "        [[ 0.0042,  0.0088]],\n",
      "\n",
      "        [[ 0.0572,  0.0250]],\n",
      "\n",
      "        [[-0.0039, -0.0085]],\n",
      "\n",
      "        [[-0.0246, -0.0349]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6971, -0.6892]],\n",
      "\n",
      "        [[-0.6963, -0.6900]],\n",
      "\n",
      "        [[-0.6863, -0.7000]],\n",
      "\n",
      "        [[-0.6833, -0.7031]],\n",
      "\n",
      "        [[-0.6805, -0.7060]],\n",
      "\n",
      "        [[-0.6753, -0.7113]],\n",
      "\n",
      "        [[-0.6906, -0.6957]],\n",
      "\n",
      "        [[-0.6810, -0.7055]],\n",
      "\n",
      "        [[-0.6795, -0.7070]],\n",
      "\n",
      "        [[-0.6875, -0.6988]],\n",
      "\n",
      "        [[-0.6768, -0.7097]],\n",
      "\n",
      "        [[-0.6859, -0.7004]],\n",
      "\n",
      "        [[-0.6954, -0.6909]],\n",
      "\n",
      "        [[-0.6772, -0.7094]],\n",
      "\n",
      "        [[-0.6908, -0.6955]],\n",
      "\n",
      "        [[-0.6880, -0.6983]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 1.0543e-02, -2.9912e-02]],\n",
      "\n",
      "        [[ 2.1011e-02, -1.0374e-02]],\n",
      "\n",
      "        [[ 6.8381e-04, -2.6153e-02]],\n",
      "\n",
      "        [[-9.3063e-03, -1.6443e-02]],\n",
      "\n",
      "        [[ 1.4668e-02,  1.5282e-02]],\n",
      "\n",
      "        [[ 2.2299e-02, -1.0404e-02]],\n",
      "\n",
      "        [[ 1.7121e-02, -5.7062e-03]],\n",
      "\n",
      "        [[ 2.3102e-02,  6.0640e-05]],\n",
      "\n",
      "        [[ 7.9199e-03, -1.3376e-02]],\n",
      "\n",
      "        [[-2.8428e-03, -4.9194e-02]],\n",
      "\n",
      "        [[-9.4767e-03, -1.7132e-02]],\n",
      "\n",
      "        [[ 2.7427e-02, -1.2384e-02]],\n",
      "\n",
      "        [[ 1.0752e-02, -2.3253e-02]],\n",
      "\n",
      "        [[-7.7525e-03, -1.1431e-02]],\n",
      "\n",
      "        [[ 2.9955e-02,  1.8781e-02]],\n",
      "\n",
      "        [[ 1.6072e-04, -1.8083e-02]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6731, -0.7136]],\n",
      "\n",
      "        [[-0.6776, -0.7090]],\n",
      "\n",
      "        [[-0.6798, -0.7067]],\n",
      "\n",
      "        [[-0.6896, -0.6967]],\n",
      "\n",
      "        [[-0.6935, -0.6928]],\n",
      "\n",
      "        [[-0.6769, -0.7096]],\n",
      "\n",
      "        [[-0.6818, -0.7046]],\n",
      "\n",
      "        [[-0.6817, -0.7047]],\n",
      "\n",
      "        [[-0.6826, -0.7039]],\n",
      "\n",
      "        [[-0.6702, -0.7166]],\n",
      "\n",
      "        [[-0.6893, -0.6970]],\n",
      "\n",
      "        [[-0.6734, -0.7133]],\n",
      "\n",
      "        [[-0.6763, -0.7103]],\n",
      "\n",
      "        [[-0.6913, -0.6950]],\n",
      "\n",
      "        [[-0.6876, -0.6988]],\n",
      "\n",
      "        [[-0.6841, -0.7023]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-1.9304e-02, -2.6570e-02]],\n",
      "\n",
      "        [[-2.9201e-03, -2.2482e-02]],\n",
      "\n",
      "        [[ 1.4997e-02, -4.8978e-03]],\n",
      "\n",
      "        [[ 1.4004e-02, -1.4073e-02]],\n",
      "\n",
      "        [[ 1.8992e-02, -2.7391e-02]],\n",
      "\n",
      "        [[ 1.5926e-02,  3.6226e-03]],\n",
      "\n",
      "        [[ 6.6245e-03, -2.3099e-02]],\n",
      "\n",
      "        [[ 2.3509e-02, -2.1079e-02]],\n",
      "\n",
      "        [[ 3.2921e-02,  8.1163e-03]],\n",
      "\n",
      "        [[-1.2574e-03, -4.5989e-03]],\n",
      "\n",
      "        [[ 3.4686e-02, -1.1899e-02]],\n",
      "\n",
      "        [[ 1.0269e-02,  5.3299e-03]],\n",
      "\n",
      "        [[ 1.5444e-02, -9.9129e-03]],\n",
      "\n",
      "        [[ 3.6491e-03, -2.0282e-02]],\n",
      "\n",
      "        [[ 3.4409e-02,  2.4319e-02]],\n",
      "\n",
      "        [[ 2.8963e-02,  8.0582e-05]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6895, -0.6968]],\n",
      "\n",
      "        [[-0.6834, -0.7030]],\n",
      "\n",
      "        [[-0.6832, -0.7031]],\n",
      "\n",
      "        [[-0.6792, -0.7073]],\n",
      "\n",
      "        [[-0.6702, -0.7166]],\n",
      "\n",
      "        [[-0.6870, -0.6993]],\n",
      "\n",
      "        [[-0.6784, -0.7081]],\n",
      "\n",
      "        [[-0.6711, -0.7157]],\n",
      "\n",
      "        [[-0.6808, -0.7056]],\n",
      "\n",
      "        [[-0.6915, -0.6948]],\n",
      "\n",
      "        [[-0.6701, -0.7167]],\n",
      "\n",
      "        [[-0.6907, -0.6956]],\n",
      "\n",
      "        [[-0.6805, -0.7059]],\n",
      "\n",
      "        [[-0.6813, -0.7052]],\n",
      "\n",
      "        [[-0.6881, -0.6982]],\n",
      "\n",
      "        [[-0.6788, -0.7077]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 2.3380e-02, -9.9295e-03]],\n",
      "\n",
      "        [[ 1.4980e-02, -3.5793e-05]],\n",
      "\n",
      "        [[ 3.6660e-02, -2.2821e-02]],\n",
      "\n",
      "        [[ 9.8461e-03, -2.0991e-02]],\n",
      "\n",
      "        [[ 2.4880e-02,  1.9522e-02]],\n",
      "\n",
      "        [[ 2.9838e-03, -1.7759e-02]],\n",
      "\n",
      "        [[ 7.6223e-03, -2.9144e-02]],\n",
      "\n",
      "        [[ 1.1636e-02, -2.0026e-02]],\n",
      "\n",
      "        [[ 2.4252e-02,  1.5955e-02]],\n",
      "\n",
      "        [[ 3.3222e-02,  1.1703e-03]],\n",
      "\n",
      "        [[ 3.3508e-02,  1.3398e-02]],\n",
      "\n",
      "        [[-6.4666e-03, -8.5189e-03]],\n",
      "\n",
      "        [[ 1.3328e-04,  2.9008e-02]],\n",
      "\n",
      "        [[ 6.4528e-03, -3.6804e-02]],\n",
      "\n",
      "        [[-9.1976e-03, -1.7164e-02]],\n",
      "\n",
      "        [[ 2.5283e-02,  7.6891e-03]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6766, -0.7099]],\n",
      "\n",
      "        [[-0.6857, -0.7007]],\n",
      "\n",
      "        [[-0.6638, -0.7233]],\n",
      "\n",
      "        [[-0.6778, -0.7087]],\n",
      "\n",
      "        [[-0.6905, -0.6958]],\n",
      "\n",
      "        [[-0.6828, -0.7036]],\n",
      "\n",
      "        [[-0.6749, -0.7117]],\n",
      "\n",
      "        [[-0.6774, -0.7091]],\n",
      "\n",
      "        [[-0.6890, -0.6973]],\n",
      "\n",
      "        [[-0.6772, -0.7093]],\n",
      "\n",
      "        [[-0.6831, -0.7033]],\n",
      "\n",
      "        [[-0.6921, -0.6942]],\n",
      "\n",
      "        [[-0.7077, -0.6788]],\n",
      "\n",
      "        [[-0.6718, -0.7150]],\n",
      "\n",
      "        [[-0.6892, -0.6971]],\n",
      "\n",
      "        [[-0.6844, -0.7020]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0184, -0.0370]],\n",
      "\n",
      "        [[ 0.0016, -0.0009]],\n",
      "\n",
      "        [[ 0.0175, -0.0153]],\n",
      "\n",
      "        [[-0.0050, -0.0100]],\n",
      "\n",
      "        [[ 0.0306,  0.0267]],\n",
      "\n",
      "        [[-0.0171,  0.0109]],\n",
      "\n",
      "        [[ 0.0085, -0.0177]],\n",
      "\n",
      "        [[ 0.0141,  0.0088]],\n",
      "\n",
      "        [[ 0.0776,  0.0179]],\n",
      "\n",
      "        [[ 0.0035, -0.0220]],\n",
      "\n",
      "        [[-0.0239, -0.0333]],\n",
      "\n",
      "        [[-0.0087,  0.0023]],\n",
      "\n",
      "        [[ 0.0318,  0.0156]],\n",
      "\n",
      "        [[-0.0076, -0.0217]],\n",
      "\n",
      "        [[ 0.0472,  0.0496]],\n",
      "\n",
      "        [[ 0.0229,  0.0091]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6659, -0.7212]],\n",
      "\n",
      "        [[-0.6919, -0.6944]],\n",
      "\n",
      "        [[-0.6769, -0.7097]],\n",
      "\n",
      "        [[-0.6907, -0.6956]],\n",
      "\n",
      "        [[-0.6912, -0.6951]],\n",
      "\n",
      "        [[-0.7072, -0.6793]],\n",
      "\n",
      "        [[-0.6801, -0.7064]],\n",
      "\n",
      "        [[-0.6905, -0.6958]],\n",
      "\n",
      "        [[-0.6637, -0.7235]],\n",
      "\n",
      "        [[-0.6804, -0.7060]],\n",
      "\n",
      "        [[-0.6885, -0.6979]],\n",
      "\n",
      "        [[-0.6987, -0.6876]],\n",
      "\n",
      "        [[-0.6851, -0.7013]],\n",
      "\n",
      "        [[-0.6861, -0.7003]],\n",
      "\n",
      "        [[-0.6943, -0.6920]],\n",
      "\n",
      "        [[-0.6863, -0.7001]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0306, -0.0233]],\n",
      "\n",
      "        [[-0.0002, -0.0318]],\n",
      "\n",
      "        [[ 0.0357, -0.0333]],\n",
      "\n",
      "        [[ 0.0214, -0.0416]],\n",
      "\n",
      "        [[ 0.0101,  0.0016]],\n",
      "\n",
      "        [[ 0.0113, -0.0140]],\n",
      "\n",
      "        [[ 0.0149, -0.0217]],\n",
      "\n",
      "        [[ 0.0266, -0.0240]],\n",
      "\n",
      "        [[ 0.0263,  0.0045]],\n",
      "\n",
      "        [[ 0.0404,  0.0036]],\n",
      "\n",
      "        [[ 0.0201,  0.0032]],\n",
      "\n",
      "        [[ 0.0410, -0.0274]],\n",
      "\n",
      "        [[ 0.0393, -0.0126]],\n",
      "\n",
      "        [[ 0.0747, -0.0154]],\n",
      "\n",
      "        [[ 0.0419, -0.0168]],\n",
      "\n",
      "        [[ 0.0240, -0.0047]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6666, -0.7205]],\n",
      "\n",
      "        [[-0.6775, -0.7091]],\n",
      "\n",
      "        [[-0.6593, -0.7282]],\n",
      "\n",
      "        [[-0.6622, -0.7251]],\n",
      "\n",
      "        [[-0.6889, -0.6974]],\n",
      "\n",
      "        [[-0.6806, -0.7059]],\n",
      "\n",
      "        [[-0.6750, -0.7116]],\n",
      "\n",
      "        [[-0.6682, -0.7188]],\n",
      "\n",
      "        [[-0.6823, -0.7041]],\n",
      "\n",
      "        [[-0.6749, -0.7117]],\n",
      "\n",
      "        [[-0.6847, -0.7016]],\n",
      "\n",
      "        [[-0.6595, -0.7279]],\n",
      "\n",
      "        [[-0.6675, -0.7194]],\n",
      "\n",
      "        [[-0.6491, -0.7392]],\n",
      "\n",
      "        [[-0.6642, -0.7229]],\n",
      "\n",
      "        [[-0.6789, -0.7076]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0221, -0.0071]],\n",
      "\n",
      "        [[-0.0052, -0.0228]],\n",
      "\n",
      "        [[ 0.0016, -0.0202]],\n",
      "\n",
      "        [[ 0.0603,  0.0476]],\n",
      "\n",
      "        [[ 0.0166,  0.0111]],\n",
      "\n",
      "        [[ 0.0267,  0.0162]],\n",
      "\n",
      "        [[ 0.0165,  0.0053]],\n",
      "\n",
      "        [[ 0.0409, -0.0284]],\n",
      "\n",
      "        [[ 0.0325,  0.0314]],\n",
      "\n",
      "        [[ 0.0166, -0.0317]],\n",
      "\n",
      "        [[ 0.0342,  0.0010]],\n",
      "\n",
      "        [[ 0.0190, -0.0358]],\n",
      "\n",
      "        [[ 0.0191,  0.0130]],\n",
      "\n",
      "        [[ 0.0464,  0.0076]],\n",
      "\n",
      "        [[-0.0102,  0.0220]],\n",
      "\n",
      "        [[ 0.0095, -0.0176]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6787, -0.7078]],\n",
      "\n",
      "        [[-0.6844, -0.7020]],\n",
      "\n",
      "        [[-0.6823, -0.7041]],\n",
      "\n",
      "        [[-0.6868, -0.6995]],\n",
      "\n",
      "        [[-0.6904, -0.6959]],\n",
      "\n",
      "        [[-0.6879, -0.6984]],\n",
      "\n",
      "        [[-0.6876, -0.6987]],\n",
      "\n",
      "        [[-0.6591, -0.7284]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.6693, -0.7176]],\n",
      "\n",
      "        [[-0.6767, -0.7099]],\n",
      "\n",
      "        [[-0.6661, -0.7209]],\n",
      "\n",
      "        [[-0.6901, -0.6962]],\n",
      "\n",
      "        [[-0.6739, -0.7128]],\n",
      "\n",
      "        [[-0.7094, -0.6772]],\n",
      "\n",
      "        [[-0.6797, -0.7068]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0534, -0.0129]],\n",
      "\n",
      "        [[ 0.0099, -0.0309]],\n",
      "\n",
      "        [[ 0.0251, -0.0284]],\n",
      "\n",
      "        [[ 0.0357, -0.0166]],\n",
      "\n",
      "        [[ 0.0235, -0.0257]],\n",
      "\n",
      "        [[ 0.0778, -0.0030]],\n",
      "\n",
      "        [[ 0.0548,  0.0264]],\n",
      "\n",
      "        [[ 0.0372, -0.0015]],\n",
      "\n",
      "        [[ 0.0242, -0.0140]],\n",
      "\n",
      "        [[ 0.0318, -0.0086]],\n",
      "\n",
      "        [[ 0.0233, -0.0085]],\n",
      "\n",
      "        [[ 0.0240, -0.0210]],\n",
      "\n",
      "        [[ 0.0340,  0.0163]],\n",
      "\n",
      "        [[ 0.0188, -0.0206]],\n",
      "\n",
      "        [[ 0.0190, -0.0266]],\n",
      "\n",
      "        [[ 0.0535, -0.0109]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6606, -0.7268]],\n",
      "\n",
      "        [[-0.6729, -0.7138]],\n",
      "\n",
      "        [[-0.6667, -0.7203]],\n",
      "\n",
      "        [[-0.6673, -0.7196]],\n",
      "\n",
      "        [[-0.6688, -0.7181]],\n",
      "\n",
      "        [[-0.6536, -0.7343]],\n",
      "\n",
      "        [[-0.6790, -0.7075]],\n",
      "\n",
      "        [[-0.6740, -0.7127]],\n",
      "\n",
      "        [[-0.6742, -0.7125]],\n",
      "\n",
      "        [[-0.6731, -0.7136]],\n",
      "\n",
      "        [[-0.6774, -0.7092]],\n",
      "\n",
      "        [[-0.6709, -0.7159]],\n",
      "\n",
      "        [[-0.6843, -0.7020]],\n",
      "\n",
      "        [[-0.6736, -0.7131]],\n",
      "\n",
      "        [[-0.6706, -0.7162]],\n",
      "\n",
      "        [[-0.6615, -0.7258]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0288, -0.0039]],\n",
      "\n",
      "        [[ 0.0110, -0.0263]],\n",
      "\n",
      "        [[ 0.0157, -0.0325]],\n",
      "\n",
      "        [[ 0.0240, -0.0110]],\n",
      "\n",
      "        [[ 0.0424,  0.0044]],\n",
      "\n",
      "        [[ 0.0511, -0.0397]],\n",
      "\n",
      "        [[ 0.0451,  0.0106]],\n",
      "\n",
      "        [[ 0.0161, -0.0251]],\n",
      "\n",
      "        [[ 0.0331, -0.0379]],\n",
      "\n",
      "        [[ 0.0470,  0.0080]],\n",
      "\n",
      "        [[ 0.0679, -0.0366]],\n",
      "\n",
      "        [[ 0.0133, -0.0224]],\n",
      "\n",
      "        [[ 0.0456, -0.0019]],\n",
      "\n",
      "        [[ 0.0205, -0.0395]],\n",
      "\n",
      "        [[ 0.0384, -0.0055]],\n",
      "\n",
      "        [[ 0.0651, -0.0151]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6770, -0.7096]],\n",
      "\n",
      "        [[-0.6747, -0.7120]],\n",
      "\n",
      "        [[-0.6693, -0.7175]],\n",
      "\n",
      "        [[-0.6758, -0.7108]],\n",
      "\n",
      "        [[-0.6744, -0.7123]],\n",
      "\n",
      "        [[-0.6488, -0.7396]],\n",
      "\n",
      "        [[-0.6760, -0.7106]],\n",
      "\n",
      "        [[-0.6728, -0.7140]],\n",
      "\n",
      "        [[-0.6583, -0.7292]],\n",
      "\n",
      "        [[-0.6739, -0.7128]],\n",
      "\n",
      "        [[-0.6422, -0.7468]],\n",
      "\n",
      "        [[-0.6754, -0.7112]],\n",
      "\n",
      "        [[-0.6697, -0.7171]],\n",
      "\n",
      "        [[-0.6636, -0.7236]],\n",
      "\n",
      "        [[-0.6714, -0.7153]],\n",
      "\n",
      "        [[-0.6538, -0.7341]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0214, -0.0336]],\n",
      "\n",
      "        [[ 0.0749, -0.0112]],\n",
      "\n",
      "        [[ 0.0437, -0.0604]],\n",
      "\n",
      "        [[ 0.0202, -0.0238]],\n",
      "\n",
      "        [[ 0.0422,  0.0043]],\n",
      "\n",
      "        [[ 0.0704,  0.0285]],\n",
      "\n",
      "        [[ 0.0498, -0.0103]],\n",
      "\n",
      "        [[ 0.0479,  0.0004]],\n",
      "\n",
      "        [[ 0.0141, -0.0322]],\n",
      "\n",
      "        [[ 0.0183, -0.0272]],\n",
      "\n",
      "        [[ 0.0326, -0.0401]],\n",
      "\n",
      "        [[ 0.0390, -0.0180]],\n",
      "\n",
      "        [[-0.0008, -0.0558]],\n",
      "\n",
      "        [[ 0.0037, -0.0530]],\n",
      "\n",
      "        [[ 0.0033, -0.0365]],\n",
      "\n",
      "        [[ 0.0319, -0.0274]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6660, -0.7210]],\n",
      "\n",
      "        [[-0.6510, -0.7371]],\n",
      "\n",
      "        [[-0.6425, -0.7465]],\n",
      "\n",
      "        [[-0.6714, -0.7154]],\n",
      "\n",
      "        [[-0.6744, -0.7123]],\n",
      "\n",
      "        [[-0.6725, -0.7143]],\n",
      "\n",
      "        [[-0.6635, -0.7237]],\n",
      "\n",
      "        [[-0.6696, -0.7172]],\n",
      "\n",
      "        [[-0.6703, -0.7166]],\n",
      "\n",
      "        [[-0.6707, -0.7161]],\n",
      "\n",
      "        [[-0.6575, -0.7301]],\n",
      "\n",
      "        [[-0.6650, -0.7221]],\n",
      "\n",
      "        [[-0.6660, -0.7211]],\n",
      "\n",
      "        [[-0.6652, -0.7219]],\n",
      "\n",
      "        [[-0.6735, -0.7132]],\n",
      "\n",
      "        [[-0.6639, -0.7232]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0284, -0.0079]],\n",
      "\n",
      "        [[ 0.0174, -0.0264]],\n",
      "\n",
      "        [[ 0.0494, -0.0456]],\n",
      "\n",
      "        [[ 0.0321, -0.0108]],\n",
      "\n",
      "        [[ 0.0407, -0.0566]],\n",
      "\n",
      "        [[ 0.0500, -0.0076]],\n",
      "\n",
      "        [[ 0.0188, -0.0234]],\n",
      "\n",
      "        [[ 0.0316, -0.0169]],\n",
      "\n",
      "        [[ 0.0386, -0.0147]],\n",
      "\n",
      "        [[ 0.0389, -0.0421]],\n",
      "\n",
      "        [[ 0.0232, -0.0220]],\n",
      "\n",
      "        [[ 0.0657, -0.0227]],\n",
      "\n",
      "        [[ 0.0442, -0.0132]],\n",
      "\n",
      "        [[ 0.0361, -0.0471]],\n",
      "\n",
      "        [[ 0.0395,  0.0027]],\n",
      "\n",
      "        [[ 0.0311, -0.0447]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6752, -0.7114]],\n",
      "\n",
      "        [[-0.6715, -0.7153]],\n",
      "\n",
      "        [[-0.6468, -0.7418]],\n",
      "\n",
      "        [[-0.6719, -0.7149]],\n",
      "\n",
      "        [[-0.6457, -0.7430]],\n",
      "\n",
      "        [[-0.6648, -0.7223]],\n",
      "\n",
      "        [[-0.6722, -0.7145]],\n",
      "\n",
      "        [[-0.6692, -0.7177]],\n",
      "\n",
      "        [[-0.6668, -0.7202]],\n",
      "\n",
      "        [[-0.6535, -0.7345]],\n",
      "\n",
      "        [[-0.6708, -0.7160]],\n",
      "\n",
      "        [[-0.6499, -0.7383]],\n",
      "\n",
      "        [[-0.6648, -0.7223]],\n",
      "\n",
      "        [[-0.6524, -0.7356]],\n",
      "\n",
      "        [[-0.6749, -0.7117]],\n",
      "\n",
      "        [[-0.6560, -0.7318]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0529, -0.0344]],\n",
      "\n",
      "        [[ 0.0618, -0.0201]],\n",
      "\n",
      "        [[ 0.0287, -0.0379]],\n",
      "\n",
      "        [[ 0.0308, -0.0146]],\n",
      "\n",
      "        [[ 0.0349, -0.0283]],\n",
      "\n",
      "        [[ 0.0640, -0.0195]],\n",
      "\n",
      "        [[ 0.0449, -0.0303]],\n",
      "\n",
      "        [[ 0.0370, -0.0414]],\n",
      "\n",
      "        [[ 0.0484, -0.0411]],\n",
      "\n",
      "        [[ 0.0325, -0.0532]],\n",
      "\n",
      "        [[ 0.0405, -0.0365]],\n",
      "\n",
      "        [[ 0.0509, -0.0286]],\n",
      "\n",
      "        [[ 0.0605, -0.0353]],\n",
      "\n",
      "        [[ 0.0222, -0.0401]],\n",
      "\n",
      "        [[ 0.0646, -0.0213]],\n",
      "\n",
      "        [[ 0.0350, -0.0483]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6504, -0.7378]],\n",
      "\n",
      "        [[-0.6530, -0.7350]],\n",
      "\n",
      "        [[-0.6604, -0.7270]],\n",
      "\n",
      "        [[-0.6707, -0.7161]],\n",
      "\n",
      "        [[-0.6620, -0.7253]],\n",
      "\n",
      "        [[-0.6523, -0.7358]],\n",
      "\n",
      "        [[-0.6562, -0.7315]],\n",
      "\n",
      "        [[-0.6548, -0.7331]],\n",
      "\n",
      "        [[-0.6494, -0.7389]],\n",
      "\n",
      "        [[-0.6513, -0.7369]],\n",
      "\n",
      "        [[-0.6554, -0.7324]],\n",
      "\n",
      "        [[-0.6542, -0.7337]],\n",
      "\n",
      "        [[-0.6464, -0.7422]],\n",
      "\n",
      "        [[-0.6625, -0.7248]],\n",
      "\n",
      "        [[-0.6511, -0.7370]],\n",
      "\n",
      "        [[-0.6523, -0.7357]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0352, -0.0649]],\n",
      "\n",
      "        [[ 0.0376, -0.0312]],\n",
      "\n",
      "        [[ 0.0798, -0.0301]],\n",
      "\n",
      "        [[ 0.0153, -0.0210]],\n",
      "\n",
      "        [[ 0.0638, -0.0196]],\n",
      "\n",
      "        [[ 0.0505,  0.0048]],\n",
      "\n",
      "        [[ 0.0564, -0.0294]],\n",
      "\n",
      "        [[ 0.0323, -0.0472]],\n",
      "\n",
      "        [[ 0.0547, -0.0163]],\n",
      "\n",
      "        [[ 0.0462, -0.0543]],\n",
      "\n",
      "        [[ 0.0671, -0.0298]],\n",
      "\n",
      "        [[ 0.0270, -0.0478]],\n",
      "\n",
      "        [[ 0.0392, -0.0622]],\n",
      "\n",
      "        [[ 0.0217, -0.0417]],\n",
      "\n",
      "        [[ 0.0464, -0.0298]],\n",
      "\n",
      "        [[ 0.0519, -0.0670]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6444, -0.7444]],\n",
      "\n",
      "        [[-0.6593, -0.7281]],\n",
      "\n",
      "        [[-0.6397, -0.7496]],\n",
      "\n",
      "        [[-0.6751, -0.7115]],\n",
      "\n",
      "        [[-0.6523, -0.7357]],\n",
      "\n",
      "        [[-0.6706, -0.7163]],\n",
      "\n",
      "        [[-0.6511, -0.7370]],\n",
      "\n",
      "        [[-0.6542, -0.7337]],\n",
      "\n",
      "        [[-0.6583, -0.7292]],\n",
      "\n",
      "        [[-0.6441, -0.7447]],\n",
      "\n",
      "        [[-0.6458, -0.7428]],\n",
      "\n",
      "        [[-0.6564, -0.7313]],\n",
      "\n",
      "        [[-0.6437, -0.7452]],\n",
      "\n",
      "        [[-0.6620, -0.7253]],\n",
      "\n",
      "        [[-0.6558, -0.7319]],\n",
      "\n",
      "        [[-0.6355, -0.7544]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0436, -0.0041]],\n",
      "\n",
      "        [[ 0.0756, -0.0442]],\n",
      "\n",
      "        [[ 0.0629, -0.0020]],\n",
      "\n",
      "        [[ 0.0829, -0.0379]],\n",
      "\n",
      "        [[ 0.0311, -0.0451]],\n",
      "\n",
      "        [[ 0.0513, -0.0611]],\n",
      "\n",
      "        [[ 0.0502, -0.0171]],\n",
      "\n",
      "        [[ 0.0427, -0.0684]],\n",
      "\n",
      "        [[ 0.0442, -0.0383]],\n",
      "\n",
      "        [[ 0.0678, -0.0166]],\n",
      "\n",
      "        [[ 0.0484, -0.0483]],\n",
      "\n",
      "        [[ 0.0554, -0.0513]],\n",
      "\n",
      "        [[ 0.0662, -0.0350]],\n",
      "\n",
      "        [[ 0.0281, -0.0751]],\n",
      "\n",
      "        [[ 0.0207, -0.0450]],\n",
      "\n",
      "        [[ 0.0971,  0.0066]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6696, -0.7173]],\n",
      "\n",
      "        [[-0.6351, -0.7548]],\n",
      "\n",
      "        [[-0.6612, -0.7261]],\n",
      "\n",
      "        [[-0.6346, -0.7554]],\n",
      "\n",
      "        [[-0.6558, -0.7320]],\n",
      "\n",
      "        [[-0.6385, -0.7509]],\n",
      "\n",
      "        [[-0.6601, -0.7273]],\n",
      "\n",
      "        [[-0.6391, -0.7503]],\n",
      "\n",
      "        [[-0.6528, -0.7352]],\n",
      "\n",
      "        [[-0.6518, -0.7362]],\n",
      "\n",
      "        [[-0.6460, -0.7427]],\n",
      "\n",
      "        [[-0.6412, -0.7479]],\n",
      "\n",
      "        [[-0.6438, -0.7450]],\n",
      "\n",
      "        [[-0.6429, -0.7461]],\n",
      "\n",
      "        [[-0.6608, -0.7265]],\n",
      "\n",
      "        [[-0.6489, -0.7394]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0271, -0.0265]],\n",
      "\n",
      "        [[ 0.0542, -0.0395]],\n",
      "\n",
      "        [[ 0.0327, -0.0255]],\n",
      "\n",
      "        [[ 0.0532, -0.0478]],\n",
      "\n",
      "        [[ 0.0364, -0.0472]],\n",
      "\n",
      "        [[ 0.0018, -0.0382]],\n",
      "\n",
      "        [[ 0.0256, -0.0459]],\n",
      "\n",
      "        [[ 0.0815, -0.0496]],\n",
      "\n",
      "        [[ 0.0505, -0.0678]],\n",
      "\n",
      "        [[ 0.0383, -0.0457]],\n",
      "\n",
      "        [[ 0.0587, -0.0248]],\n",
      "\n",
      "        [[ 0.0206, -0.0311]],\n",
      "\n",
      "        [[ 0.0394, -0.0328]],\n",
      "\n",
      "        [[ 0.0717, -0.0461]],\n",
      "\n",
      "        [[ 0.0777, -0.0647]],\n",
      "\n",
      "        [[ 0.0637, -0.0150]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6667, -0.7203]],\n",
      "\n",
      "        [[-0.6474, -0.7411]],\n",
      "\n",
      "        [[-0.6645, -0.7227]],\n",
      "\n",
      "        [[-0.6439, -0.7449]],\n",
      "\n",
      "        [[-0.6523, -0.7358]],\n",
      "\n",
      "        [[-0.6733, -0.7134]],\n",
      "\n",
      "        [[-0.6581, -0.7295]],\n",
      "\n",
      "        [[-0.6297, -0.7609]],\n",
      "\n",
      "        [[-0.6358, -0.7540]],\n",
      "\n",
      "        [[-0.6520, -0.7361]],\n",
      "\n",
      "        [[-0.6523, -0.7357]],\n",
      "\n",
      "        [[-0.6677, -0.7193]],\n",
      "\n",
      "        [[-0.6577, -0.7299]],\n",
      "\n",
      "        [[-0.6359, -0.7538]],\n",
      "\n",
      "        [[-0.6245, -0.7669]],\n",
      "\n",
      "        [[-0.6546, -0.7333]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0158, -0.0493]],\n",
      "\n",
      "        [[ 0.0764, -0.0675]],\n",
      "\n",
      "        [[ 0.0439, -0.0675]],\n",
      "\n",
      "        [[ 0.0576, -0.0289]],\n",
      "\n",
      "        [[ 0.0447, -0.0577]],\n",
      "\n",
      "        [[ 0.0699, -0.0436]],\n",
      "\n",
      "        [[ 0.0692, -0.0121]],\n",
      "\n",
      "        [[ 0.0382, -0.0598]],\n",
      "\n",
      "        [[ 0.0559, -0.0560]],\n",
      "\n",
      "        [[ 0.0756, -0.0453]],\n",
      "\n",
      "        [[ 0.0378, -0.0430]],\n",
      "\n",
      "        [[ 0.1031, -0.0500]],\n",
      "\n",
      "        [[ 0.0578, -0.0721]],\n",
      "\n",
      "        [[ 0.0640, -0.0574]],\n",
      "\n",
      "        [[ 0.0172, -0.0419]],\n",
      "\n",
      "        [[ 0.0594, -0.0622]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6611, -0.7263]],\n",
      "\n",
      "        [[-0.6238, -0.7677]],\n",
      "\n",
      "        [[-0.6390, -0.7504]],\n",
      "\n",
      "        [[-0.6509, -0.7373]],\n",
      "\n",
      "        [[-0.6433, -0.7457]],\n",
      "\n",
      "        [[-0.6380, -0.7515]],\n",
      "\n",
      "        [[-0.6533, -0.7346]],\n",
      "\n",
      "        [[-0.6454, -0.7433]],\n",
      "\n",
      "        [[-0.6388, -0.7507]],\n",
      "\n",
      "        [[-0.6345, -0.7554]],\n",
      "\n",
      "        [[-0.6536, -0.7344]],\n",
      "\n",
      "        [[-0.6195, -0.7726]],\n",
      "\n",
      "        [[-0.6303, -0.7602]],\n",
      "\n",
      "        [[-0.6343, -0.7557]],\n",
      "\n",
      "        [[-0.6640, -0.7232]],\n",
      "\n",
      "        [[-0.6342, -0.7558]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0695, -0.0502]],\n",
      "\n",
      "        [[ 0.0598, -0.0769]],\n",
      "\n",
      "        [[ 0.0801, -0.0361]],\n",
      "\n",
      "        [[ 0.0629, -0.0217]],\n",
      "\n",
      "        [[ 0.0379, -0.0400]],\n",
      "\n",
      "        [[ 0.0733, -0.0490]],\n",
      "\n",
      "        [[ 0.0697, -0.0372]],\n",
      "\n",
      "        [[ 0.0490, -0.0549]],\n",
      "\n",
      "        [[ 0.0626, -0.0339]],\n",
      "\n",
      "        [[ 0.0783, -0.0626]],\n",
      "\n",
      "        [[ 0.0534, -0.0652]],\n",
      "\n",
      "        [[ 0.0327, -0.0586]],\n",
      "\n",
      "        [[ 0.0831, -0.0251]],\n",
      "\n",
      "        [[ 0.0287, -0.0319]],\n",
      "\n",
      "        [[ 0.0367, -0.0350]],\n",
      "\n",
      "        [[ 0.0762, -0.0347]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6350, -0.7548]],\n",
      "\n",
      "        [[-0.6271, -0.7638]],\n",
      "\n",
      "        [[-0.6367, -0.7530]],\n",
      "\n",
      "        [[-0.6517, -0.7363]],\n",
      "\n",
      "        [[-0.6550, -0.7329]],\n",
      "\n",
      "        [[-0.6339, -0.7562]],\n",
      "\n",
      "        [[-0.6411, -0.7480]],\n",
      "\n",
      "        [[-0.6425, -0.7464]],\n",
      "\n",
      "        [[-0.6460, -0.7426]],\n",
      "\n",
      "        [[-0.6252, -0.7661]],\n",
      "\n",
      "        [[-0.6356, -0.7542]],\n",
      "\n",
      "        [[-0.6486, -0.7398]],\n",
      "\n",
      "        [[-0.6405, -0.7487]],\n",
      "\n",
      "        [[-0.6633, -0.7239]],\n",
      "\n",
      "        [[-0.6580, -0.7296]],\n",
      "\n",
      "        [[-0.6392, -0.7501]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0868, -0.0783]],\n",
      "\n",
      "        [[ 0.0784, -0.0245]],\n",
      "\n",
      "        [[ 0.0574, -0.0398]],\n",
      "\n",
      "        [[ 0.0625, -0.0474]],\n",
      "\n",
      "        [[ 0.0741, -0.0459]],\n",
      "\n",
      "        [[ 0.0332, -0.0785]],\n",
      "\n",
      "        [[ 0.0900, -0.0262]],\n",
      "\n",
      "        [[ 0.0364, -0.0443]],\n",
      "\n",
      "        [[ 0.0301, -0.0667]],\n",
      "\n",
      "        [[ 0.0518, -0.0729]],\n",
      "\n",
      "        [[ 0.0393, -0.0767]],\n",
      "\n",
      "        [[ 0.0457, -0.0631]],\n",
      "\n",
      "        [[ 0.0781, -0.0255]],\n",
      "\n",
      "        [[ 0.0759, -0.0267]],\n",
      "\n",
      "        [[ 0.0723, -0.0278]],\n",
      "\n",
      "        [[ 0.1040, -0.0193]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6140, -0.7791]],\n",
      "\n",
      "        [[-0.6430, -0.7459]],\n",
      "\n",
      "        [[-0.6457, -0.7429]],\n",
      "\n",
      "        [[-0.6397, -0.7496]],\n",
      "\n",
      "        [[-0.6349, -0.7549]],\n",
      "\n",
      "        [[-0.6389, -0.7505]],\n",
      "\n",
      "        [[-0.6368, -0.7529]],\n",
      "\n",
      "        [[-0.6536, -0.7343]],\n",
      "\n",
      "        [[-0.6459, -0.7428]],\n",
      "\n",
      "        [[-0.6327, -0.7574]],\n",
      "\n",
      "        [[-0.6368, -0.7528]],\n",
      "\n",
      "        [[-0.6402, -0.7491]],\n",
      "\n",
      "        [[-0.6427, -0.7463]],\n",
      "\n",
      "        [[-0.6432, -0.7457]],\n",
      "\n",
      "        [[-0.6444, -0.7444]],\n",
      "\n",
      "        [[-0.6334, -0.7567]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0634, -0.0426]],\n",
      "\n",
      "        [[ 0.0656, -0.0691]],\n",
      "\n",
      "        [[ 0.0410, -0.0484]],\n",
      "\n",
      "        [[ 0.0554, -0.0614]],\n",
      "\n",
      "        [[ 0.0492, -0.0632]],\n",
      "\n",
      "        [[ 0.0469, -0.0565]],\n",
      "\n",
      "        [[ 0.0469, -0.0240]],\n",
      "\n",
      "        [[ 0.0333, -0.0478]],\n",
      "\n",
      "        [[ 0.0892,  0.0019]],\n",
      "\n",
      "        [[ 0.0605, -0.0350]],\n",
      "\n",
      "        [[ 0.0327, -0.0664]],\n",
      "\n",
      "        [[ 0.0922, -0.0648]],\n",
      "\n",
      "        [[ 0.0737, -0.0375]],\n",
      "\n",
      "        [[ 0.0664, -0.0345]],\n",
      "\n",
      "        [[ 0.0700, -0.0678]],\n",
      "\n",
      "        [[ 0.0737, -0.0418]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6416, -0.7475]],\n",
      "\n",
      "        [[-0.6281, -0.7627]],\n",
      "\n",
      "        [[-0.6494, -0.7389]],\n",
      "\n",
      "        [[-0.6364, -0.7533]],\n",
      "\n",
      "        [[-0.6385, -0.7510]],\n",
      "\n",
      "        [[-0.6428, -0.7462]],\n",
      "\n",
      "        [[-0.6583, -0.7292]],\n",
      "\n",
      "        [[-0.6534, -0.7345]],\n",
      "\n",
      "        [[-0.6505, -0.7377]],\n",
      "\n",
      "        [[-0.6465, -0.7420]],\n",
      "\n",
      "        [[-0.6448, -0.7439]],\n",
      "\n",
      "        [[-0.6177, -0.7747]],\n",
      "\n",
      "        [[-0.6391, -0.7503]],\n",
      "\n",
      "        [[-0.6440, -0.7449]],\n",
      "\n",
      "        [[-0.6266, -0.7644]],\n",
      "\n",
      "        [[-0.6371, -0.7526]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0577, -0.0485]],\n",
      "\n",
      "        [[ 0.0345, -0.0798]],\n",
      "\n",
      "        [[ 0.0722, -0.0345]],\n",
      "\n",
      "        [[ 0.0686, -0.0738]],\n",
      "\n",
      "        [[ 0.0372, -0.0337]],\n",
      "\n",
      "        [[ 0.0244, -0.0710]],\n",
      "\n",
      "        [[ 0.0563, -0.0582]],\n",
      "\n",
      "        [[ 0.0576, -0.0506]],\n",
      "\n",
      "        [[ 0.0647, -0.0629]],\n",
      "\n",
      "        [[ 0.0889, -0.0232]],\n",
      "\n",
      "        [[ 0.0818, -0.0764]],\n",
      "\n",
      "        [[ 0.0786, -0.0539]],\n",
      "\n",
      "        [[ 0.0813, -0.0400]],\n",
      "\n",
      "        [[ 0.0971, -0.0183]],\n",
      "\n",
      "        [[ 0.0674, -0.0333]],\n",
      "\n",
      "        [[ 0.0640, -0.0360]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6415, -0.7476]],\n",
      "\n",
      "        [[-0.6376, -0.7519]],\n",
      "\n",
      "        [[-0.6412, -0.7479]],\n",
      "\n",
      "        [[-0.6245, -0.7669]],\n",
      "\n",
      "        [[-0.6583, -0.7292]],\n",
      "\n",
      "        [[-0.6466, -0.7420]],\n",
      "\n",
      "        [[-0.6375, -0.7521]],\n",
      "\n",
      "        [[-0.6405, -0.7487]],\n",
      "\n",
      "        [[-0.6314, -0.7590]],\n",
      "\n",
      "        [[-0.6387, -0.7507]],\n",
      "\n",
      "        [[-0.6172, -0.7754]],\n",
      "\n",
      "        [[-0.6291, -0.7616]],\n",
      "\n",
      "        [[-0.6343, -0.7556]],\n",
      "\n",
      "        [[-0.6371, -0.7525]],\n",
      "\n",
      "        [[-0.6441, -0.7447]],\n",
      "\n",
      "        [[-0.6444, -0.7444]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0774, -0.0194]],\n",
      "\n",
      "        [[ 0.0442, -0.0354]],\n",
      "\n",
      "        [[ 0.0051, -0.0598]],\n",
      "\n",
      "        [[ 0.0447, -0.0604]],\n",
      "\n",
      "        [[ 0.1081, -0.0535]],\n",
      "\n",
      "        [[ 0.0743, -0.0586]],\n",
      "\n",
      "        [[ 0.0497, -0.0730]],\n",
      "\n",
      "        [[ 0.1019, -0.0849]],\n",
      "\n",
      "        [[ 0.0871, -0.0475]],\n",
      "\n",
      "        [[ 0.0596, -0.0468]],\n",
      "\n",
      "        [[ 0.0754, -0.0056]],\n",
      "\n",
      "        [[ 0.0773, -0.0336]],\n",
      "\n",
      "        [[ 0.0855, -0.0640]],\n",
      "\n",
      "        [[ 0.0617, -0.0326]],\n",
      "\n",
      "        [[ 0.0921, -0.0312]],\n",
      "\n",
      "        [[ 0.0824, -0.0444]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6459, -0.7427]],\n",
      "\n",
      "        [[-0.6541, -0.7337]],\n",
      "\n",
      "        [[-0.6612, -0.7261]],\n",
      "\n",
      "        [[-0.6420, -0.7471]],\n",
      "\n",
      "        [[-0.6156, -0.7772]],\n",
      "\n",
      "        [[-0.6289, -0.7618]],\n",
      "\n",
      "        [[-0.6337, -0.7564]],\n",
      "\n",
      "        [[-0.6041, -0.7909]],\n",
      "\n",
      "        [[-0.6281, -0.7627]],\n",
      "\n",
      "        [[-0.6413, -0.7478]],\n",
      "\n",
      "        [[-0.6535, -0.7345]],\n",
      "\n",
      "        [[-0.6392, -0.7501]],\n",
      "\n",
      "        [[-0.6212, -0.7707]],\n",
      "\n",
      "        [[-0.6471, -0.7414]],\n",
      "\n",
      "        [[-0.6334, -0.7567]],\n",
      "\n",
      "        [[-0.6317, -0.7586]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0713, -0.0816]],\n",
      "\n",
      "        [[ 0.0716, -0.0451]],\n",
      "\n",
      "        [[ 0.0716, -0.0665]],\n",
      "\n",
      "        [[ 0.0646, -0.0477]],\n",
      "\n",
      "        [[ 0.0891, -0.0486]],\n",
      "\n",
      "        [[ 0.0682, -0.0633]],\n",
      "\n",
      "        [[ 0.0753, -0.0449]],\n",
      "\n",
      "        [[ 0.0625, -0.0905]],\n",
      "\n",
      "        [[ 0.0831, -0.0694]],\n",
      "\n",
      "        [[ 0.0776, -0.0540]],\n",
      "\n",
      "        [[ 0.0650, -0.0680]],\n",
      "\n",
      "        [[ 0.0867, -0.0847]],\n",
      "\n",
      "        [[ 0.0843, -0.0649]],\n",
      "\n",
      "        [[ 0.1199, -0.0642]],\n",
      "\n",
      "        [[ 0.0413, -0.0851]],\n",
      "\n",
      "        [[ 0.0652, -0.0576]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6196, -0.7725]],\n",
      "\n",
      "        [[-0.6365, -0.7532]],\n",
      "\n",
      "        [[-0.6265, -0.7646]],\n",
      "\n",
      "        [[-0.6386, -0.7508]],\n",
      "\n",
      "        [[-0.6267, -0.7644]],\n",
      "\n",
      "        [[-0.6296, -0.7611]],\n",
      "\n",
      "        [[-0.6349, -0.7550]],\n",
      "\n",
      "        [[-0.6196, -0.7726]],\n",
      "\n",
      "        [[-0.6198, -0.7723]],\n",
      "\n",
      "        [[-0.6295, -0.7611]],\n",
      "\n",
      "        [[-0.6289, -0.7619]],\n",
      "\n",
      "        [[-0.6111, -0.7825]],\n",
      "\n",
      "        [[-0.6213, -0.7705]],\n",
      "\n",
      "        [[-0.6053, -0.7895]],\n",
      "\n",
      "        [[-0.6319, -0.7584]],\n",
      "\n",
      "        [[-0.6336, -0.7565]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0719, -0.0723]],\n",
      "\n",
      "        [[ 0.0828, -0.0250]],\n",
      "\n",
      "        [[ 0.0674, -0.1156]],\n",
      "\n",
      "        [[ 0.0968, -0.0620]],\n",
      "\n",
      "        [[ 0.0690, -0.0743]],\n",
      "\n",
      "        [[ 0.0827, -0.0591]],\n",
      "\n",
      "        [[ 0.0625, -0.0559]],\n",
      "\n",
      "        [[ 0.0695, -0.0754]],\n",
      "\n",
      "        [[ 0.0511, -0.0916]],\n",
      "\n",
      "        [[ 0.0905, -0.0187]],\n",
      "\n",
      "        [[ 0.0930, -0.0294]],\n",
      "\n",
      "        [[ 0.0831, -0.0279]],\n",
      "\n",
      "        [[ 0.1017, -0.1040]],\n",
      "\n",
      "        [[ 0.0612, -0.0531]],\n",
      "\n",
      "        [[ 0.0728, -0.0079]],\n",
      "\n",
      "        [[ 0.1200, -0.0888]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6237, -0.7678]],\n",
      "\n",
      "        [[-0.6407, -0.7485]],\n",
      "\n",
      "        [[-0.6058, -0.7888]],\n",
      "\n",
      "        [[-0.6169, -0.7757]],\n",
      "\n",
      "        [[-0.6241, -0.7673]],\n",
      "\n",
      "        [[-0.6248, -0.7665]],\n",
      "\n",
      "        [[-0.6357, -0.7541]],\n",
      "\n",
      "        [[-0.6233, -0.7682]],\n",
      "\n",
      "        [[-0.6243, -0.7670]],\n",
      "\n",
      "        [[-0.6400, -0.7493]],\n",
      "\n",
      "        [[-0.6338, -0.7563]],\n",
      "\n",
      "        [[-0.6392, -0.7502]],\n",
      "\n",
      "        [[-0.5956, -0.8013]],\n",
      "\n",
      "        [[-0.6376, -0.7519]],\n",
      "\n",
      "        [[-0.6536, -0.7343]],\n",
      "\n",
      "        [[-0.5942, -0.8030]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0719, -0.0651]],\n",
      "\n",
      "        [[ 0.0714, -0.0510]],\n",
      "\n",
      "        [[ 0.1146, -0.0891]],\n",
      "\n",
      "        [[ 0.0687, -0.0640]],\n",
      "\n",
      "        [[ 0.0550, -0.0836]],\n",
      "\n",
      "        [[ 0.0914, -0.0275]],\n",
      "\n",
      "        [[ 0.0598, -0.0857]],\n",
      "\n",
      "        [[ 0.0848, -0.0771]],\n",
      "\n",
      "        [[ 0.0729, -0.0618]],\n",
      "\n",
      "        [[ 0.0908, -0.0657]],\n",
      "\n",
      "        [[ 0.0762, -0.0499]],\n",
      "\n",
      "        [[ 0.0882, -0.0355]],\n",
      "\n",
      "        [[ 0.0513, -0.0760]],\n",
      "\n",
      "        [[ 0.1164, -0.0234]],\n",
      "\n",
      "        [[ 0.0585, -0.0655]],\n",
      "\n",
      "        [[ 0.1272, -0.0095]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6270, -0.7640]],\n",
      "\n",
      "        [[-0.6338, -0.7562]],\n",
      "\n",
      "        [[-0.5965, -0.8001]],\n",
      "\n",
      "        [[-0.6290, -0.7617]],\n",
      "\n",
      "        [[-0.6262, -0.7649]],\n",
      "\n",
      "        [[-0.6355, -0.7544]],\n",
      "\n",
      "        [[-0.6230, -0.7686]],\n",
      "\n",
      "        [[-0.6155, -0.7774]],\n",
      "\n",
      "        [[-0.6280, -0.7628]],\n",
      "\n",
      "        [[-0.6179, -0.7745]],\n",
      "\n",
      "        [[-0.6321, -0.7582]],\n",
      "\n",
      "        [[-0.6332, -0.7569]],\n",
      "\n",
      "        [[-0.6315, -0.7588]],\n",
      "\n",
      "        [[-0.6257, -0.7655]],\n",
      "\n",
      "        [[-0.6331, -0.7571]],\n",
      "\n",
      "        [[-0.6271, -0.7638]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1140, -0.0896]],\n",
      "\n",
      "        [[ 0.0533, -0.0694]],\n",
      "\n",
      "        [[ 0.0720, -0.0598]],\n",
      "\n",
      "        [[ 0.1052, -0.1169]],\n",
      "\n",
      "        [[ 0.0735, -0.0694]],\n",
      "\n",
      "        [[ 0.0793, -0.0626]],\n",
      "\n",
      "        [[ 0.0772, -0.0447]],\n",
      "\n",
      "        [[ 0.0907, -0.0814]],\n",
      "\n",
      "        [[ 0.0424, -0.0866]],\n",
      "\n",
      "        [[ 0.0554, -0.0864]],\n",
      "\n",
      "        [[ 0.0939, -0.0731]],\n",
      "\n",
      "        [[ 0.0868, -0.0586]],\n",
      "\n",
      "        [[ 0.0873, -0.0612]],\n",
      "\n",
      "        [[ 0.1071, -0.0299]],\n",
      "\n",
      "        [[ 0.0425, -0.0286]],\n",
      "\n",
      "        [[ 0.0828, -0.0667]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5965, -0.8001]],\n",
      "\n",
      "        [[-0.6337, -0.7564]],\n",
      "\n",
      "        [[-0.6294, -0.7612]],\n",
      "\n",
      "        [[-0.5883, -0.8103]],\n",
      "\n",
      "        [[-0.6243, -0.7671]],\n",
      "\n",
      "        [[-0.6247, -0.7666]],\n",
      "\n",
      "        [[-0.6341, -0.7560]],\n",
      "\n",
      "        [[-0.6108, -0.7829]],\n",
      "\n",
      "        [[-0.6307, -0.7597]],\n",
      "\n",
      "        [[-0.6247, -0.7666]],\n",
      "\n",
      "        [[-0.6131, -0.7801]],\n",
      "\n",
      "        [[-0.6231, -0.7685]],\n",
      "\n",
      "        [[-0.6217, -0.7701]],\n",
      "\n",
      "        [[-0.6270, -0.7640]],\n",
      "\n",
      "        [[-0.6583, -0.7293]],\n",
      "\n",
      "        [[-0.6212, -0.7707]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0807, -0.0671]],\n",
      "\n",
      "        [[ 0.1128, -0.0243]],\n",
      "\n",
      "        [[ 0.0760, -0.0426]],\n",
      "\n",
      "        [[ 0.0875, -0.0814]],\n",
      "\n",
      "        [[ 0.0904, -0.0771]],\n",
      "\n",
      "        [[ 0.0613, -0.0979]],\n",
      "\n",
      "        [[ 0.0827, -0.0751]],\n",
      "\n",
      "        [[ 0.1168, -0.0692]],\n",
      "\n",
      "        [[ 0.1133, -0.0734]],\n",
      "\n",
      "        [[ 0.1233, -0.0351]],\n",
      "\n",
      "        [[ 0.0851, -0.1012]],\n",
      "\n",
      "        [[ 0.1285, -0.0904]],\n",
      "\n",
      "        [[ 0.1074, -0.0779]],\n",
      "\n",
      "        [[ 0.0979, -0.0779]],\n",
      "\n",
      "        [[ 0.1309, -0.0481]],\n",
      "\n",
      "        [[ 0.0622, -0.0495]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6220, -0.7698]],\n",
      "\n",
      "        [[-0.6269, -0.7641]],\n",
      "\n",
      "        [[-0.6356, -0.7542]],\n",
      "\n",
      "        [[-0.6123, -0.7812]],\n",
      "\n",
      "        [[-0.6129, -0.7804]],\n",
      "\n",
      "        [[-0.6167, -0.7759]],\n",
      "\n",
      "        [[-0.6174, -0.7752]],\n",
      "\n",
      "        [[-0.6045, -0.7905]],\n",
      "\n",
      "        [[-0.6041, -0.7909]],\n",
      "\n",
      "        [[-0.6171, -0.7755]],\n",
      "\n",
      "        [[-0.6043, -0.7906]],\n",
      "\n",
      "        [[-0.5897, -0.8086]],\n",
      "\n",
      "        [[-0.6048, -0.7901]],\n",
      "\n",
      "        [[-0.6091, -0.7849]],\n",
      "\n",
      "        [[-0.6077, -0.7866]],\n",
      "\n",
      "        [[-0.6389, -0.7505]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0815, -0.0803]],\n",
      "\n",
      "        [[ 0.1151, -0.0150]],\n",
      "\n",
      "        [[ 0.0904, -0.0330]],\n",
      "\n",
      "        [[ 0.0565, -0.0728]],\n",
      "\n",
      "        [[ 0.0792, -0.0719]],\n",
      "\n",
      "        [[ 0.0736, -0.0645]],\n",
      "\n",
      "        [[ 0.0973, -0.0944]],\n",
      "\n",
      "        [[ 0.0684, -0.0683]],\n",
      "\n",
      "        [[ 0.1088, -0.1084]],\n",
      "\n",
      "        [[ 0.0736, -0.0895]],\n",
      "\n",
      "        [[ 0.0846, -0.0702]],\n",
      "\n",
      "        [[ 0.0479, -0.0779]],\n",
      "\n",
      "        [[ 0.0608, -0.0906]],\n",
      "\n",
      "        [[ 0.0815, -0.0936]],\n",
      "\n",
      "        [[ 0.0947, -0.0663]],\n",
      "\n",
      "        [[ 0.1446, -0.0738]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6155, -0.7773]],\n",
      "\n",
      "        [[-0.6302, -0.7603]],\n",
      "\n",
      "        [[-0.6333, -0.7568]],\n",
      "\n",
      "        [[-0.6306, -0.7599]],\n",
      "\n",
      "        [[-0.6204, -0.7716]],\n",
      "\n",
      "        [[-0.6265, -0.7646]],\n",
      "\n",
      "        [[-0.6019, -0.7936]],\n",
      "\n",
      "        [[-0.6272, -0.7638]],\n",
      "\n",
      "        [[-0.5904, -0.8076]],\n",
      "\n",
      "        [[-0.6149, -0.7780]],\n",
      "\n",
      "        [[-0.6188, -0.7735]],\n",
      "\n",
      "        [[-0.6322, -0.7580]],\n",
      "\n",
      "        [[-0.6203, -0.7718]],\n",
      "\n",
      "        [[-0.6094, -0.7845]],\n",
      "\n",
      "        [[-0.6159, -0.7769]],\n",
      "\n",
      "        [[-0.5899, -0.8083]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1105, -0.0591]],\n",
      "\n",
      "        [[ 0.0846, -0.0901]],\n",
      "\n",
      "        [[ 0.0769, -0.0660]],\n",
      "\n",
      "        [[ 0.0443, -0.0881]],\n",
      "\n",
      "        [[ 0.1410, -0.0753]],\n",
      "\n",
      "        [[ 0.0961, -0.0620]],\n",
      "\n",
      "        [[ 0.0620, -0.0691]],\n",
      "\n",
      "        [[ 0.1151, -0.0539]],\n",
      "\n",
      "        [[ 0.1385, -0.0720]],\n",
      "\n",
      "        [[ 0.0953, -0.0867]],\n",
      "\n",
      "        [[ 0.1298, -0.0801]],\n",
      "\n",
      "        [[ 0.1089, -0.0875]],\n",
      "\n",
      "        [[ 0.0793, -0.0604]],\n",
      "\n",
      "        [[ 0.0704, -0.0670]],\n",
      "\n",
      "        [[ 0.0470, -0.0950]],\n",
      "\n",
      "        [[ 0.1112, -0.0317]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6119, -0.7815]],\n",
      "\n",
      "        [[-0.6096, -0.7843]],\n",
      "\n",
      "        [[-0.6243, -0.7671]],\n",
      "\n",
      "        [[-0.6291, -0.7615]],\n",
      "\n",
      "        [[-0.5909, -0.8071]],\n",
      "\n",
      "        [[-0.6173, -0.7753]],\n",
      "\n",
      "        [[-0.6297, -0.7608]],\n",
      "\n",
      "        [[-0.6122, -0.7812]],\n",
      "\n",
      "        [[-0.5934, -0.8039]],\n",
      "\n",
      "        [[-0.6063, -0.7883]],\n",
      "\n",
      "        [[-0.5937, -0.8036]],\n",
      "\n",
      "        [[-0.5998, -0.7961]],\n",
      "\n",
      "        [[-0.6257, -0.7655]],\n",
      "\n",
      "        [[-0.6268, -0.7642]],\n",
      "\n",
      "        [[-0.6247, -0.7666]],\n",
      "\n",
      "        [[-0.6243, -0.7671]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0807, -0.0759]],\n",
      "\n",
      "        [[ 0.0742, -0.0607]],\n",
      "\n",
      "        [[ 0.1080, -0.1009]],\n",
      "\n",
      "        [[ 0.0852, -0.1071]],\n",
      "\n",
      "        [[ 0.1212, -0.1003]],\n",
      "\n",
      "        [[ 0.1523, -0.0655]],\n",
      "\n",
      "        [[ 0.1151, -0.0475]],\n",
      "\n",
      "        [[ 0.1699, -0.1181]],\n",
      "\n",
      "        [[ 0.1251, -0.0553]],\n",
      "\n",
      "        [[ 0.1362, -0.0986]],\n",
      "\n",
      "        [[ 0.0718, -0.0563]],\n",
      "\n",
      "        [[ 0.0963, -0.0129]],\n",
      "\n",
      "        [[ 0.1624, -0.1101]],\n",
      "\n",
      "        [[ 0.1435, -0.1071]],\n",
      "\n",
      "        [[ 0.1066, -0.0272]],\n",
      "\n",
      "        [[ 0.1351, -0.0972]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6179, -0.7745]],\n",
      "\n",
      "        [[-0.6280, -0.7628]],\n",
      "\n",
      "        [[-0.5941, -0.8030]],\n",
      "\n",
      "        [[-0.6016, -0.7939]],\n",
      "\n",
      "        [[-0.5885, -0.8100]],\n",
      "\n",
      "        [[-0.5902, -0.8080]],\n",
      "\n",
      "        [[-0.6151, -0.7778]],\n",
      "\n",
      "        [[-0.5595, -0.8475]],\n",
      "\n",
      "        [[-0.6070, -0.7874]],\n",
      "\n",
      "        [[-0.5826, -0.8174]],\n",
      "\n",
      "        [[-0.6311, -0.7592]],\n",
      "\n",
      "        [[-0.6400, -0.7493]],\n",
      "\n",
      "        [[-0.5662, -0.8386]],\n",
      "\n",
      "        [[-0.5757, -0.8263]],\n",
      "\n",
      "        [[-0.6285, -0.7623]],\n",
      "\n",
      "        [[-0.5837, -0.8160]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0772, -0.1091]],\n",
      "\n",
      "        [[ 0.0929, -0.0955]],\n",
      "\n",
      "        [[ 0.0939, -0.0424]],\n",
      "\n",
      "        [[ 0.1034, -0.0742]],\n",
      "\n",
      "        [[ 0.1268, -0.0825]],\n",
      "\n",
      "        [[ 0.0988, -0.0264]],\n",
      "\n",
      "        [[ 0.1252, -0.0543]],\n",
      "\n",
      "        [[ 0.1081, -0.0663]],\n",
      "\n",
      "        [[ 0.0767, -0.0709]],\n",
      "\n",
      "        [[ 0.1133, -0.0412]],\n",
      "\n",
      "        [[ 0.0855, -0.0805]],\n",
      "\n",
      "        [[ 0.0996, -0.0882]],\n",
      "\n",
      "        [[ 0.1433, -0.0831]],\n",
      "\n",
      "        [[ 0.1105, -0.0536]],\n",
      "\n",
      "        [[ 0.1417, -0.0926]],\n",
      "\n",
      "        [[ 0.1252, -0.0330]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6043, -0.7906]],\n",
      "\n",
      "        [[-0.6034, -0.7918]],\n",
      "\n",
      "        [[-0.6273, -0.7637]],\n",
      "\n",
      "        [[-0.6083, -0.7859]],\n",
      "\n",
      "        [[-0.5940, -0.8033]],\n",
      "\n",
      "        [[-0.6325, -0.7577]],\n",
      "\n",
      "        [[-0.6074, -0.7869]],\n",
      "\n",
      "        [[-0.6097, -0.7842]],\n",
      "\n",
      "        [[-0.6221, -0.7697]],\n",
      "\n",
      "        [[-0.6189, -0.7734]],\n",
      "\n",
      "        [[-0.6136, -0.7796]],\n",
      "\n",
      "        [[-0.6036, -0.7915]],\n",
      "\n",
      "        [[-0.5864, -0.8127]],\n",
      "\n",
      "        [[-0.6145, -0.7785]],\n",
      "\n",
      "        [[-0.5828, -0.8172]],\n",
      "\n",
      "        [[-0.6171, -0.7754]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1253, -0.1202]],\n",
      "\n",
      "        [[ 0.1019, -0.0834]],\n",
      "\n",
      "        [[ 0.1164, -0.1179]],\n",
      "\n",
      "        [[ 0.1125, -0.0656]],\n",
      "\n",
      "        [[ 0.1113, -0.0420]],\n",
      "\n",
      "        [[ 0.1056, -0.0647]],\n",
      "\n",
      "        [[ 0.1258, -0.0360]],\n",
      "\n",
      "        [[ 0.0841, -0.0751]],\n",
      "\n",
      "        [[ 0.1096, -0.0863]],\n",
      "\n",
      "        [[ 0.1246, -0.0565]],\n",
      "\n",
      "        [[ 0.0864, -0.0577]],\n",
      "\n",
      "        [[ 0.1055, -0.0177]],\n",
      "\n",
      "        [[ 0.0978, -0.0686]],\n",
      "\n",
      "        [[ 0.1025, -0.0879]],\n",
      "\n",
      "        [[ 0.1447, -0.0132]],\n",
      "\n",
      "        [[ 0.0740, -0.0889]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5779, -0.8234]],\n",
      "\n",
      "        [[-0.6048, -0.7901]],\n",
      "\n",
      "        [[-0.5829, -0.8171]],\n",
      "\n",
      "        [[-0.6080, -0.7862]],\n",
      "\n",
      "        [[-0.6195, -0.7727]],\n",
      "\n",
      "        [[-0.6117, -0.7819]],\n",
      "\n",
      "        [[-0.6155, -0.7773]],\n",
      "\n",
      "        [[-0.6167, -0.7759]],\n",
      "\n",
      "        [[-0.6000, -0.7958]],\n",
      "\n",
      "        [[-0.6067, -0.7878]],\n",
      "\n",
      "        [[-0.6237, -0.7678]],\n",
      "\n",
      "        [[-0.6335, -0.7566]],\n",
      "\n",
      "        [[-0.6134, -0.7798]],\n",
      "\n",
      "        [[-0.6025, -0.7928]],\n",
      "\n",
      "        [[-0.6173, -0.7752]],\n",
      "\n",
      "        [[-0.6150, -0.7779]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1054, -0.0927]],\n",
      "\n",
      "        [[ 0.0771, -0.0876]],\n",
      "\n",
      "        [[ 0.0970, -0.0373]],\n",
      "\n",
      "        [[ 0.0968, -0.0348]],\n",
      "\n",
      "        [[ 0.1267, -0.0732]],\n",
      "\n",
      "        [[ 0.1261, -0.0802]],\n",
      "\n",
      "        [[ 0.0894, -0.0785]],\n",
      "\n",
      "        [[ 0.1190, -0.0981]],\n",
      "\n",
      "        [[ 0.2150, -0.0997]],\n",
      "\n",
      "        [[ 0.0881, -0.0950]],\n",
      "\n",
      "        [[ 0.0859, -0.1153]],\n",
      "\n",
      "        [[ 0.0639, -0.0400]],\n",
      "\n",
      "        [[ 0.1258, -0.0690]],\n",
      "\n",
      "        [[ 0.1042, -0.0962]],\n",
      "\n",
      "        [[ 0.1095, -0.0769]],\n",
      "\n",
      "        [[ 0.1368, -0.0754]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5990, -0.7971]],\n",
      "\n",
      "        [[-0.6142, -0.7789]],\n",
      "\n",
      "        [[-0.6282, -0.7626]],\n",
      "\n",
      "        [[-0.6295, -0.7612]],\n",
      "\n",
      "        [[-0.5982, -0.7981]],\n",
      "\n",
      "        [[-0.5953, -0.8016]],\n",
      "\n",
      "        [[-0.6127, -0.7806]],\n",
      "\n",
      "        [[-0.5905, -0.8076]],\n",
      "\n",
      "        [[-0.5481, -0.8628]],\n",
      "\n",
      "        [[-0.6058, -0.7889]],\n",
      "\n",
      "        [[-0.5976, -0.7988]],\n",
      "\n",
      "        [[-0.6425, -0.7465]],\n",
      "\n",
      "        [[-0.6005, -0.7953]],\n",
      "\n",
      "        [[-0.5980, -0.7984]],\n",
      "\n",
      "        [[-0.6043, -0.7907]],\n",
      "\n",
      "        [[-0.5927, -0.8049]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0793, -0.0873]],\n",
      "\n",
      "        [[ 0.1111, -0.0908]],\n",
      "\n",
      "        [[ 0.0761, -0.1033]],\n",
      "\n",
      "        [[ 0.1545, -0.1194]],\n",
      "\n",
      "        [[ 0.1316, -0.0755]],\n",
      "\n",
      "        [[ 0.1187, -0.0953]],\n",
      "\n",
      "        [[ 0.0875, -0.1140]],\n",
      "\n",
      "        [[ 0.0981, -0.0867]],\n",
      "\n",
      "        [[ 0.0991, -0.0807]],\n",
      "\n",
      "        [[ 0.0653, -0.0765]],\n",
      "\n",
      "        [[ 0.1212, -0.0818]],\n",
      "\n",
      "        [[ 0.1380, -0.1120]],\n",
      "\n",
      "        [[ 0.1056, -0.0725]],\n",
      "\n",
      "        [[ 0.1125, -0.0158]],\n",
      "\n",
      "        [[ 0.0959, -0.1136]],\n",
      "\n",
      "        [[ 0.0860, -0.0942]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6133, -0.7799]],\n",
      "\n",
      "        [[-0.5973, -0.7992]],\n",
      "\n",
      "        [[-0.6074, -0.7869]],\n",
      "\n",
      "        [[-0.5656, -0.8394]],\n",
      "\n",
      "        [[-0.5949, -0.8021]],\n",
      "\n",
      "        [[-0.5919, -0.8059]],\n",
      "\n",
      "        [[-0.5974, -0.7990]],\n",
      "\n",
      "        [[-0.6050, -0.7898]],\n",
      "\n",
      "        [[-0.6073, -0.7871]],\n",
      "\n",
      "        [[-0.6248, -0.7666]],\n",
      "\n",
      "        [[-0.5968, -0.7998]],\n",
      "\n",
      "        [[-0.5759, -0.8259]],\n",
      "\n",
      "        [[-0.6081, -0.7862]],\n",
      "\n",
      "        [[-0.6311, -0.7594]],\n",
      "\n",
      "        [[-0.5939, -0.8033]],\n",
      "\n",
      "        [[-0.6071, -0.7873]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0824, -0.0814]],\n",
      "\n",
      "        [[ 0.1021, -0.0948]],\n",
      "\n",
      "        [[ 0.1482, -0.0909]],\n",
      "\n",
      "        [[ 0.1309, -0.0928]],\n",
      "\n",
      "        [[ 0.0637, -0.0914]],\n",
      "\n",
      "        [[ 0.0898, -0.0740]],\n",
      "\n",
      "        [[ 0.1052, -0.0471]],\n",
      "\n",
      "        [[ 0.0884, -0.0640]],\n",
      "\n",
      "        [[ 0.1278, -0.0663]],\n",
      "\n",
      "        [[ 0.0703, -0.0609]],\n",
      "\n",
      "        [[ 0.1077, -0.0969]],\n",
      "\n",
      "        [[ 0.1047, -0.0832]],\n",
      "\n",
      "        [[ 0.0856, -0.0737]],\n",
      "\n",
      "        [[ 0.1205, -0.0944]],\n",
      "\n",
      "        [[ 0.0653, -0.0719]],\n",
      "\n",
      "        [[ 0.0923, -0.0657]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6146, -0.7784]],\n",
      "\n",
      "        [[-0.5995, -0.7964]],\n",
      "\n",
      "        [[-0.5808, -0.8198]],\n",
      "\n",
      "        [[-0.5875, -0.8112]],\n",
      "\n",
      "        [[-0.6186, -0.7737]],\n",
      "\n",
      "        [[-0.6146, -0.7784]],\n",
      "\n",
      "        [[-0.6199, -0.7722]],\n",
      "\n",
      "        [[-0.6198, -0.7723]],\n",
      "\n",
      "        [[-0.6008, -0.7949]],\n",
      "\n",
      "        [[-0.6297, -0.7609]],\n",
      "\n",
      "        [[-0.5961, -0.8006]],\n",
      "\n",
      "        [[-0.6036, -0.7915]],\n",
      "\n",
      "        [[-0.6166, -0.7760]],\n",
      "\n",
      "        [[-0.5914, -0.8064]],\n",
      "\n",
      "        [[-0.6269, -0.7641]],\n",
      "\n",
      "        [[-0.6173, -0.7753]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1373, -0.0434]],\n",
      "\n",
      "        [[ 0.1251, -0.0887]],\n",
      "\n",
      "        [[ 0.0787, -0.0988]],\n",
      "\n",
      "        [[ 0.0888, -0.0224]],\n",
      "\n",
      "        [[ 0.1007, -0.0633]],\n",
      "\n",
      "        [[ 0.1321, -0.0752]],\n",
      "\n",
      "        [[ 0.1231, -0.0285]],\n",
      "\n",
      "        [[ 0.1767, -0.1220]],\n",
      "\n",
      "        [[ 0.1498, -0.0458]],\n",
      "\n",
      "        [[ 0.1010, -0.1024]],\n",
      "\n",
      "        [[ 0.0922, -0.0448]],\n",
      "\n",
      "        [[ 0.0817, -0.1048]],\n",
      "\n",
      "        [[ 0.0938, -0.0647]],\n",
      "\n",
      "        [[ 0.1032, -0.1207]],\n",
      "\n",
      "        [[ 0.1183, -0.0863]],\n",
      "\n",
      "        [[ 0.0804, -0.0331]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6069, -0.7876]],\n",
      "\n",
      "        [[-0.5919, -0.8058]],\n",
      "\n",
      "        [[-0.6084, -0.7858]],\n",
      "\n",
      "        [[-0.6391, -0.7502]],\n",
      "\n",
      "        [[-0.6145, -0.7785]],\n",
      "\n",
      "        [[-0.5949, -0.8021]],\n",
      "\n",
      "        [[-0.6202, -0.7718]],\n",
      "\n",
      "        [[-0.5549, -0.8536]],\n",
      "\n",
      "        [[-0.6001, -0.7958]],\n",
      "\n",
      "        [[-0.5966, -0.8000]],\n",
      "\n",
      "        [[-0.6270, -0.7640]],\n",
      "\n",
      "        [[-0.6043, -0.7907]],\n",
      "\n",
      "        [[-0.6170, -0.7755]],\n",
      "\n",
      "        [[-0.5875, -0.8113]],\n",
      "\n",
      "        [[-0.5960, -0.8007]],\n",
      "\n",
      "        [[-0.6380, -0.7515]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1060, -0.0999]],\n",
      "\n",
      "        [[ 0.0852, -0.0750]],\n",
      "\n",
      "        [[ 0.1213, -0.0442]],\n",
      "\n",
      "        [[ 0.1074, -0.0768]],\n",
      "\n",
      "        [[ 0.1727, -0.1122]],\n",
      "\n",
      "        [[ 0.1158, -0.0859]],\n",
      "\n",
      "        [[ 0.0809, -0.1133]],\n",
      "\n",
      "        [[ 0.0921, -0.0694]],\n",
      "\n",
      "        [[ 0.1289, -0.1458]],\n",
      "\n",
      "        [[ 0.0872, -0.0847]],\n",
      "\n",
      "        [[ 0.1053, -0.0830]],\n",
      "\n",
      "        [[ 0.1171, -0.0539]],\n",
      "\n",
      "        [[ 0.1208, -0.1137]],\n",
      "\n",
      "        [[ 0.1311, -0.0654]],\n",
      "\n",
      "        [[ 0.1014, -0.0605]],\n",
      "\n",
      "        [[ 0.1060, -0.0462]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5955, -0.8014]],\n",
      "\n",
      "        [[-0.6163, -0.7764]],\n",
      "\n",
      "        [[-0.6138, -0.7793]],\n",
      "\n",
      "        [[-0.6053, -0.7895]],\n",
      "\n",
      "        [[-0.5608, -0.8457]],\n",
      "\n",
      "        [[-0.5974, -0.7991]],\n",
      "\n",
      "        [[-0.6008, -0.7949]],\n",
      "\n",
      "        [[-0.6157, -0.7771]],\n",
      "\n",
      "        [[-0.5652, -0.8399]],\n",
      "\n",
      "        [[-0.6109, -0.7828]],\n",
      "\n",
      "        [[-0.6034, -0.7917]],\n",
      "\n",
      "        [[-0.6113, -0.7823]],\n",
      "\n",
      "        [[-0.5827, -0.8173]],\n",
      "\n",
      "        [[-0.5997, -0.7962]],\n",
      "\n",
      "        [[-0.6155, -0.7774]],\n",
      "\n",
      "        [[-0.6200, -0.7721]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1223, -0.0893]],\n",
      "\n",
      "        [[ 0.1060, -0.0733]],\n",
      "\n",
      "        [[ 0.1147, -0.0716]],\n",
      "\n",
      "        [[ 0.0495, -0.0337]],\n",
      "\n",
      "        [[ 0.0793, -0.0743]],\n",
      "\n",
      "        [[ 0.0849, -0.0258]],\n",
      "\n",
      "        [[ 0.0881, -0.0472]],\n",
      "\n",
      "        [[ 0.0893, -0.0314]],\n",
      "\n",
      "        [[ 0.0901, -0.0830]],\n",
      "\n",
      "        [[ 0.1057, -0.0670]],\n",
      "\n",
      "        [[ 0.0824, -0.0429]],\n",
      "\n",
      "        [[ 0.0920, -0.0779]],\n",
      "\n",
      "        [[ 0.0796, -0.0826]],\n",
      "\n",
      "        [[ 0.1179, -0.0460]],\n",
      "\n",
      "        [[ 0.1156, -0.1035]],\n",
      "\n",
      "        [[ 0.0672, -0.1132]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5929, -0.8046]],\n",
      "\n",
      "        [[-0.6075, -0.7868]],\n",
      "\n",
      "        [[-0.6043, -0.7906]],\n",
      "\n",
      "        [[-0.6524, -0.7356]],\n",
      "\n",
      "        [[-0.6193, -0.7729]],\n",
      "\n",
      "        [[-0.6393, -0.7501]],\n",
      "\n",
      "        [[-0.6278, -0.7631]],\n",
      "\n",
      "        [[-0.6346, -0.7553]],\n",
      "\n",
      "        [[-0.6103, -0.7835]],\n",
      "\n",
      "        [[-0.6105, -0.7832]],\n",
      "\n",
      "        [[-0.6325, -0.7577]],\n",
      "\n",
      "        [[-0.6118, -0.7817]],\n",
      "\n",
      "        [[-0.6153, -0.7775]],\n",
      "\n",
      "        [[-0.6146, -0.7784]],\n",
      "\n",
      "        [[-0.5896, -0.8087]],\n",
      "\n",
      "        [[-0.6070, -0.7875]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0766, -0.0078]],\n",
      "\n",
      "        [[ 0.0842, -0.0232]],\n",
      "\n",
      "        [[ 0.1071, -0.0831]],\n",
      "\n",
      "        [[ 0.0848, -0.1021]],\n",
      "\n",
      "        [[ 0.0910, -0.0852]],\n",
      "\n",
      "        [[ 0.1072, -0.0677]],\n",
      "\n",
      "        [[ 0.1490, -0.1160]],\n",
      "\n",
      "        [[ 0.0789, -0.0618]],\n",
      "\n",
      "        [[ 0.1077, -0.0892]],\n",
      "\n",
      "        [[ 0.0782, -0.0768]],\n",
      "\n",
      "        [[ 0.1527, -0.1316]],\n",
      "\n",
      "        [[ 0.0950, -0.0574]],\n",
      "\n",
      "        [[ 0.1821, -0.1205]],\n",
      "\n",
      "        [[ 0.0736, -0.0570]],\n",
      "\n",
      "        [[ 0.0790, -0.0846]],\n",
      "\n",
      "        [[ 0.0926, -0.1050]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6518, -0.7363]],\n",
      "\n",
      "        [[-0.6409, -0.7482]],\n",
      "\n",
      "        [[-0.6026, -0.7928]],\n",
      "\n",
      "        [[-0.6041, -0.7910]],\n",
      "\n",
      "        [[-0.6090, -0.7851]],\n",
      "\n",
      "        [[-0.6095, -0.7845]],\n",
      "\n",
      "        [[-0.5694, -0.8344]],\n",
      "\n",
      "        [[-0.6253, -0.7660]],\n",
      "\n",
      "        [[-0.5995, -0.7964]],\n",
      "\n",
      "        [[-0.6187, -0.7736]],\n",
      "\n",
      "        [[-0.5611, -0.8454]],\n",
      "\n",
      "        [[-0.6199, -0.7722]],\n",
      "\n",
      "        [[-0.5533, -0.8558]],\n",
      "\n",
      "        [[-0.6300, -0.7606]],\n",
      "\n",
      "        [[-0.6147, -0.7783]],\n",
      "\n",
      "        [[-0.5992, -0.7968]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.1796, -0.1179]],\n",
      "\n",
      "        [[ 0.0845, -0.0771]],\n",
      "\n",
      "        [[ 0.0377, -0.0727]],\n",
      "\n",
      "        [[ 0.0684, -0.0442]],\n",
      "\n",
      "        [[ 0.1083, -0.0926]],\n",
      "\n",
      "        [[ 0.1017, -0.0617]],\n",
      "\n",
      "        [[ 0.0717, -0.0601]],\n",
      "\n",
      "        [[ 0.0740, -0.0843]],\n",
      "\n",
      "        [[ 0.0517, -0.0924]],\n",
      "\n",
      "        [[ 0.1135, -0.0723]],\n",
      "\n",
      "        [[ 0.0923, -0.0435]],\n",
      "\n",
      "        [[ 0.1077, -0.0500]],\n",
      "\n",
      "        [[ 0.0793, -0.0974]],\n",
      "\n",
      "        [[ 0.1077, -0.0976]],\n",
      "\n",
      "        [[ 0.0933, -0.0984]],\n",
      "\n",
      "        [[ 0.0932, -0.0757]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5554, -0.8529]],\n",
      "\n",
      "        [[-0.6156, -0.7772]],\n",
      "\n",
      "        [[-0.6395, -0.7499]],\n",
      "\n",
      "        [[-0.6385, -0.7510]],\n",
      "\n",
      "        [[-0.5978, -0.7986]],\n",
      "\n",
      "        [[-0.6148, -0.7781]],\n",
      "\n",
      "        [[-0.6294, -0.7612]],\n",
      "\n",
      "        [[-0.6171, -0.7754]],\n",
      "\n",
      "        [[-0.6237, -0.7678]],\n",
      "\n",
      "        [[-0.6045, -0.7904]],\n",
      "\n",
      "        [[-0.6275, -0.7634]],\n",
      "\n",
      "        [[-0.6174, -0.7751]],\n",
      "\n",
      "        [[-0.6087, -0.7854]],\n",
      "\n",
      "        [[-0.5958, -0.8010]],\n",
      "\n",
      "        [[-0.6019, -0.7936]],\n",
      "\n",
      "        [[-0.6123, -0.7812]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0735, -0.1028]],\n",
      "\n",
      "        [[ 0.0660, -0.0904]],\n",
      "\n",
      "        [[ 0.1072, -0.0683]],\n",
      "\n",
      "        [[ 0.0900, -0.1013]],\n",
      "\n",
      "        [[ 0.1020, -0.0237]],\n",
      "\n",
      "        [[ 0.0738, -0.0819]],\n",
      "\n",
      "        [[ 0.0869, -0.0336]],\n",
      "\n",
      "        [[ 0.0636, -0.0769]],\n",
      "\n",
      "        [[ 0.0807,  0.0035]],\n",
      "\n",
      "        [[ 0.0774, -0.0849]],\n",
      "\n",
      "        [[ 0.0892, -0.0861]],\n",
      "\n",
      "        [[ 0.0917, -0.0514]],\n",
      "\n",
      "        [[ 0.0525, -0.0396]],\n",
      "\n",
      "        [[ 0.1035, -0.0653]],\n",
      "\n",
      "        [[ 0.0639, -0.0660]],\n",
      "\n",
      "        [[ 0.0905, -0.0653]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6089, -0.7852]],\n",
      "\n",
      "        [[-0.6180, -0.7744]],\n",
      "\n",
      "        [[-0.6092, -0.7847]],\n",
      "\n",
      "        [[-0.6021, -0.7934]],\n",
      "\n",
      "        [[-0.6323, -0.7579]],\n",
      "\n",
      "        [[-0.6183, -0.7741]],\n",
      "\n",
      "        [[-0.6347, -0.7552]],\n",
      "\n",
      "        [[-0.6253, -0.7659]],\n",
      "\n",
      "        [[-0.6553, -0.7325]],\n",
      "\n",
      "        [[-0.6153, -0.7776]],\n",
      "\n",
      "        [[-0.6094, -0.7846]],\n",
      "\n",
      "        [[-0.6242, -0.7673]],\n",
      "\n",
      "        [[-0.6482, -0.7403]],\n",
      "\n",
      "        [[-0.6123, -0.7811]],\n",
      "\n",
      "        [[-0.6303, -0.7602]],\n",
      "\n",
      "        [[-0.6183, -0.7741]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.1243, -0.0962]],\n",
      "\n",
      "        [[ 0.1054, -0.0671]],\n",
      "\n",
      "        [[ 0.0866, -0.0719]],\n",
      "\n",
      "        [[ 0.0948, -0.0387]],\n",
      "\n",
      "        [[ 0.0570, -0.0645]],\n",
      "\n",
      "        [[ 0.0842, -0.0450]],\n",
      "\n",
      "        [[ 0.0590, -0.0313]],\n",
      "\n",
      "        [[ 0.0832, -0.0767]],\n",
      "\n",
      "        [[ 0.1306, -0.0725]],\n",
      "\n",
      "        [[ 0.1105, -0.0795]],\n",
      "\n",
      "        [[ 0.0894, -0.0863]],\n",
      "\n",
      "        [[ 0.1170, -0.0872]],\n",
      "\n",
      "        [[ 0.0769, -0.0499]],\n",
      "\n",
      "        [[ 0.0711, -0.0700]],\n",
      "\n",
      "        [[ 0.0685, -0.0897]],\n",
      "\n",
      "        [[ 0.0948, -0.0758]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.5890, -0.8094]],\n",
      "\n",
      "        [[-0.6106, -0.7831]],\n",
      "\n",
      "        [[-0.6171, -0.7755]],\n",
      "\n",
      "        [[-0.6286, -0.7621]],\n",
      "\n",
      "        [[-0.6343, -0.7557]],\n",
      "\n",
      "        [[-0.6306, -0.7598]],\n",
      "\n",
      "        [[-0.6490, -0.7393]],\n",
      "\n",
      "        [[-0.6164, -0.7763]],\n",
      "\n",
      "        [[-0.5968, -0.7998]],\n",
      "\n",
      "        [[-0.6026, -0.7927]],\n",
      "\n",
      "        [[-0.6092, -0.7848]],\n",
      "\n",
      "        [[-0.5962, -0.8005]],\n",
      "\n",
      "        [[-0.6318, -0.7585]],\n",
      "\n",
      "        [[-0.6251, -0.7662]],\n",
      "\n",
      "        [[-0.6172, -0.7754]],\n",
      "\n",
      "        [[-0.6115, -0.7821]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0992, -0.0496]],\n",
      "\n",
      "        [[ 0.0802, -0.0661]],\n",
      "\n",
      "        [[ 0.0481, -0.0511]],\n",
      "\n",
      "        [[ 0.0589, -0.0268]],\n",
      "\n",
      "        [[ 0.0511, -0.0784]],\n",
      "\n",
      "        [[ 0.1191, -0.0312]],\n",
      "\n",
      "        [[ 0.0389,  0.0244]],\n",
      "\n",
      "        [[ 0.0785, -0.0728]],\n",
      "\n",
      "        [[ 0.0388, -0.0797]],\n",
      "\n",
      "        [[ 0.0752, -0.0779]],\n",
      "\n",
      "        [[ 0.0915, -0.0919]],\n",
      "\n",
      "        [[ 0.0817, -0.0434]],\n",
      "\n",
      "        [[ 0.0628, -0.0789]],\n",
      "\n",
      "        [[ 0.0696, -0.0722]],\n",
      "\n",
      "        [[ 0.0884, -0.0558]],\n",
      "\n",
      "        [[ 0.0818, -0.0379]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6215, -0.7703]],\n",
      "\n",
      "        [[-0.6227, -0.7689]],\n",
      "\n",
      "        [[-0.6448, -0.7440]],\n",
      "\n",
      "        [[-0.6512, -0.7369]],\n",
      "\n",
      "        [[-0.6305, -0.7600]],\n",
      "\n",
      "        [[-0.6208, -0.7711]],\n",
      "\n",
      "        [[-0.6860, -0.7004]],\n",
      "\n",
      "        [[-0.6203, -0.7717]],\n",
      "\n",
      "        [[-0.6356, -0.7542]],\n",
      "\n",
      "        [[-0.6195, -0.7726]],\n",
      "\n",
      "        [[-0.6057, -0.7890]],\n",
      "\n",
      "        [[-0.6325, -0.7577]],\n",
      "\n",
      "        [[-0.6248, -0.7665]],\n",
      "\n",
      "        [[-0.6248, -0.7665]],\n",
      "\n",
      "        [[-0.6237, -0.7678]],\n",
      "\n",
      "        [[-0.6351, -0.7548]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0063, -0.0004]],\n",
      "\n",
      "        [[ 0.0635,  0.0131]],\n",
      "\n",
      "        [[ 0.0727, -0.0711]],\n",
      "\n",
      "        [[ 0.0850, -0.0451]],\n",
      "\n",
      "        [[ 0.0284, -0.0228]],\n",
      "\n",
      "        [[ 0.0577,  0.0133]],\n",
      "\n",
      "        [[ 0.0995, -0.0609]],\n",
      "\n",
      "        [[ 0.0775, -0.0219]],\n",
      "\n",
      "        [[ 0.1275, -0.0938]],\n",
      "\n",
      "        [[ 0.0675, -0.0711]],\n",
      "\n",
      "        [[ 0.0788, -0.0788]],\n",
      "\n",
      "        [[ 0.0769, -0.0727]],\n",
      "\n",
      "        [[ 0.0639, -0.0341]],\n",
      "\n",
      "        [[ 0.0684, -0.0203]],\n",
      "\n",
      "        [[ 0.0645, -0.0729]],\n",
      "\n",
      "        [[ 0.0428, -0.0594]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6898, -0.6965]],\n",
      "\n",
      "        [[-0.6683, -0.7187]],\n",
      "\n",
      "        [[-0.6238, -0.7676]],\n",
      "\n",
      "        [[-0.6302, -0.7603]],\n",
      "\n",
      "        [[-0.6679, -0.7191]],\n",
      "\n",
      "        [[-0.6712, -0.7156]],\n",
      "\n",
      "        [[-0.6162, -0.7766]],\n",
      "\n",
      "        [[-0.6446, -0.7441]],\n",
      "\n",
      "        [[-0.5886, -0.8099]],\n",
      "\n",
      "        [[-0.6262, -0.7648]],\n",
      "\n",
      "        [[-0.6175, -0.7750]],\n",
      "\n",
      "        [[-0.6211, -0.7708]],\n",
      "\n",
      "        [[-0.6454, -0.7433]],\n",
      "\n",
      "        [[-0.6498, -0.7385]],\n",
      "\n",
      "        [[-0.6268, -0.7642]],\n",
      "\n",
      "        [[-0.6434, -0.7455]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0585, -0.0576]],\n",
      "\n",
      "        [[ 0.0690,  0.0105]],\n",
      "\n",
      "        [[ 0.0508, -0.0534]],\n",
      "\n",
      "        [[ 0.0791, -0.0577]],\n",
      "\n",
      "        [[ 0.0826, -0.0176]],\n",
      "\n",
      "        [[ 0.1009, -0.0419]],\n",
      "\n",
      "        [[ 0.0667, -0.0384]],\n",
      "\n",
      "        [[ 0.1057, -0.0543]],\n",
      "\n",
      "        [[ 0.0527, -0.0432]],\n",
      "\n",
      "        [[ 0.0774,  0.0054]],\n",
      "\n",
      "        [[ 0.0836, -0.0016]],\n",
      "\n",
      "        [[ 0.0753, -0.0148]],\n",
      "\n",
      "        [[ 0.0940, -0.0534]],\n",
      "\n",
      "        [[ 0.0851, -0.0540]],\n",
      "\n",
      "        [[ 0.0681, -0.0508]],\n",
      "\n",
      "        [[ 0.0769, -0.0483]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6368, -0.7529]],\n",
      "\n",
      "        [[-0.6643, -0.7228]],\n",
      "\n",
      "        [[-0.6424, -0.7466]],\n",
      "\n",
      "        [[-0.6270, -0.7639]],\n",
      "\n",
      "        [[-0.6443, -0.7445]],\n",
      "\n",
      "        [[-0.6243, -0.7671]],\n",
      "\n",
      "        [[-0.6420, -0.7471]],\n",
      "\n",
      "        [[-0.6164, -0.7763]],\n",
      "\n",
      "        [[-0.6464, -0.7422]],\n",
      "\n",
      "        [[-0.6578, -0.7298]],\n",
      "\n",
      "        [[-0.6514, -0.7367]],\n",
      "\n",
      "        [[-0.6491, -0.7392]],\n",
      "\n",
      "        [[-0.6222, -0.7695]],\n",
      "\n",
      "        [[-0.6260, -0.7651]],\n",
      "\n",
      "        [[-0.6355, -0.7544]],\n",
      "\n",
      "        [[-0.6325, -0.7577]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0591, -0.0238]],\n",
      "\n",
      "        [[ 0.0629, -0.0102]],\n",
      "\n",
      "        [[ 0.0572, -0.0087]],\n",
      "\n",
      "        [[ 0.0793, -0.0402]],\n",
      "\n",
      "        [[ 0.0645, -0.0308]],\n",
      "\n",
      "        [[ 0.0790, -0.0150]],\n",
      "\n",
      "        [[ 0.0503, -0.0713]],\n",
      "\n",
      "        [[ 0.0509, -0.0194]],\n",
      "\n",
      "        [[ 0.0453,  0.0104]],\n",
      "\n",
      "        [[ 0.0724, -0.0527]],\n",
      "\n",
      "        [[ 0.0669, -0.0435]],\n",
      "\n",
      "        [[ 0.0335, -0.0694]],\n",
      "\n",
      "        [[ 0.0564, -0.0306]],\n",
      "\n",
      "        [[ 0.0985, -0.0847]],\n",
      "\n",
      "        [[ 0.0438, -0.0482]],\n",
      "\n",
      "        [[ 0.0637,  0.0002]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6526, -0.7354]],\n",
      "\n",
      "        [[-0.6573, -0.7304]],\n",
      "\n",
      "        [[-0.6607, -0.7266]],\n",
      "\n",
      "        [[-0.6352, -0.7546]],\n",
      "\n",
      "        [[-0.6466, -0.7420]],\n",
      "\n",
      "        [[-0.6473, -0.7412]],\n",
      "\n",
      "        [[-0.6342, -0.7558]],\n",
      "\n",
      "        [[-0.6586, -0.7289]],\n",
      "\n",
      "        [[-0.6758, -0.7108]],\n",
      "\n",
      "        [[-0.6326, -0.7576]],\n",
      "\n",
      "        [[-0.6394, -0.7499]],\n",
      "\n",
      "        [[-0.6430, -0.7459]],\n",
      "\n",
      "        [[-0.6506, -0.7376]],\n",
      "\n",
      "        [[-0.6057, -0.7890]],\n",
      "\n",
      "        [[-0.6482, -0.7402]],\n",
      "\n",
      "        [[-0.6619, -0.7254]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0597,  0.0314]],\n",
      "\n",
      "        [[ 0.0545, -0.0107]],\n",
      "\n",
      "        [[ 0.0463, -0.0051]],\n",
      "\n",
      "        [[ 0.0495, -0.0384]],\n",
      "\n",
      "        [[ 0.0379, -0.0421]],\n",
      "\n",
      "        [[ 0.0663, -0.0389]],\n",
      "\n",
      "        [[ 0.0544, -0.0026]],\n",
      "\n",
      "        [[ 0.0486, -0.0101]],\n",
      "\n",
      "        [[ 0.0661, -0.0614]],\n",
      "\n",
      "        [[ 0.0934, -0.0398]],\n",
      "\n",
      "        [[ 0.0476,  0.0038]],\n",
      "\n",
      "        [[ 0.0432, -0.0271]],\n",
      "\n",
      "        [[ 0.0442, -0.0385]],\n",
      "\n",
      "        [[ 0.0377, -0.0260]],\n",
      "\n",
      "        [[ 0.0453, -0.0574]],\n",
      "\n",
      "        [[ 0.0114,  0.0092]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6791, -0.7074]],\n",
      "\n",
      "        [[-0.6611, -0.7263]],\n",
      "\n",
      "        [[-0.6677, -0.7192]],\n",
      "\n",
      "        [[-0.6502, -0.7381]],\n",
      "\n",
      "        [[-0.6539, -0.7340]],\n",
      "\n",
      "        [[-0.6420, -0.7471]],\n",
      "\n",
      "        [[-0.6650, -0.7221]],\n",
      "\n",
      "        [[-0.6642, -0.7229]],\n",
      "\n",
      "        [[-0.6314, -0.7589]],\n",
      "\n",
      "        [[-0.6287, -0.7620]],\n",
      "\n",
      "        [[-0.6714, -0.7153]],\n",
      "\n",
      "        [[-0.6586, -0.7289]],\n",
      "\n",
      "        [[-0.6526, -0.7354]],\n",
      "\n",
      "        [[-0.6618, -0.7255]],\n",
      "\n",
      "        [[-0.6431, -0.7458]],\n",
      "\n",
      "        [[-0.6921, -0.6942]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0487,  0.0358]],\n",
      "\n",
      "        [[ 0.0472, -0.0425]],\n",
      "\n",
      "        [[ 0.0360,  0.0184]],\n",
      "\n",
      "        [[ 0.0657, -0.0324]],\n",
      "\n",
      "        [[ 0.0223,  0.0131]],\n",
      "\n",
      "        [[ 0.0067,  0.0309]],\n",
      "\n",
      "        [[ 0.0036, -0.0036]],\n",
      "\n",
      "        [[ 0.0472, -0.0171]],\n",
      "\n",
      "        [[ 0.0269, -0.0269]],\n",
      "\n",
      "        [[ 0.0514, -0.0093]],\n",
      "\n",
      "        [[-0.0132,  0.0070]],\n",
      "\n",
      "        [[ 0.0582,  0.0046]],\n",
      "\n",
      "        [[ 0.0409, -0.0015]],\n",
      "\n",
      "        [[ 0.0009, -0.0085]],\n",
      "\n",
      "        [[ 0.1031, -0.0662]],\n",
      "\n",
      "        [[ 0.0176,  0.0421]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6867, -0.6996]],\n",
      "\n",
      "        [[-0.6493, -0.7390]],\n",
      "\n",
      "        [[-0.6844, -0.7020]],\n",
      "\n",
      "        [[-0.6453, -0.7434]],\n",
      "\n",
      "        [[-0.6886, -0.6978]],\n",
      "\n",
      "        [[-0.7053, -0.6811]],\n",
      "\n",
      "        [[-0.6895, -0.6968]],\n",
      "\n",
      "        [[-0.6615, -0.7258]],\n",
      "\n",
      "        [[-0.6666, -0.7204]],\n",
      "\n",
      "        [[-0.6632, -0.7240]],\n",
      "\n",
      "        [[-0.7033, -0.6831]],\n",
      "\n",
      "        [[-0.6667, -0.7203]],\n",
      "\n",
      "        [[-0.6721, -0.7146]],\n",
      "\n",
      "        [[-0.6885, -0.6978]],\n",
      "\n",
      "        [[-0.6121, -0.7814]],\n",
      "\n",
      "        [[-0.7055, -0.6809]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0609, -0.0225]],\n",
      "\n",
      "        [[-0.0079, -0.0235]],\n",
      "\n",
      "        [[ 0.0332,  0.0497]],\n",
      "\n",
      "        [[ 0.0287, -0.0040]],\n",
      "\n",
      "        [[ 0.0469,  0.0082]],\n",
      "\n",
      "        [[ 0.0658, -0.0238]],\n",
      "\n",
      "        [[ 0.0071,  0.0747]],\n",
      "\n",
      "        [[ 0.0575, -0.0407]],\n",
      "\n",
      "        [[ 0.0150,  0.0094]],\n",
      "\n",
      "        [[ 0.0361, -0.0317]],\n",
      "\n",
      "        [[ 0.0163, -0.0305]],\n",
      "\n",
      "        [[ 0.0559, -0.0270]],\n",
      "\n",
      "        [[ 0.0108,  0.0527]],\n",
      "\n",
      "        [[ 0.0299,  0.0216]],\n",
      "\n",
      "        [[ 0.0540,  0.0240]],\n",
      "\n",
      "        [[ 0.0195, -0.0413]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6523, -0.7357]],\n",
      "\n",
      "        [[-0.6854, -0.7010]],\n",
      "\n",
      "        [[-0.7014, -0.6849]],\n",
      "\n",
      "        [[-0.6769, -0.7096]],\n",
      "\n",
      "        [[-0.6740, -0.7127]],\n",
      "\n",
      "        [[-0.6493, -0.7390]],\n",
      "\n",
      "        [[-0.7275, -0.6599]],\n",
      "\n",
      "        [[-0.6453, -0.7434]],\n",
      "\n",
      "        [[-0.6904, -0.6959]],\n",
      "\n",
      "        [[-0.6598, -0.7276]],\n",
      "\n",
      "        [[-0.6700, -0.7168]],\n",
      "\n",
      "        [[-0.6526, -0.7355]],\n",
      "\n",
      "        [[-0.7143, -0.6725]],\n",
      "\n",
      "        [[-0.6890, -0.6973]],\n",
      "\n",
      "        [[-0.6783, -0.7083]],\n",
      "\n",
      "        [[-0.6632, -0.7240]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.0239,  0.0171]],\n",
      "\n",
      "        [[ 0.0105,  0.0440]],\n",
      "\n",
      "        [[ 0.0368,  0.0009]],\n",
      "\n",
      "        [[ 0.0177,  0.0488]],\n",
      "\n",
      "        [[ 0.0131,  0.0250]],\n",
      "\n",
      "        [[ 0.0646, -0.0011]],\n",
      "\n",
      "        [[-0.0058,  0.0629]],\n",
      "\n",
      "        [[ 0.0117,  0.0087]],\n",
      "\n",
      "        [[ 0.0215, -0.0187]],\n",
      "\n",
      "        [[ 0.0230,  0.0023]],\n",
      "\n",
      "        [[ 0.0574, -0.0093]],\n",
      "\n",
      "        [[ 0.0187,  0.0029]],\n",
      "\n",
      "        [[ 0.0263, -0.0180]],\n",
      "\n",
      "        [[-0.0117, -0.0061]],\n",
      "\n",
      "        [[ 0.0517,  0.0014]],\n",
      "\n",
      "        [[-0.0059,  0.0325]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6897, -0.6966]],\n",
      "\n",
      "        [[-0.7100, -0.6765]],\n",
      "\n",
      "        [[-0.6753, -0.7113]],\n",
      "\n",
      "        [[-0.7088, -0.6778]],\n",
      "\n",
      "        [[-0.6991, -0.6872]],\n",
      "\n",
      "        [[-0.6609, -0.7265]],\n",
      "\n",
      "        [[-0.7281, -0.6594]],\n",
      "\n",
      "        [[-0.6917, -0.6946]],\n",
      "\n",
      "        [[-0.6732, -0.7135]],\n",
      "\n",
      "        [[-0.6828, -0.7036]],\n",
      "\n",
      "        [[-0.6604, -0.7270]],\n",
      "\n",
      "        [[-0.6853, -0.7011]],\n",
      "\n",
      "        [[-0.6712, -0.7155]],\n",
      "\n",
      "        [[-0.6959, -0.6904]],\n",
      "\n",
      "        [[-0.6683, -0.7186]],\n",
      "\n",
      "        [[-0.7126, -0.6741]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0126,  0.0309]],\n",
      "\n",
      "        [[ 0.0320,  0.0066]],\n",
      "\n",
      "        [[-0.0132,  0.0615]],\n",
      "\n",
      "        [[ 0.0202, -0.0205]],\n",
      "\n",
      "        [[ 0.0251,  0.0281]],\n",
      "\n",
      "        [[ 0.0306, -0.0323]],\n",
      "\n",
      "        [[ 0.0219, -0.0183]],\n",
      "\n",
      "        [[ 0.0656,  0.0137]],\n",
      "\n",
      "        [[ 0.0628, -0.0031]],\n",
      "\n",
      "        [[ 0.0102, -0.0323]],\n",
      "\n",
      "        [[ 0.0431, -0.0017]],\n",
      "\n",
      "        [[ 0.0087,  0.0225]],\n",
      "\n",
      "        [[ 0.0409, -0.0274]],\n",
      "\n",
      "        [[ 0.0299,  0.0287]],\n",
      "\n",
      "        [[ 0.0419, -0.0286]],\n",
      "\n",
      "        [[ 0.0427, -0.0310]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7023, -0.6840]],\n",
      "\n",
      "        [[-0.6805, -0.7059]],\n",
      "\n",
      "        [[-0.7312, -0.6565]],\n",
      "\n",
      "        [[-0.6730, -0.7137]],\n",
      "\n",
      "        [[-0.6947, -0.6916]],\n",
      "\n",
      "        [[-0.6622, -0.7251]],\n",
      "\n",
      "        [[-0.6733, -0.7134]],\n",
      "\n",
      "        [[-0.6675, -0.7195]],\n",
      "\n",
      "        [[-0.6607, -0.7267]],\n",
      "\n",
      "        [[-0.6721, -0.7146]],\n",
      "\n",
      "        [[-0.6710, -0.7158]],\n",
      "\n",
      "        [[-0.7001, -0.6863]],\n",
      "\n",
      "        [[-0.6596, -0.7279]],\n",
      "\n",
      "        [[-0.6925, -0.6938]],\n",
      "\n",
      "        [[-0.6586, -0.7290]],\n",
      "\n",
      "        [[-0.6570, -0.7307]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0254, -0.0140]],\n",
      "\n",
      "        [[ 0.0062,  0.0029]],\n",
      "\n",
      "        [[ 0.0193, -0.0162]],\n",
      "\n",
      "        [[-0.0303,  0.0570]],\n",
      "\n",
      "        [[-0.0140,  0.0300]],\n",
      "\n",
      "        [[ 0.0259,  0.0029]],\n",
      "\n",
      "        [[ 0.0168, -0.0113]],\n",
      "\n",
      "        [[ 0.0536, -0.0122]],\n",
      "\n",
      "        [[-0.0319,  0.1096]],\n",
      "\n",
      "        [[-0.0891,  0.0689]],\n",
      "\n",
      "        [[ 0.0294, -0.0048]],\n",
      "\n",
      "        [[ 0.0242,  0.0246]],\n",
      "\n",
      "        [[ 0.0170,  0.0476]],\n",
      "\n",
      "        [[ 0.0012,  0.0147]],\n",
      "\n",
      "        [[-0.0061,  0.0356]],\n",
      "\n",
      "        [[ 0.0095, -0.0158]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6737, -0.7130]],\n",
      "\n",
      "        [[-0.6915, -0.6948]],\n",
      "\n",
      "        [[-0.6756, -0.7111]],\n",
      "\n",
      "        [[-0.7378, -0.6504]],\n",
      "\n",
      "        [[-0.7154, -0.6714]],\n",
      "\n",
      "        [[-0.6817, -0.7047]],\n",
      "\n",
      "        [[-0.6792, -0.7073]],\n",
      "\n",
      "        [[-0.6608, -0.7266]],\n",
      "\n",
      "        [[-0.7664, -0.6249]],\n",
      "\n",
      "        [[-0.7752, -0.6173]],\n",
      "\n",
      "        [[-0.6762, -0.7104]],\n",
      "\n",
      "        [[-0.6933, -0.6930]],\n",
      "\n",
      "        [[-0.7086, -0.6779]],\n",
      "\n",
      "        [[-0.6999, -0.6864]],\n",
      "\n",
      "        [[-0.7142, -0.6725]],\n",
      "\n",
      "        [[-0.6806, -0.7059]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0147,  0.0723]],\n",
      "\n",
      "        [[ 0.0124, -0.0256]],\n",
      "\n",
      "        [[-0.0256,  0.0094]],\n",
      "\n",
      "        [[ 0.0072,  0.0223]],\n",
      "\n",
      "        [[-0.0118,  0.0535]],\n",
      "\n",
      "        [[ 0.0340,  0.0781]],\n",
      "\n",
      "        [[ 0.0165,  0.0696]],\n",
      "\n",
      "        [[ 0.0277, -0.0308]],\n",
      "\n",
      "        [[ 0.0482, -0.0175]],\n",
      "\n",
      "        [[ 0.0025,  0.0491]],\n",
      "\n",
      "        [[ 0.0113,  0.0359]],\n",
      "\n",
      "        [[-0.0039, -0.0286]],\n",
      "\n",
      "        [[ 0.0067,  0.0056]],\n",
      "\n",
      "        [[-0.0229,  0.0380]],\n",
      "\n",
      "        [[ 0.0316, -0.0057]],\n",
      "\n",
      "        [[ 0.0120,  0.0057]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7223, -0.6648]],\n",
      "\n",
      "        [[-0.6744, -0.7123]],\n",
      "\n",
      "        [[-0.7108, -0.6758]],\n",
      "\n",
      "        [[-0.7007, -0.6856]],\n",
      "\n",
      "        [[-0.7263, -0.6611]],\n",
      "\n",
      "        [[-0.7154, -0.6714]],\n",
      "\n",
      "        [[-0.7201, -0.6669]],\n",
      "\n",
      "        [[-0.6643, -0.7228]],\n",
      "\n",
      "        [[-0.6608, -0.7265]],\n",
      "\n",
      "        [[-0.7167, -0.6701]],\n",
      "\n",
      "        [[-0.7055, -0.6809]],\n",
      "\n",
      "        [[-0.6809, -0.7056]],\n",
      "\n",
      "        [[-0.6926, -0.6937]],\n",
      "\n",
      "        [[-0.7241, -0.6632]],\n",
      "\n",
      "        [[-0.6746, -0.7120]],\n",
      "\n",
      "        [[-0.6900, -0.6963]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0121,  0.0843]],\n",
      "\n",
      "        [[ 0.0114,  0.0456]],\n",
      "\n",
      "        [[ 0.0166, -0.0058]],\n",
      "\n",
      "        [[-0.0143,  0.0485]],\n",
      "\n",
      "        [[ 0.0213,  0.0687]],\n",
      "\n",
      "        [[ 0.0064,  0.0392]],\n",
      "\n",
      "        [[ 0.0090,  0.0161]],\n",
      "\n",
      "        [[-0.0179,  0.0309]],\n",
      "\n",
      "        [[-0.0141, -0.0074]],\n",
      "\n",
      "        [[-0.0119,  0.0427]],\n",
      "\n",
      "        [[ 0.0095,  0.0410]],\n",
      "\n",
      "        [[-0.0192,  0.0673]],\n",
      "\n",
      "        [[-0.0119,  0.0208]],\n",
      "\n",
      "        [[ 0.0094,  0.0607]],\n",
      "\n",
      "        [[ 0.0110,  0.0738]],\n",
      "\n",
      "        [[-0.0308,  0.0947]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7299, -0.6577]],\n",
      "\n",
      "        [[-0.7104, -0.6762]],\n",
      "\n",
      "        [[-0.6820, -0.7044]],\n",
      "\n",
      "        [[-0.7250, -0.6623]],\n",
      "\n",
      "        [[-0.7171, -0.6697]],\n",
      "\n",
      "        [[-0.7097, -0.6769]],\n",
      "\n",
      "        [[-0.6967, -0.6896]],\n",
      "\n",
      "        [[-0.7178, -0.6691]],\n",
      "\n",
      "        [[-0.6965, -0.6898]],\n",
      "\n",
      "        [[-0.7208, -0.6662]],\n",
      "\n",
      "        [[-0.7090, -0.6775]],\n",
      "\n",
      "        [[-0.7373, -0.6508]],\n",
      "\n",
      "        [[-0.7096, -0.6769]],\n",
      "\n",
      "        [[-0.7191, -0.6678]],\n",
      "\n",
      "        [[-0.7251, -0.6622]],\n",
      "\n",
      "        [[-0.7579, -0.6324]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0104,  0.0309]],\n",
      "\n",
      "        [[ 0.0138,  0.0110]],\n",
      "\n",
      "        [[ 0.0503,  0.0239]],\n",
      "\n",
      "        [[-0.0151,  0.1054]],\n",
      "\n",
      "        [[-0.0492,  0.0719]],\n",
      "\n",
      "        [[-0.0121,  0.0707]],\n",
      "\n",
      "        [[-0.0654,  0.0529]],\n",
      "\n",
      "        [[ 0.0256,  0.0390]],\n",
      "\n",
      "        [[-0.0397,  0.0889]],\n",
      "\n",
      "        [[ 0.0038,  0.0369]],\n",
      "\n",
      "        [[-0.0104,  0.0390]],\n",
      "\n",
      "        [[-0.0078,  0.0922]],\n",
      "\n",
      "        [[-0.0355,  0.0830]],\n",
      "\n",
      "        [[ 0.0126, -0.0016]],\n",
      "\n",
      "        [[ 0.0110,  0.0787]],\n",
      "\n",
      "        [[-0.0351,  0.0780]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7140, -0.6727]],\n",
      "\n",
      "        [[-0.6917, -0.6946]],\n",
      "\n",
      "        [[-0.6800, -0.7064]],\n",
      "\n",
      "        [[-0.7552, -0.6347]],\n",
      "\n",
      "        [[-0.7555, -0.6344]],\n",
      "\n",
      "        [[-0.7354, -0.6526]],\n",
      "\n",
      "        [[-0.7540, -0.6358]],\n",
      "\n",
      "        [[-0.6998, -0.6865]],\n",
      "\n",
      "        [[-0.7595, -0.6309]],\n",
      "\n",
      "        [[-0.7098, -0.6768]],\n",
      "\n",
      "        [[-0.7181, -0.6688]],\n",
      "\n",
      "        [[-0.7444, -0.6444]],\n",
      "\n",
      "        [[-0.7541, -0.6357]],\n",
      "\n",
      "        [[-0.6861, -0.7003]],\n",
      "\n",
      "        [[-0.7275, -0.6599]],\n",
      "\n",
      "        [[-0.7513, -0.6382]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0305,  0.0794]],\n",
      "\n",
      "        [[-0.0107,  0.0457]],\n",
      "\n",
      "        [[ 0.0184,  0.0151]],\n",
      "\n",
      "        [[ 0.0369,  0.0422]],\n",
      "\n",
      "        [[-0.0616,  0.1076]],\n",
      "\n",
      "        [[ 0.0241,  0.0328]],\n",
      "\n",
      "        [[-0.0675,  0.1371]],\n",
      "\n",
      "        [[-0.0079,  0.0351]],\n",
      "\n",
      "        [[-0.0237,  0.0721]],\n",
      "\n",
      "        [[-0.0058,  0.0485]],\n",
      "\n",
      "        [[ 0.0272, -0.0194]],\n",
      "\n",
      "        [[ 0.0126,  0.0544]],\n",
      "\n",
      "        [[-0.0093,  0.0362]],\n",
      "\n",
      "        [[-0.0397,  0.0726]],\n",
      "\n",
      "        [[-0.0132,  0.1009]],\n",
      "\n",
      "        [[-0.0412,  0.0938]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7496, -0.6397]],\n",
      "\n",
      "        [[-0.7217, -0.6653]],\n",
      "\n",
      "        [[-0.6915, -0.6948]],\n",
      "\n",
      "        [[-0.6958, -0.6905]],\n",
      "\n",
      "        [[-0.7813, -0.6121]],\n",
      "\n",
      "        [[-0.6975, -0.6888]],\n",
      "\n",
      "        [[-0.8007, -0.5961]],\n",
      "\n",
      "        [[-0.7148, -0.6719]],\n",
      "\n",
      "        [[-0.7422, -0.6464]],\n",
      "\n",
      "        [[-0.7207, -0.6664]],\n",
      "\n",
      "        [[-0.6701, -0.7167]],\n",
      "\n",
      "        [[-0.7142, -0.6725]],\n",
      "\n",
      "        [[-0.7162, -0.6706]],\n",
      "\n",
      "        [[-0.7509, -0.6386]],\n",
      "\n",
      "        [[-0.7518, -0.6377]],\n",
      "\n",
      "        [[-0.7629, -0.6279]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0134, -0.0167]],\n",
      "\n",
      "        [[-0.0436,  0.0812]],\n",
      "\n",
      "        [[-0.0568,  0.1266]],\n",
      "\n",
      "        [[ 0.0208,  0.0962]],\n",
      "\n",
      "        [[-0.0408,  0.0920]],\n",
      "\n",
      "        [[-0.0659,  0.0635]],\n",
      "\n",
      "        [[-0.0190,  0.0426]],\n",
      "\n",
      "        [[ 0.0131,  0.0460]],\n",
      "\n",
      "        [[-0.0233,  0.0533]],\n",
      "\n",
      "        [[-0.0302,  0.0172]],\n",
      "\n",
      "        [[-0.0105,  0.0374]],\n",
      "\n",
      "        [[ 0.0320,  0.0193]],\n",
      "\n",
      "        [[ 0.0060,  0.0264]],\n",
      "\n",
      "        [[-0.0048,  0.0140]],\n",
      "\n",
      "        [[-0.0013,  0.0340]],\n",
      "\n",
      "        [[-0.0211,  0.0349]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.6782, -0.7083]],\n",
      "\n",
      "        [[-0.7575, -0.6327]],\n",
      "\n",
      "        [[-0.7890, -0.6057]],\n",
      "\n",
      "        [[-0.7316, -0.6562]],\n",
      "\n",
      "        [[-0.7618, -0.6289]],\n",
      "\n",
      "        [[-0.7599, -0.6305]],\n",
      "\n",
      "        [[-0.7244, -0.6628]],\n",
      "\n",
      "        [[-0.7097, -0.6768]],\n",
      "\n",
      "        [[-0.7322, -0.6556]],\n",
      "\n",
      "        [[-0.7171, -0.6697]],\n",
      "\n",
      "        [[-0.7174, -0.6695]],\n",
      "\n",
      "        [[-0.6868, -0.6995]],\n",
      "\n",
      "        [[-0.7034, -0.6830]],\n",
      "\n",
      "        [[-0.7026, -0.6838]],\n",
      "\n",
      "        [[-0.7109, -0.6757]],\n",
      "\n",
      "        [[-0.7215, -0.6655]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0295,  0.0426]],\n",
      "\n",
      "        [[-0.0050,  0.0347]],\n",
      "\n",
      "        [[ 0.0496,  0.0611]],\n",
      "\n",
      "        [[-0.0156,  0.0817]],\n",
      "\n",
      "        [[-0.0180,  0.0369]],\n",
      "\n",
      "        [[-0.0260,  0.1133]],\n",
      "\n",
      "        [[-0.0208,  0.0638]],\n",
      "\n",
      "        [[-0.0169,  0.0629]],\n",
      "\n",
      "        [[-0.0442,  0.0376]],\n",
      "\n",
      "        [[ 0.0151,  0.0566]],\n",
      "\n",
      "        [[-0.0231, -0.0105]],\n",
      "\n",
      "        [[-0.0407,  0.0342]],\n",
      "\n",
      "        [[-0.0179,  0.0664]],\n",
      "\n",
      "        [[ 0.0221,  0.0730]],\n",
      "\n",
      "        [[-0.0117,  0.0466]],\n",
      "\n",
      "        [[-0.0303,  0.0902]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7298, -0.6578]],\n",
      "\n",
      "        [[-0.7132, -0.6735]],\n",
      "\n",
      "        [[-0.6989, -0.6874]],\n",
      "\n",
      "        [[-0.7430, -0.6457]],\n",
      "\n",
      "        [[-0.7210, -0.6661]],\n",
      "\n",
      "        [[-0.7652, -0.6259]],\n",
      "\n",
      "        [[-0.7364, -0.6517]],\n",
      "\n",
      "        [[-0.7338, -0.6541]],\n",
      "\n",
      "        [[-0.7348, -0.6531]],\n",
      "\n",
      "        [[-0.7141, -0.6726]],\n",
      "\n",
      "        [[-0.6995, -0.6869]],\n",
      "\n",
      "        [[-0.7313, -0.6564]],\n",
      "\n",
      "        [[-0.7362, -0.6519]],\n",
      "\n",
      "        [[-0.7189, -0.6680]],\n",
      "\n",
      "        [[-0.7227, -0.6644]],\n",
      "\n",
      "        [[-0.7552, -0.6348]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0232,  0.0957]],\n",
      "\n",
      "        [[-0.0071,  0.1044]],\n",
      "\n",
      "        [[ 0.0142,  0.0613]],\n",
      "\n",
      "        [[-0.0640,  0.0723]],\n",
      "\n",
      "        [[-0.1063,  0.1216]],\n",
      "\n",
      "        [[-0.0363,  0.0772]],\n",
      "\n",
      "        [[-0.0228,  0.0544]],\n",
      "\n",
      "        [[-0.0115,  0.0006]],\n",
      "\n",
      "        [[-0.0404,  0.0851]],\n",
      "\n",
      "        [[-0.0236,  0.0714]],\n",
      "\n",
      "        [[-0.0172,  0.0471]],\n",
      "\n",
      "        [[-0.0719,  0.0646]],\n",
      "\n",
      "        [[-0.0969,  0.1139]],\n",
      "\n",
      "        [[-0.0084,  0.0415]],\n",
      "\n",
      "        [[-0.0272,  0.0163]],\n",
      "\n",
      "        [[-0.0228,  0.0643]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7543, -0.6355]],\n",
      "\n",
      "        [[-0.7504, -0.6390]],\n",
      "\n",
      "        [[-0.7170, -0.6699]],\n",
      "\n",
      "        [[-0.7636, -0.6273]],\n",
      "\n",
      "        [[-0.8136, -0.5857]],\n",
      "\n",
      "        [[-0.7515, -0.6380]],\n",
      "\n",
      "        [[-0.7325, -0.6553]],\n",
      "\n",
      "        [[-0.6992, -0.6871]],\n",
      "\n",
      "        [[-0.7578, -0.6324]],\n",
      "\n",
      "        [[-0.7418, -0.6468]],\n",
      "\n",
      "        [[-0.7258, -0.6615]],\n",
      "\n",
      "        [[-0.7637, -0.6272]],\n",
      "\n",
      "        [[-0.8041, -0.5933]],\n",
      "\n",
      "        [[-0.7184, -0.6685]],\n",
      "\n",
      "        [[-0.7151, -0.6716]],\n",
      "\n",
      "        [[-0.7376, -0.6506]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0540,  0.0818]],\n",
      "\n",
      "        [[-0.0471,  0.0896]],\n",
      "\n",
      "        [[ 0.0021,  0.0441]],\n",
      "\n",
      "        [[-0.0678,  0.0657]],\n",
      "\n",
      "        [[ 0.0047,  0.0435]],\n",
      "\n",
      "        [[-0.0880,  0.1151]],\n",
      "\n",
      "        [[-0.0204,  0.0093]],\n",
      "\n",
      "        [[-0.0159,  0.0293]],\n",
      "\n",
      "        [[-0.0321,  0.1333]],\n",
      "\n",
      "        [[-0.0641,  0.0875]],\n",
      "\n",
      "        [[-0.0486,  0.1164]],\n",
      "\n",
      "        [[-0.0204,  0.0889]],\n",
      "\n",
      "        [[-0.0070,  0.0222]],\n",
      "\n",
      "        [[-0.0005,  0.0481]],\n",
      "\n",
      "        [[ 0.0122,  0.0463]],\n",
      "\n",
      "        [[-0.0436,  0.1011]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7634, -0.6275]],\n",
      "\n",
      "        [[-0.7638, -0.6271]],\n",
      "\n",
      "        [[-0.7143, -0.6724]],\n",
      "\n",
      "        [[-0.7621, -0.6286]],\n",
      "\n",
      "        [[-0.7127, -0.6739]],\n",
      "\n",
      "        [[-0.7998, -0.5968]],\n",
      "\n",
      "        [[-0.7081, -0.6784]],\n",
      "\n",
      "        [[-0.7160, -0.6708]],\n",
      "\n",
      "        [[-0.7792, -0.6139]],\n",
      "\n",
      "        [[-0.7718, -0.6202]],\n",
      "\n",
      "        [[-0.7790, -0.6140]],\n",
      "\n",
      "        [[-0.7493, -0.6400]],\n",
      "\n",
      "        [[-0.7078, -0.6787]],\n",
      "\n",
      "        [[-0.7178, -0.6691]],\n",
      "\n",
      "        [[-0.7104, -0.6762]],\n",
      "\n",
      "        [[-0.7681, -0.6234]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0285,  0.0312]],\n",
      "\n",
      "        [[-0.0669,  0.1203]],\n",
      "\n",
      "        [[-0.0572,  0.1213]],\n",
      "\n",
      "        [[-0.0040,  0.0370]],\n",
      "\n",
      "        [[-0.0513,  0.1595]],\n",
      "\n",
      "        [[-0.0466,  0.1510]],\n",
      "\n",
      "        [[-0.0803,  0.1586]],\n",
      "\n",
      "        [[-0.0237,  0.0486]],\n",
      "\n",
      "        [[-0.0143,  0.0607]],\n",
      "\n",
      "        [[-0.0416,  0.0705]],\n",
      "\n",
      "        [[-0.0219,  0.0500]],\n",
      "\n",
      "        [[-0.0878,  0.1809]],\n",
      "\n",
      "        [[-0.0547,  0.0755]],\n",
      "\n",
      "        [[-0.0316,  0.0761]],\n",
      "\n",
      "        [[-0.1247,  0.1456]],\n",
      "\n",
      "        [[-0.0801,  0.1634]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7234, -0.6637]],\n",
      "\n",
      "        [[-0.7911, -0.6039]],\n",
      "\n",
      "        [[-0.7864, -0.6079]],\n",
      "\n",
      "        [[-0.7139, -0.6729]],\n",
      "\n",
      "        [[-0.8041, -0.5933]],\n",
      "\n",
      "        [[-0.7968, -0.5992]],\n",
      "\n",
      "        [[-0.8197, -0.5808]],\n",
      "\n",
      "        [[-0.7299, -0.6577]],\n",
      "\n",
      "        [[-0.7313, -0.6564]],\n",
      "\n",
      "        [[-0.7508, -0.6386]],\n",
      "\n",
      "        [[-0.7297, -0.6578]],\n",
      "\n",
      "        [[-0.8365, -0.5678]],\n",
      "\n",
      "        [[-0.7604, -0.6302]],\n",
      "\n",
      "        [[-0.7485, -0.6407]],\n",
      "\n",
      "        [[-0.8374, -0.5671]],\n",
      "\n",
      "        [[-0.8223, -0.5788]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1418,  0.2143]],\n",
      "\n",
      "        [[-0.0905,  0.0880]],\n",
      "\n",
      "        [[-0.0647,  0.1222]],\n",
      "\n",
      "        [[-0.0206,  0.0260]],\n",
      "\n",
      "        [[-0.0718,  0.0962]],\n",
      "\n",
      "        [[-0.0500,  0.1302]],\n",
      "\n",
      "        [[-0.0628,  0.1045]],\n",
      "\n",
      "        [[-0.0683,  0.0810]],\n",
      "\n",
      "        [[-0.0158,  0.1096]],\n",
      "\n",
      "        [[ 0.0045,  0.0502]],\n",
      "\n",
      "        [[-0.0282,  0.0236]],\n",
      "\n",
      "        [[-0.0431,  0.0447]],\n",
      "\n",
      "        [[-0.0437,  0.0844]],\n",
      "\n",
      "        [[-0.0598,  0.1228]],\n",
      "\n",
      "        [[-0.0026,  0.0166]],\n",
      "\n",
      "        [[-0.0395,  0.1132]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8870, -0.5309]],\n",
      "\n",
      "        [[-0.7864, -0.6079]],\n",
      "\n",
      "        [[-0.7909, -0.6041]],\n",
      "\n",
      "        [[-0.7167, -0.6701]],\n",
      "\n",
      "        [[-0.7807, -0.6126]],\n",
      "\n",
      "        [[-0.7873, -0.6071]],\n",
      "\n",
      "        [[-0.7803, -0.6130]],\n",
      "\n",
      "        [[-0.7706, -0.6213]],\n",
      "\n",
      "        [[-0.7578, -0.6324]],\n",
      "\n",
      "        [[-0.7162, -0.6706]],\n",
      "\n",
      "        [[-0.7194, -0.6675]],\n",
      "\n",
      "        [[-0.7380, -0.6502]],\n",
      "\n",
      "        [[-0.7593, -0.6311]],\n",
      "\n",
      "        [[-0.7886, -0.6060]],\n",
      "\n",
      "        [[-0.7028, -0.6836]],\n",
      "\n",
      "        [[-0.7724, -0.6197]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0271,  0.1176]],\n",
      "\n",
      "        [[ 0.0013,  0.0361]],\n",
      "\n",
      "        [[-0.0370,  0.1253]],\n",
      "\n",
      "        [[-0.0526,  0.1143]],\n",
      "\n",
      "        [[-0.0945,  0.1976]],\n",
      "\n",
      "        [[-0.1076,  0.1950]],\n",
      "\n",
      "        [[-0.0834,  0.1393]],\n",
      "\n",
      "        [[-0.1066,  0.2028]],\n",
      "\n",
      "        [[-0.0638,  0.1651]],\n",
      "\n",
      "        [[-0.0362,  0.0827]],\n",
      "\n",
      "        [[-0.0497,  0.0535]],\n",
      "\n",
      "        [[-0.1066,  0.2011]],\n",
      "\n",
      "        [[-0.0965,  0.1660]],\n",
      "\n",
      "        [[-0.0773,  0.0750]],\n",
      "\n",
      "        [[-0.0377,  0.0891]],\n",
      "\n",
      "        [[-0.0911,  0.1715]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7681, -0.6234]],\n",
      "\n",
      "        [[-0.7107, -0.6759]],\n",
      "\n",
      "        [[-0.7776, -0.6153]],\n",
      "\n",
      "        [[-0.7801, -0.6131]],\n",
      "\n",
      "        [[-0.8498, -0.5578]],\n",
      "\n",
      "        [[-0.8559, -0.5532]],\n",
      "\n",
      "        [[-0.8107, -0.5880]],\n",
      "\n",
      "        [[-0.8598, -0.5503]],\n",
      "\n",
      "        [[-0.8142, -0.5852]],\n",
      "\n",
      "        [[-0.7544, -0.6355]],\n",
      "\n",
      "        [[-0.7461, -0.6429]],\n",
      "\n",
      "        [[-0.8588, -0.5511]],\n",
      "\n",
      "        [[-0.8330, -0.5705]],\n",
      "\n",
      "        [[-0.7721, -0.6199]],\n",
      "\n",
      "        [[-0.7586, -0.6317]],\n",
      "\n",
      "        [[-0.8330, -0.5704]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[ 0.0267,  0.0629]],\n",
      "\n",
      "        [[-0.0238,  0.1118]],\n",
      "\n",
      "        [[-0.0572,  0.0718]],\n",
      "\n",
      "        [[-0.0352,  0.0698]],\n",
      "\n",
      "        [[-0.0829,  0.0882]],\n",
      "\n",
      "        [[-0.0126,  0.0631]],\n",
      "\n",
      "        [[-0.1234,  0.2402]],\n",
      "\n",
      "        [[-0.0831,  0.1508]],\n",
      "\n",
      "        [[-0.0686,  0.1246]],\n",
      "\n",
      "        [[-0.0763,  0.1408]],\n",
      "\n",
      "        [[-0.1136,  0.1178]],\n",
      "\n",
      "        [[-0.1123,  0.2018]],\n",
      "\n",
      "        [[-0.0638,  0.0988]],\n",
      "\n",
      "        [[-0.0259,  0.0916]],\n",
      "\n",
      "        [[-0.0988,  0.2009]],\n",
      "\n",
      "        [[-0.0518,  0.1089]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7114, -0.6752]],\n",
      "\n",
      "        [[-0.7632, -0.6276]],\n",
      "\n",
      "        [[-0.7597, -0.6307]],\n",
      "\n",
      "        [[-0.7471, -0.6420]],\n",
      "\n",
      "        [[-0.7823, -0.6113]],\n",
      "\n",
      "        [[-0.7317, -0.6560]],\n",
      "\n",
      "        [[-0.8914, -0.5277]],\n",
      "\n",
      "        [[-0.8169, -0.5831]],\n",
      "\n",
      "        [[-0.7944, -0.6012]],\n",
      "\n",
      "        [[-0.8076, -0.5905]],\n",
      "\n",
      "        [[-0.8155, -0.5841]],\n",
      "\n",
      "        [[-0.8624, -0.5484]],\n",
      "\n",
      "        [[-0.7778, -0.6151]],\n",
      "\n",
      "        [[-0.7536, -0.6361]],\n",
      "\n",
      "        [[-0.8542, -0.5545]],\n",
      "\n",
      "        [[-0.7767, -0.6160]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0158,  0.0438]],\n",
      "\n",
      "        [[-0.0670,  0.1225]],\n",
      "\n",
      "        [[-0.0413,  0.0263]],\n",
      "\n",
      "        [[-0.1233,  0.2223]],\n",
      "\n",
      "        [[-0.0871,  0.1280]],\n",
      "\n",
      "        [[-0.1043,  0.2335]],\n",
      "\n",
      "        [[-0.1199,  0.1929]],\n",
      "\n",
      "        [[-0.0217,  0.0547]],\n",
      "\n",
      "        [[-0.0625,  0.1388]],\n",
      "\n",
      "        [[-0.1230,  0.1618]],\n",
      "\n",
      "        [[-0.0639,  0.1000]],\n",
      "\n",
      "        [[-0.0269,  0.1674]],\n",
      "\n",
      "        [[-0.0615,  0.0893]],\n",
      "\n",
      "        [[-0.0840,  0.1112]],\n",
      "\n",
      "        [[-0.1338,  0.1776]],\n",
      "\n",
      "        [[-0.0305,  0.0733]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7234, -0.6638]],\n",
      "\n",
      "        [[-0.7924, -0.6029]],\n",
      "\n",
      "        [[-0.7275, -0.6599]],\n",
      "\n",
      "        [[-0.8808, -0.5352]],\n",
      "\n",
      "        [[-0.8065, -0.5914]],\n",
      "\n",
      "        [[-0.8762, -0.5384]],\n",
      "\n",
      "        [[-0.8617, -0.5489]],\n",
      "\n",
      "        [[-0.7321, -0.6557]],\n",
      "\n",
      "        [[-0.7988, -0.5976]],\n",
      "\n",
      "        [[-0.8456, -0.5609]],\n",
      "\n",
      "        [[-0.7785, -0.6145]],\n",
      "\n",
      "        [[-0.7950, -0.6007]],\n",
      "\n",
      "        [[-0.7714, -0.6206]],\n",
      "\n",
      "        [[-0.7955, -0.6003]],\n",
      "\n",
      "        [[-0.8609, -0.5495]],\n",
      "\n",
      "        [[-0.7464, -0.6426]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1307,  0.2234]],\n",
      "\n",
      "        [[-0.1093,  0.1630]],\n",
      "\n",
      "        [[-0.0863,  0.1149]],\n",
      "\n",
      "        [[-0.0223,  0.0632]],\n",
      "\n",
      "        [[-0.1484,  0.1804]],\n",
      "\n",
      "        [[-0.1238,  0.1669]],\n",
      "\n",
      "        [[-0.0568,  0.1420]],\n",
      "\n",
      "        [[-0.0820,  0.1998]],\n",
      "\n",
      "        [[-0.0530,  0.0728]],\n",
      "\n",
      "        [[-0.1088,  0.1969]],\n",
      "\n",
      "        [[-0.0797,  0.1756]],\n",
      "\n",
      "        [[-0.1221,  0.1903]],\n",
      "\n",
      "        [[-0.0852,  0.1304]],\n",
      "\n",
      "        [[-0.1043,  0.2074]],\n",
      "\n",
      "        [[-0.1049,  0.1706]],\n",
      "\n",
      "        [[-0.0705,  0.1183]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8858, -0.5317]],\n",
      "\n",
      "        [[-0.8385, -0.5662]],\n",
      "\n",
      "        [[-0.7988, -0.5976]],\n",
      "\n",
      "        [[-0.7368, -0.6513]],\n",
      "\n",
      "        [[-0.8710, -0.5422]],\n",
      "\n",
      "        [[-0.8490, -0.5584]],\n",
      "\n",
      "        [[-0.7975, -0.5987]],\n",
      "\n",
      "        [[-0.8439, -0.5622]],\n",
      "\n",
      "        [[-0.7580, -0.6322]],\n",
      "\n",
      "        [[-0.8576, -0.5519]],\n",
      "\n",
      "        [[-0.8289, -0.5736]],\n",
      "\n",
      "        [[-0.8615, -0.5491]],\n",
      "\n",
      "        [[-0.8068, -0.5911]],\n",
      "\n",
      "        [[-0.8611, -0.5494]],\n",
      "\n",
      "        [[-0.8404, -0.5648]],\n",
      "\n",
      "        [[-0.7920, -0.6032]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0494,  0.1185]],\n",
      "\n",
      "        [[-0.0492,  0.1019]],\n",
      "\n",
      "        [[-0.0904,  0.1828]],\n",
      "\n",
      "        [[-0.0498,  0.0610]],\n",
      "\n",
      "        [[-0.1151,  0.1942]],\n",
      "\n",
      "        [[-0.0394,  0.0417]],\n",
      "\n",
      "        [[-0.0191,  0.1197]],\n",
      "\n",
      "        [[-0.0888,  0.1070]],\n",
      "\n",
      "        [[-0.0764,  0.1407]],\n",
      "\n",
      "        [[-0.1057,  0.1960]],\n",
      "\n",
      "        [[-0.0912,  0.1435]],\n",
      "\n",
      "        [[-0.0974,  0.2021]],\n",
      "\n",
      "        [[-0.1392,  0.1677]],\n",
      "\n",
      "        [[-0.1064,  0.2204]],\n",
      "\n",
      "        [[-0.0600,  0.0945]],\n",
      "\n",
      "        [[-0.0688,  0.1915]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7806, -0.6128]],\n",
      "\n",
      "        [[-0.7715, -0.6205]],\n",
      "\n",
      "        [[-0.8390, -0.5659]],\n",
      "\n",
      "        [[-0.7501, -0.6393]],\n",
      "\n",
      "        [[-0.8597, -0.5504]],\n",
      "\n",
      "        [[-0.7345, -0.6534]],\n",
      "\n",
      "        [[-0.7650, -0.6261]],\n",
      "\n",
      "        [[-0.7958, -0.6000]],\n",
      "\n",
      "        [[-0.8075, -0.5905]],\n",
      "\n",
      "        [[-0.8553, -0.5536]],\n",
      "\n",
      "        [[-0.8173, -0.5827]],\n",
      "\n",
      "        [[-0.8540, -0.5546]],\n",
      "\n",
      "        [[-0.8583, -0.5514]],\n",
      "\n",
      "        [[-0.8698, -0.5430]],\n",
      "\n",
      "        [[-0.7733, -0.6189]],\n",
      "\n",
      "        [[-0.8318, -0.5714]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0689,  0.1144]],\n",
      "\n",
      "        [[-0.1451,  0.2129]],\n",
      "\n",
      "        [[-0.0794,  0.1204]],\n",
      "\n",
      "        [[-0.0880,  0.1967]],\n",
      "\n",
      "        [[-0.0922,  0.1263]],\n",
      "\n",
      "        [[-0.0077,  0.0644]],\n",
      "\n",
      "        [[-0.0629,  0.1379]],\n",
      "\n",
      "        [[-0.0824,  0.1194]],\n",
      "\n",
      "        [[-0.1082,  0.1583]],\n",
      "\n",
      "        [[-0.0759,  0.1703]],\n",
      "\n",
      "        [[-0.0428,  0.0857]],\n",
      "\n",
      "        [[-0.0436,  0.0608]],\n",
      "\n",
      "        [[-0.1263,  0.1898]],\n",
      "\n",
      "        [[-0.1146,  0.2046]],\n",
      "\n",
      "        [[-0.0851,  0.1057]],\n",
      "\n",
      "        [[-0.0419,  0.0778]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7890, -0.6057]],\n",
      "\n",
      "        [[-0.8881, -0.5301]],\n",
      "\n",
      "        [[-0.7980, -0.5982]],\n",
      "\n",
      "        [[-0.8456, -0.5609]],\n",
      "\n",
      "        [[-0.8083, -0.5899]],\n",
      "\n",
      "        [[-0.7298, -0.6578]],\n",
      "\n",
      "        [[-0.7986, -0.5978]],\n",
      "\n",
      "        [[-0.7991, -0.5973]],\n",
      "\n",
      "        [[-0.8353, -0.5687]],\n",
      "\n",
      "        [[-0.8238, -0.5776]],\n",
      "\n",
      "        [[-0.7594, -0.6310]],\n",
      "\n",
      "        [[-0.7467, -0.6423]],\n",
      "\n",
      "        [[-0.8637, -0.5475]],\n",
      "\n",
      "        [[-0.8654, -0.5462]],\n",
      "\n",
      "        [[-0.7931, -0.6023]],\n",
      "\n",
      "        [[-0.7548, -0.6351]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1293,  0.1656]],\n",
      "\n",
      "        [[-0.0673,  0.0578]],\n",
      "\n",
      "        [[-0.1117,  0.1879]],\n",
      "\n",
      "        [[-0.0606,  0.1747]],\n",
      "\n",
      "        [[-0.0595,  0.1535]],\n",
      "\n",
      "        [[-0.0443,  0.0509]],\n",
      "\n",
      "        [[-0.1719,  0.2381]],\n",
      "\n",
      "        [[-0.0640,  0.1232]],\n",
      "\n",
      "        [[-0.0497,  0.0296]],\n",
      "\n",
      "        [[-0.0571,  0.1118]],\n",
      "\n",
      "        [[-0.1411,  0.1931]],\n",
      "\n",
      "        [[-0.0979,  0.2132]],\n",
      "\n",
      "        [[-0.0171,  0.0352]],\n",
      "\n",
      "        [[-0.0343,  0.1091]],\n",
      "\n",
      "        [[-0.0888,  0.1507]],\n",
      "\n",
      "        [[-0.0604,  0.0935]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8515, -0.5565]],\n",
      "\n",
      "        [[-0.7576, -0.6326]],\n",
      "\n",
      "        [[-0.8541, -0.5545]],\n",
      "\n",
      "        [[-0.8177, -0.5824]],\n",
      "\n",
      "        [[-0.8053, -0.5923]],\n",
      "\n",
      "        [[-0.7419, -0.6467]],\n",
      "\n",
      "        [[-0.9191, -0.5090]],\n",
      "\n",
      "        [[-0.7911, -0.6039]],\n",
      "\n",
      "        [[-0.7336, -0.6543]],\n",
      "\n",
      "        [[-0.7811, -0.6123]],\n",
      "\n",
      "        [[-0.8741, -0.5400]],\n",
      "\n",
      "        [[-0.8607, -0.5497]],\n",
      "\n",
      "        [[-0.7196, -0.6673]],\n",
      "\n",
      "        [[-0.7674, -0.6240]],\n",
      "\n",
      "        [[-0.8201, -0.5805]],\n",
      "\n",
      "        [[-0.7730, -0.6192]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0794,  0.0960]],\n",
      "\n",
      "        [[-0.0360,  0.0670]],\n",
      "\n",
      "        [[-0.1168,  0.2328]],\n",
      "\n",
      "        [[-0.0919,  0.1094]],\n",
      "\n",
      "        [[-0.0868,  0.1388]],\n",
      "\n",
      "        [[-0.0750,  0.1364]],\n",
      "\n",
      "        [[-0.1390,  0.2342]],\n",
      "\n",
      "        [[-0.0879,  0.1245]],\n",
      "\n",
      "        [[-0.1216,  0.2421]],\n",
      "\n",
      "        [[-0.0414,  0.1209]],\n",
      "\n",
      "        [[-0.0847,  0.1717]],\n",
      "\n",
      "        [[-0.0729,  0.0921]],\n",
      "\n",
      "        [[-0.0985,  0.1397]],\n",
      "\n",
      "        [[-0.0252,  0.0579]],\n",
      "\n",
      "        [[-0.1604,  0.1822]],\n",
      "\n",
      "        [[-0.0826,  0.1263]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7847, -0.6093]],\n",
      "\n",
      "        [[-0.7460, -0.6430]],\n",
      "\n",
      "        [[-0.8831, -0.5336]],\n",
      "\n",
      "        [[-0.7989, -0.5975]],\n",
      "\n",
      "        [[-0.8123, -0.5867]],\n",
      "\n",
      "        [[-0.8044, -0.5931]],\n",
      "\n",
      "        [[-0.8970, -0.5239]],\n",
      "\n",
      "        [[-0.8050, -0.5926]],\n",
      "\n",
      "        [[-0.8915, -0.5277]],\n",
      "\n",
      "        [[-0.7776, -0.6153]],\n",
      "\n",
      "        [[-0.8295, -0.5731]],\n",
      "\n",
      "        [[-0.7791, -0.6140]],\n",
      "\n",
      "        [[-0.8193, -0.5811]],\n",
      "\n",
      "        [[-0.7355, -0.6525]],\n",
      "\n",
      "        [[-0.8791, -0.5364]],\n",
      "\n",
      "        [[-0.8030, -0.5942]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0608,  0.0644]],\n",
      "\n",
      "        [[-0.0467,  0.0947]],\n",
      "\n",
      "        [[-0.0996,  0.1636]],\n",
      "\n",
      "        [[-0.0339,  0.0683]],\n",
      "\n",
      "        [[-0.1227,  0.1840]],\n",
      "\n",
      "        [[-0.1157,  0.2342]],\n",
      "\n",
      "        [[-0.1345,  0.0781]],\n",
      "\n",
      "        [[-0.1311,  0.2344]],\n",
      "\n",
      "        [[-0.0803,  0.2054]],\n",
      "\n",
      "        [[-0.1034,  0.1796]],\n",
      "\n",
      "        [[-0.1616,  0.2494]],\n",
      "\n",
      "        [[-0.0704,  0.0738]],\n",
      "\n",
      "        [[-0.0671,  0.1013]],\n",
      "\n",
      "        [[-0.0860,  0.1010]],\n",
      "\n",
      "        [[-0.0822,  0.1278]],\n",
      "\n",
      "        [[-0.1095,  0.1738]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7577, -0.6325]],\n",
      "\n",
      "        [[-0.7663, -0.6250]],\n",
      "\n",
      "        [[-0.8334, -0.5702]],\n",
      "\n",
      "        [[-0.7455, -0.6434]],\n",
      "\n",
      "        [[-0.8582, -0.5515]],\n",
      "\n",
      "        [[-0.8833, -0.5334]],\n",
      "\n",
      "        [[-0.8051, -0.5925]],\n",
      "\n",
      "        [[-0.8925, -0.5270]],\n",
      "\n",
      "        [[-0.8462, -0.5605]],\n",
      "\n",
      "        [[-0.8446, -0.5616]],\n",
      "\n",
      "        [[-0.9196, -0.5086]],\n",
      "\n",
      "        [[-0.7679, -0.6236]],\n",
      "\n",
      "        [[-0.7809, -0.6125]],\n",
      "\n",
      "        [[-0.7910, -0.6040]],\n",
      "\n",
      "        [[-0.8036, -0.5937]],\n",
      "\n",
      "        [[-0.8448, -0.5615]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0670,  0.1438]],\n",
      "\n",
      "        [[-0.1429,  0.1851]],\n",
      "\n",
      "        [[-0.1206,  0.1964]],\n",
      "\n",
      "        [[-0.1559,  0.1997]],\n",
      "\n",
      "        [[-0.0807,  0.1069]],\n",
      "\n",
      "        [[-0.1151,  0.1212]],\n",
      "\n",
      "        [[-0.1015,  0.2203]],\n",
      "\n",
      "        [[-0.1104,  0.1405]],\n",
      "\n",
      "        [[-0.0292,  0.0458]],\n",
      "\n",
      "        [[-0.0730,  0.1232]],\n",
      "\n",
      "        [[-0.1108,  0.1431]],\n",
      "\n",
      "        [[-0.1313,  0.2370]],\n",
      "\n",
      "        [[-0.1143,  0.1140]],\n",
      "\n",
      "        [[-0.1098,  0.1149]],\n",
      "\n",
      "        [[-0.1129,  0.1820]],\n",
      "\n",
      "        [[-0.1633,  0.2491]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8041, -0.5933]],\n",
      "\n",
      "        [[-0.8705, -0.5425]],\n",
      "\n",
      "        [[-0.8641, -0.5472]],\n",
      "\n",
      "        [[-0.8867, -0.5311]],\n",
      "\n",
      "        [[-0.7913, -0.6037]],\n",
      "\n",
      "        [[-0.8183, -0.5820]],\n",
      "\n",
      "        [[-0.8669, -0.5452]],\n",
      "\n",
      "        [[-0.8264, -0.5756]],\n",
      "\n",
      "        [[-0.7314, -0.6563]],\n",
      "\n",
      "        [[-0.7961, -0.5998]],\n",
      "\n",
      "        [[-0.8282, -0.5742]],\n",
      "\n",
      "        [[-0.8941, -0.5259]],\n",
      "\n",
      "        [[-0.8138, -0.5855]],\n",
      "\n",
      "        [[-0.8118, -0.5871]],\n",
      "\n",
      "        [[-0.8515, -0.5565]],\n",
      "\n",
      "        [[-0.9204, -0.5081]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0767,  0.1287]],\n",
      "\n",
      "        [[-0.1066,  0.1853]],\n",
      "\n",
      "        [[ 0.0049,  0.0590]],\n",
      "\n",
      "        [[-0.0996,  0.1201]],\n",
      "\n",
      "        [[-0.0650,  0.1137]],\n",
      "\n",
      "        [[-0.0719,  0.1086]],\n",
      "\n",
      "        [[-0.1373,  0.2046]],\n",
      "\n",
      "        [[-0.1816,  0.2192]],\n",
      "\n",
      "        [[-0.1050,  0.2156]],\n",
      "\n",
      "        [[-0.0452,  0.0704]],\n",
      "\n",
      "        [[-0.1095,  0.1684]],\n",
      "\n",
      "        [[-0.1166,  0.2041]],\n",
      "\n",
      "        [[-0.0217,  0.0685]],\n",
      "\n",
      "        [[-0.1362,  0.2026]],\n",
      "\n",
      "        [[-0.1481,  0.1947]],\n",
      "\n",
      "        [[-0.0786,  0.1570]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8011, -0.5957]],\n",
      "\n",
      "        [[-0.8497, -0.5578]],\n",
      "\n",
      "        [[-0.7205, -0.6665]],\n",
      "\n",
      "        [[-0.8090, -0.5893]],\n",
      "\n",
      "        [[-0.7865, -0.6078]],\n",
      "\n",
      "        [[-0.7874, -0.6070]],\n",
      "\n",
      "        [[-0.8787, -0.5367]],\n",
      "\n",
      "        [[-0.9135, -0.5127]],\n",
      "\n",
      "        [[-0.8662, -0.5456]],\n",
      "\n",
      "        [[-0.7526, -0.6370]],\n",
      "\n",
      "        [[-0.8417, -0.5638]],\n",
      "\n",
      "        [[-0.8663, -0.5456]],\n",
      "\n",
      "        [[-0.7393, -0.6491]],\n",
      "\n",
      "        [[-0.8768, -0.5380]],\n",
      "\n",
      "        [[-0.8791, -0.5364]],\n",
      "\n",
      "        [[-0.8179, -0.5823]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1494,  0.2268]],\n",
      "\n",
      "        [[-0.1141,  0.1906]],\n",
      "\n",
      "        [[-0.1055,  0.1959]],\n",
      "\n",
      "        [[-0.1419,  0.2053]],\n",
      "\n",
      "        [[-0.0538,  0.1451]],\n",
      "\n",
      "        [[-0.1311,  0.2019]],\n",
      "\n",
      "        [[-0.1089,  0.1692]],\n",
      "\n",
      "        [[-0.0413,  0.1292]],\n",
      "\n",
      "        [[-0.1629,  0.2271]],\n",
      "\n",
      "        [[-0.1217,  0.1908]],\n",
      "\n",
      "        [[-0.1124,  0.1828]],\n",
      "\n",
      "        [[-0.0462,  0.0892]],\n",
      "\n",
      "        [[-0.1570,  0.2808]],\n",
      "\n",
      "        [[-0.1064,  0.2544]],\n",
      "\n",
      "        [[-0.1427,  0.1941]],\n",
      "\n",
      "        [[-0.1258,  0.1444]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8988, -0.5226]],\n",
      "\n",
      "        [[-0.8571, -0.5523]],\n",
      "\n",
      "        [[-0.8552, -0.5538]],\n",
      "\n",
      "        [[-0.8817, -0.5346]],\n",
      "\n",
      "        [[-0.7975, -0.5986]],\n",
      "\n",
      "        [[-0.8734, -0.5404]],\n",
      "\n",
      "        [[-0.8418, -0.5637]],\n",
      "\n",
      "        [[-0.7820, -0.6115]],\n",
      "\n",
      "        [[-0.9071, -0.5170]],\n",
      "\n",
      "        [[-0.8616, -0.5491]],\n",
      "\n",
      "        [[-0.8516, -0.5564]],\n",
      "\n",
      "        [[-0.7631, -0.6278]],\n",
      "\n",
      "        [[-0.9358, -0.4980]],\n",
      "\n",
      "        [[-0.8897, -0.5289]],\n",
      "\n",
      "        [[-0.8756, -0.5389]],\n",
      "\n",
      "        [[-0.8373, -0.5671]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.0912,  0.1336]],\n",
      "\n",
      "        [[-0.1590,  0.2706]],\n",
      "\n",
      "        [[-0.0717,  0.1171]],\n",
      "\n",
      "        [[-0.1262,  0.2418]],\n",
      "\n",
      "        [[-0.1297,  0.2131]],\n",
      "\n",
      "        [[-0.1479,  0.2546]],\n",
      "\n",
      "        [[-0.0922,  0.1331]],\n",
      "\n",
      "        [[-0.1124,  0.1018]],\n",
      "\n",
      "        [[-0.0728,  0.0716]],\n",
      "\n",
      "        [[-0.1200,  0.1148]],\n",
      "\n",
      "        [[-0.1154,  0.1024]],\n",
      "\n",
      "        [[-0.0710,  0.1352]],\n",
      "\n",
      "        [[-0.1035,  0.1602]],\n",
      "\n",
      "        [[-0.1533,  0.2022]],\n",
      "\n",
      "        [[-0.1109,  0.1630]],\n",
      "\n",
      "        [[-0.1207,  0.1502]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8118, -0.5871]],\n",
      "\n",
      "        [[-0.9308, -0.5012]],\n",
      "\n",
      "        [[-0.7920, -0.6032]],\n",
      "\n",
      "        [[-0.8940, -0.5260]],\n",
      "\n",
      "        [[-0.8791, -0.5364]],\n",
      "\n",
      "        [[-0.9145, -0.5120]],\n",
      "\n",
      "        [[-0.8121, -0.5868]],\n",
      "\n",
      "        [[-0.8060, -0.5918]],\n",
      "\n",
      "        [[-0.7679, -0.6236]],\n",
      "\n",
      "        [[-0.8174, -0.5826]],\n",
      "\n",
      "        [[-0.8079, -0.5902]],\n",
      "\n",
      "        [[-0.8015, -0.5954]],\n",
      "\n",
      "        [[-0.8337, -0.5700]],\n",
      "\n",
      "        [[-0.8866, -0.5311]],\n",
      "\n",
      "        [[-0.8394, -0.5656]],\n",
      "\n",
      "        [[-0.8377, -0.5669]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0854,  0.1834]],\n",
      "\n",
      "        [[-0.0253,  0.0648]],\n",
      "\n",
      "        [[-0.0431,  0.0973]],\n",
      "\n",
      "        [[-0.1050,  0.2104]],\n",
      "\n",
      "        [[-0.0372,  0.1264]],\n",
      "\n",
      "        [[-0.1220,  0.1736]],\n",
      "\n",
      "        [[-0.1538,  0.2972]],\n",
      "\n",
      "        [[-0.1121,  0.1558]],\n",
      "\n",
      "        [[-0.1251,  0.1494]],\n",
      "\n",
      "        [[-0.1528,  0.2548]],\n",
      "\n",
      "        [[-0.1159,  0.2131]],\n",
      "\n",
      "        [[-0.1073,  0.2208]],\n",
      "\n",
      "        [[-0.1720,  0.2866]],\n",
      "\n",
      "        [[-0.0719,  0.0703]],\n",
      "\n",
      "        [[-0.1030,  0.1642]],\n",
      "\n",
      "        [[-0.1757,  0.2851]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8365, -0.5678]],\n",
      "\n",
      "        [[-0.7392, -0.6491]],\n",
      "\n",
      "        [[-0.7658, -0.6254]],\n",
      "\n",
      "        [[-0.8632, -0.5478]],\n",
      "\n",
      "        [[-0.7783, -0.6147]],\n",
      "\n",
      "        [[-0.8518, -0.5562]],\n",
      "\n",
      "        [[-0.9439, -0.4929]],\n",
      "\n",
      "        [[-0.8360, -0.5682]],\n",
      "\n",
      "        [[-0.8398, -0.5653]],\n",
      "\n",
      "        [[-0.9175, -0.5100]],\n",
      "\n",
      "        [[-0.8711, -0.5421]],\n",
      "\n",
      "        [[-0.8706, -0.5425]],\n",
      "\n",
      "        [[-0.9485, -0.4899]],\n",
      "\n",
      "        [[-0.7667, -0.6246]],\n",
      "\n",
      "        [[-0.8356, -0.5684]],\n",
      "\n",
      "        [[-0.9499, -0.4890]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0619,  0.0871]],\n",
      "\n",
      "        [[-0.0772,  0.1628]],\n",
      "\n",
      "        [[-0.1740,  0.2536]],\n",
      "\n",
      "        [[-0.0761,  0.1408]],\n",
      "\n",
      "        [[-0.0825,  0.1298]],\n",
      "\n",
      "        [[-0.0776,  0.1397]],\n",
      "\n",
      "        [[-0.1123,  0.1721]],\n",
      "\n",
      "        [[-0.1375,  0.2013]],\n",
      "\n",
      "        [[-0.2039,  0.2514]],\n",
      "\n",
      "        [[-0.1443,  0.1878]],\n",
      "\n",
      "        [[-0.1621,  0.3078]],\n",
      "\n",
      "        [[-0.1248,  0.2499]],\n",
      "\n",
      "        [[-0.0471,  0.1074]],\n",
      "\n",
      "        [[-0.1816,  0.3335]],\n",
      "\n",
      "        [[-0.1705,  0.2835]],\n",
      "\n",
      "        [[-0.1541,  0.2176]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7704, -0.6214]],\n",
      "\n",
      "        [[-0.8203, -0.5804]],\n",
      "\n",
      "        [[-0.9296, -0.5020]],\n",
      "\n",
      "        [[-0.8075, -0.5905]],\n",
      "\n",
      "        [[-0.8049, -0.5926]],\n",
      "\n",
      "        [[-0.8077, -0.5904]],\n",
      "\n",
      "        [[-0.8455, -0.5610]],\n",
      "\n",
      "        [[-0.8768, -0.5380]],\n",
      "\n",
      "        [[-0.9465, -0.4912]],\n",
      "\n",
      "        [[-0.8729, -0.5408]],\n",
      "\n",
      "        [[-0.9554, -0.4856]],\n",
      "\n",
      "        [[-0.8980, -0.5232]],\n",
      "\n",
      "        [[-0.7734, -0.6189]],\n",
      "\n",
      "        [[-0.9835, -0.4684]],\n",
      "\n",
      "        [[-0.9457, -0.4917]],\n",
      "\n",
      "        [[-0.8962, -0.5245]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0872,  0.1458]],\n",
      "\n",
      "        [[-0.0988,  0.1212]],\n",
      "\n",
      "        [[-0.1380,  0.2044]],\n",
      "\n",
      "        [[-0.1379,  0.2403]],\n",
      "\n",
      "        [[-0.1713,  0.2651]],\n",
      "\n",
      "        [[-0.0714,  0.0853]],\n",
      "\n",
      "        [[-0.1962,  0.3050]],\n",
      "\n",
      "        [[-0.0862,  0.1593]],\n",
      "\n",
      "        [[-0.1378,  0.2608]],\n",
      "\n",
      "        [[-0.1642,  0.2188]],\n",
      "\n",
      "        [[-0.1008,  0.2143]],\n",
      "\n",
      "        [[-0.1739,  0.2707]],\n",
      "\n",
      "        [[-0.1444,  0.3055]],\n",
      "\n",
      "        [[-0.1986,  0.2964]],\n",
      "\n",
      "        [[-0.0807,  0.1584]],\n",
      "\n",
      "        [[-0.1533,  0.2438]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8164, -0.5834]],\n",
      "\n",
      "        [[-0.8092, -0.5892]],\n",
      "\n",
      "        [[-0.8789, -0.5365]],\n",
      "\n",
      "        [[-0.9000, -0.5218]],\n",
      "\n",
      "        [[-0.9349, -0.4986]],\n",
      "\n",
      "        [[-0.7746, -0.6178]],\n",
      "\n",
      "        [[-0.9748, -0.4736]],\n",
      "\n",
      "        [[-0.8234, -0.5779]],\n",
      "\n",
      "        [[-0.9122, -0.5136]],\n",
      "\n",
      "        [[-0.9029, -0.5198]],\n",
      "\n",
      "        [[-0.8631, -0.5479]],\n",
      "\n",
      "        [[-0.9400, -0.4953]],\n",
      "\n",
      "        [[-0.9432, -0.4933]],\n",
      "\n",
      "        [[-0.9710, -0.4760]],\n",
      "\n",
      "        [[-0.8198, -0.5807]],\n",
      "\n",
      "        [[-0.9113, -0.5142]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1355,  0.1383]],\n",
      "\n",
      "        [[-0.1166,  0.1397]],\n",
      "\n",
      "        [[-0.1035,  0.1950]],\n",
      "\n",
      "        [[-0.1141,  0.2099]],\n",
      "\n",
      "        [[-0.1966,  0.2791]],\n",
      "\n",
      "        [[-0.1974,  0.2879]],\n",
      "\n",
      "        [[-0.0900,  0.0957]],\n",
      "\n",
      "        [[-0.1158,  0.2062]],\n",
      "\n",
      "        [[-0.0751,  0.1870]],\n",
      "\n",
      "        [[-0.1196,  0.1567]],\n",
      "\n",
      "        [[-0.1299,  0.1501]],\n",
      "\n",
      "        [[-0.1099,  0.2270]],\n",
      "\n",
      "        [[-0.1129,  0.1360]],\n",
      "\n",
      "        [[-0.0573,  0.1425]],\n",
      "\n",
      "        [[-0.1050,  0.1486]],\n",
      "\n",
      "        [[-0.1110,  0.1048]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8394, -0.5656]],\n",
      "\n",
      "        [[-0.8295, -0.5732]],\n",
      "\n",
      "        [[-0.8535, -0.5550]],\n",
      "\n",
      "        [[-0.8682, -0.5442]],\n",
      "\n",
      "        [[-0.9590, -0.4833]],\n",
      "\n",
      "        [[-0.9649, -0.4797]],\n",
      "\n",
      "        [[-0.7903, -0.6046]],\n",
      "\n",
      "        [[-0.8670, -0.5451]],\n",
      "\n",
      "        [[-0.8327, -0.5707]],\n",
      "\n",
      "        [[-0.8408, -0.5645]],\n",
      "\n",
      "        [[-0.8429, -0.5629]],\n",
      "\n",
      "        [[-0.8758, -0.5388]],\n",
      "\n",
      "        [[-0.8253, -0.5764]],\n",
      "\n",
      "        [[-0.7980, -0.5982]],\n",
      "\n",
      "        [[-0.8279, -0.5744]],\n",
      "\n",
      "        [[-0.8068, -0.5911]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0450,  0.1251]],\n",
      "\n",
      "        [[-0.1535,  0.2827]],\n",
      "\n",
      "        [[-0.1713,  0.2726]],\n",
      "\n",
      "        [[-0.0985,  0.2125]],\n",
      "\n",
      "        [[-0.0452,  0.1084]],\n",
      "\n",
      "        [[-0.1741,  0.2469]],\n",
      "\n",
      "        [[-0.2308,  0.3191]],\n",
      "\n",
      "        [[-0.1319,  0.2021]],\n",
      "\n",
      "        [[-0.1111,  0.1630]],\n",
      "\n",
      "        [[-0.1259,  0.2169]],\n",
      "\n",
      "        [[-0.1859,  0.3349]],\n",
      "\n",
      "        [[-0.2214,  0.3310]],\n",
      "\n",
      "        [[-0.0794,  0.1313]],\n",
      "\n",
      "        [[-0.0939,  0.1658]],\n",
      "\n",
      "        [[-0.1046,  0.1513]],\n",
      "\n",
      "        [[-0.0723,  0.0868]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7818, -0.6117]],\n",
      "\n",
      "        [[-0.9349, -0.4986]],\n",
      "\n",
      "        [[-0.9395, -0.4956]],\n",
      "\n",
      "        [[-0.8607, -0.5497]],\n",
      "\n",
      "        [[-0.7729, -0.6193]],\n",
      "\n",
      "        [[-0.9256, -0.5046]],\n",
      "\n",
      "        [[-1.0054, -0.4556]],\n",
      "\n",
      "        [[-0.8740, -0.5400]],\n",
      "\n",
      "        [[-0.8396, -0.5654]],\n",
      "\n",
      "        [[-0.8792, -0.5364]],\n",
      "\n",
      "        [[-0.9870, -0.4663]],\n",
      "\n",
      "        [[-1.0070, -0.4546]],\n",
      "\n",
      "        [[-0.8040, -0.5933]],\n",
      "\n",
      "        [[-0.8314, -0.5717]],\n",
      "\n",
      "        [[-0.8293, -0.5734]],\n",
      "\n",
      "        [[-0.7759, -0.6168]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.2017,  0.2754]],\n",
      "\n",
      "        [[-0.1018,  0.1511]],\n",
      "\n",
      "        [[-0.1528,  0.2462]],\n",
      "\n",
      "        [[-0.1045,  0.1296]],\n",
      "\n",
      "        [[-0.0931,  0.1325]],\n",
      "\n",
      "        [[-0.0577,  0.0928]],\n",
      "\n",
      "        [[-0.1202,  0.1797]],\n",
      "\n",
      "        [[-0.0873,  0.0607]],\n",
      "\n",
      "        [[-0.1425,  0.2514]],\n",
      "\n",
      "        [[-0.1710,  0.2136]],\n",
      "\n",
      "        [[-0.0843,  0.1439]],\n",
      "\n",
      "        [[-0.0688,  0.0850]],\n",
      "\n",
      "        [[-0.1652,  0.2759]],\n",
      "\n",
      "        [[-0.1865,  0.1826]],\n",
      "\n",
      "        [[-0.1592,  0.2312]],\n",
      "\n",
      "        [[-0.1140,  0.1842]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.9599, -0.4828]],\n",
      "\n",
      "        [[-0.8276, -0.5747]],\n",
      "\n",
      "        [[-0.9124, -0.5134]],\n",
      "\n",
      "        [[-0.8170, -0.5829]],\n",
      "\n",
      "        [[-0.8123, -0.5867]],\n",
      "\n",
      "        [[-0.7712, -0.6207]],\n",
      "\n",
      "        [[-0.8543, -0.5544]],\n",
      "\n",
      "        [[-0.7699, -0.6219]],\n",
      "\n",
      "        [[-0.9094, -0.5155]],\n",
      "\n",
      "        [[-0.9038, -0.5192]],\n",
      "\n",
      "        [[-0.8137, -0.5856]],\n",
      "\n",
      "        [[-0.7730, -0.6192]],\n",
      "\n",
      "        [[-0.9378, -0.4967]],\n",
      "\n",
      "        [[-0.8946, -0.5255]],\n",
      "\n",
      "        [[-0.9073, -0.5169]],\n",
      "\n",
      "        [[-0.8533, -0.5551]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0880,  0.1879]],\n",
      "\n",
      "        [[-0.0603,  0.1092]],\n",
      "\n",
      "        [[-0.1396,  0.1645]],\n",
      "\n",
      "        [[-0.1018,  0.1980]],\n",
      "\n",
      "        [[-0.1849,  0.2018]],\n",
      "\n",
      "        [[-0.1275,  0.1492]],\n",
      "\n",
      "        [[-0.0935,  0.1457]],\n",
      "\n",
      "        [[-0.1684,  0.2250]],\n",
      "\n",
      "        [[-0.1722,  0.3251]],\n",
      "\n",
      "        [[-0.1040,  0.1300]],\n",
      "\n",
      "        [[-0.0673,  0.1403]],\n",
      "\n",
      "        [[-0.0950,  0.1632]],\n",
      "\n",
      "        [[-0.1991,  0.2609]],\n",
      "\n",
      "        [[-0.1500,  0.2355]],\n",
      "\n",
      "        [[-0.1747,  0.2360]],\n",
      "\n",
      "        [[-0.1498,  0.2007]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8405, -0.5647]],\n",
      "\n",
      "        [[-0.7815, -0.6120]],\n",
      "\n",
      "        [[-0.8567, -0.5526]],\n",
      "\n",
      "        [[-0.8543, -0.5544]],\n",
      "\n",
      "        [[-0.9051, -0.5184]],\n",
      "\n",
      "        [[-0.8410, -0.5644]],\n",
      "\n",
      "        [[-0.8199, -0.5807]],\n",
      "\n",
      "        [[-0.9091, -0.5157]],\n",
      "\n",
      "        [[-0.9724, -0.4751]],\n",
      "\n",
      "        [[-0.8170, -0.5830]],\n",
      "\n",
      "        [[-0.8023, -0.5947]],\n",
      "\n",
      "        [[-0.8306, -0.5723]],\n",
      "\n",
      "        [[-0.9494, -0.4893]],\n",
      "\n",
      "        [[-0.9043, -0.5189]],\n",
      "\n",
      "        [[-0.9194, -0.5088]],\n",
      "\n",
      "        [[-0.8837, -0.5332]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.1118,  0.1686]],\n",
      "\n",
      "        [[-0.1692,  0.2808]],\n",
      "\n",
      "        [[-0.1634,  0.2442]],\n",
      "\n",
      "        [[-0.1066,  0.1394]],\n",
      "\n",
      "        [[-0.1259,  0.2289]],\n",
      "\n",
      "        [[-0.1453,  0.3047]],\n",
      "\n",
      "        [[-0.0879,  0.1449]],\n",
      "\n",
      "        [[-0.1797,  0.2665]],\n",
      "\n",
      "        [[-0.1215,  0.0982]],\n",
      "\n",
      "        [[-0.1069,  0.1351]],\n",
      "\n",
      "        [[-0.0330,  0.0998]],\n",
      "\n",
      "        [[-0.1585,  0.2044]],\n",
      "\n",
      "        [[-0.1300,  0.2296]],\n",
      "\n",
      "        [[-0.1194,  0.2333]],\n",
      "\n",
      "        [[-0.1351,  0.1627]],\n",
      "\n",
      "        [[-0.2262,  0.3147]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8432, -0.5627]],\n",
      "\n",
      "        [[-0.9433, -0.4932]],\n",
      "\n",
      "        [[-0.9176, -0.5099]],\n",
      "\n",
      "        [[-0.8237, -0.5777]],\n",
      "\n",
      "        [[-0.8862, -0.5314]],\n",
      "\n",
      "        [[-0.9432, -0.4933]],\n",
      "\n",
      "        [[-0.8163, -0.5835]],\n",
      "\n",
      "        [[-0.9409, -0.4947]],\n",
      "\n",
      "        [[-0.8090, -0.5893]],\n",
      "\n",
      "        [[-0.8214, -0.5795]],\n",
      "\n",
      "        [[-0.7618, -0.6289]],\n",
      "\n",
      "        [[-0.8909, -0.5281]],\n",
      "\n",
      "        [[-0.8890, -0.5294]],\n",
      "\n",
      "        [[-0.8850, -0.5322]],\n",
      "\n",
      "        [[-0.8531, -0.5553]],\n",
      "\n",
      "        [[-0.9997, -0.4588]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0491,  0.0261]],\n",
      "\n",
      "        [[-0.1141,  0.2010]],\n",
      "\n",
      "        [[-0.0806,  0.1184]],\n",
      "\n",
      "        [[-0.0986,  0.1799]],\n",
      "\n",
      "        [[-0.1888,  0.1964]],\n",
      "\n",
      "        [[-0.0593,  0.1693]],\n",
      "\n",
      "        [[-0.0916,  0.1082]],\n",
      "\n",
      "        [[-0.0412,  0.0550]],\n",
      "\n",
      "        [[-0.1686,  0.2418]],\n",
      "\n",
      "        [[-0.2115,  0.3052]],\n",
      "\n",
      "        [[-0.1194,  0.1899]],\n",
      "\n",
      "        [[-0.1722,  0.2641]],\n",
      "\n",
      "        [[-0.1697,  0.2823]],\n",
      "\n",
      "        [[-0.0928,  0.1452]],\n",
      "\n",
      "        [[-0.2071,  0.2738]],\n",
      "\n",
      "        [[-0.0698,  0.0677]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7314, -0.6563]],\n",
      "\n",
      "        [[-0.8630, -0.5480]],\n",
      "\n",
      "        [[-0.7976, -0.5986]],\n",
      "\n",
      "        [[-0.8420, -0.5636]],\n",
      "\n",
      "        [[-0.9042, -0.5190]],\n",
      "\n",
      "        [[-0.8140, -0.5854]],\n",
      "\n",
      "        [[-0.7980, -0.5983]],\n",
      "\n",
      "        [[-0.7424, -0.6462]],\n",
      "\n",
      "        [[-0.9193, -0.5088]],\n",
      "\n",
      "        [[-0.9845, -0.4678]],\n",
      "\n",
      "        [[-0.8597, -0.5504]],\n",
      "\n",
      "        [[-0.9349, -0.4986]],\n",
      "\n",
      "        [[-0.9445, -0.4925]],\n",
      "\n",
      "        [[-0.8192, -0.5812]],\n",
      "\n",
      "        [[-0.9623, -0.4813]],\n",
      "\n",
      "        [[-0.7643, -0.6268]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1640,  0.2163]],\n",
      "\n",
      "        [[-0.0723,  0.0979]],\n",
      "\n",
      "        [[-0.1089,  0.2147]],\n",
      "\n",
      "        [[-0.0966,  0.1266]],\n",
      "\n",
      "        [[-0.0820,  0.1063]],\n",
      "\n",
      "        [[-0.1416,  0.1557]],\n",
      "\n",
      "        [[-0.1857,  0.2741]],\n",
      "\n",
      "        [[-0.1042,  0.1005]],\n",
      "\n",
      "        [[-0.0668,  0.1296]],\n",
      "\n",
      "        [[-0.1000,  0.1310]],\n",
      "\n",
      "        [[-0.1391,  0.1587]],\n",
      "\n",
      "        [[-0.0583,  0.0610]],\n",
      "\n",
      "        [[-0.0735,  0.1165]],\n",
      "\n",
      "        [[-0.1380,  0.1477]],\n",
      "\n",
      "        [[-0.1236,  0.1989]],\n",
      "\n",
      "        [[-0.0526,  0.1581]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.9013, -0.5209]],\n",
      "\n",
      "        [[-0.7819, -0.6117]],\n",
      "\n",
      "        [[-0.8680, -0.5444]],\n",
      "\n",
      "        [[-0.8109, -0.5878]],\n",
      "\n",
      "        [[-0.7917, -0.6034]],\n",
      "\n",
      "        [[-0.8528, -0.5555]],\n",
      "\n",
      "        [[-0.9492, -0.4895]],\n",
      "\n",
      "        [[-0.8007, -0.5960]],\n",
      "\n",
      "        [[-0.7962, -0.5998]],\n",
      "\n",
      "        [[-0.8153, -0.5843]],\n",
      "\n",
      "        [[-0.8531, -0.5553]],\n",
      "\n",
      "        [[-0.7545, -0.6353]],\n",
      "\n",
      "        [[-0.7927, -0.6026]],\n",
      "\n",
      "        [[-0.8462, -0.5605]],\n",
      "\n",
      "        [[-0.8673, -0.5448]],\n",
      "\n",
      "        [[-0.8040, -0.5933]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0739,  0.1030]],\n",
      "\n",
      "        [[-0.0840,  0.1266]],\n",
      "\n",
      "        [[-0.1470,  0.1590]],\n",
      "\n",
      "        [[-0.0968,  0.2126]],\n",
      "\n",
      "        [[-0.2030,  0.2769]],\n",
      "\n",
      "        [[-0.0471,  0.0907]],\n",
      "\n",
      "        [[-0.0873,  0.1196]],\n",
      "\n",
      "        [[-0.0623,  0.1016]],\n",
      "\n",
      "        [[-0.1726,  0.2088]],\n",
      "\n",
      "        [[-0.1329,  0.1842]],\n",
      "\n",
      "        [[-0.1090,  0.1876]],\n",
      "\n",
      "        [[-0.0922,  0.1215]],\n",
      "\n",
      "        [[-0.0931,  0.1640]],\n",
      "\n",
      "        [[-0.1807,  0.2148]],\n",
      "\n",
      "        [[-0.1195,  0.1289]],\n",
      "\n",
      "        [[-0.1048,  0.1045]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7855, -0.6086]],\n",
      "\n",
      "        [[-0.8040, -0.5934]],\n",
      "\n",
      "        [[-0.8578, -0.5518]],\n",
      "\n",
      "        [[-0.8598, -0.5503]],\n",
      "\n",
      "        [[-0.9616, -0.4817]],\n",
      "\n",
      "        [[-0.7645, -0.6266]],\n",
      "\n",
      "        [[-0.8019, -0.5950]],\n",
      "\n",
      "        [[-0.7784, -0.6146]],\n",
      "\n",
      "        [[-0.9019, -0.5205]],\n",
      "\n",
      "        [[-0.8643, -0.5471]],\n",
      "\n",
      "        [[-0.8524, -0.5558]],\n",
      "\n",
      "        [[-0.8057, -0.5920]],\n",
      "\n",
      "        [[-0.8299, -0.5728]],\n",
      "\n",
      "        [[-0.9103, -0.5148]],\n",
      "\n",
      "        [[-0.8251, -0.5766]],\n",
      "\n",
      "        [[-0.8033, -0.5939]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.1460,  0.1987]],\n",
      "\n",
      "        [[-0.0917,  0.1145]],\n",
      "\n",
      "        [[-0.1507,  0.1878]],\n",
      "\n",
      "        [[-0.0336,  0.1321]],\n",
      "\n",
      "        [[-0.1519,  0.1875]],\n",
      "\n",
      "        [[-0.0916,  0.1382]],\n",
      "\n",
      "        [[-0.0596,  0.0367]],\n",
      "\n",
      "        [[-0.0314,  0.0081]],\n",
      "\n",
      "        [[-0.0992,  0.0964]],\n",
      "\n",
      "        [[-0.0625,  0.0709]],\n",
      "\n",
      "        [[-0.0925,  0.1319]],\n",
      "\n",
      "        [[-0.0541,  0.1410]],\n",
      "\n",
      "        [[-0.0687,  0.0801]],\n",
      "\n",
      "        [[-0.0942,  0.1426]],\n",
      "\n",
      "        [[-0.0882,  0.1448]],\n",
      "\n",
      "        [[-0.1149,  0.1106]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.8803, -0.5356]],\n",
      "\n",
      "        [[-0.8016, -0.5953]],\n",
      "\n",
      "        [[-0.8767, -0.5381]],\n",
      "\n",
      "        [[-0.7794, -0.6137]],\n",
      "\n",
      "        [[-0.8771, -0.5378]],\n",
      "\n",
      "        [[-0.8146, -0.5848]],\n",
      "\n",
      "        [[-0.7425, -0.6462]],\n",
      "\n",
      "        [[-0.7131, -0.6736]],\n",
      "\n",
      "        [[-0.7957, -0.6001]],\n",
      "\n",
      "        [[-0.7621, -0.6287]],\n",
      "\n",
      "        [[-0.8117, -0.5872]],\n",
      "\n",
      "        [[-0.7954, -0.6004]],\n",
      "\n",
      "        [[-0.7703, -0.6215]],\n",
      "\n",
      "        [[-0.8186, -0.5817]],\n",
      "\n",
      "        [[-0.8164, -0.5834]],\n",
      "\n",
      "        [[-0.8122, -0.5868]]], grad_fn=<LogSoftmaxBackward0>)\n",
      "tensor([[[-0.0688,  0.0906]],\n",
      "\n",
      "        [[-0.0669,  0.1566]],\n",
      "\n",
      "        [[-0.0889,  0.1052]],\n",
      "\n",
      "        [[-0.0964,  0.1393]],\n",
      "\n",
      "        [[-0.1056,  0.0858]],\n",
      "\n",
      "        [[-0.0675,  0.1013]],\n",
      "\n",
      "        [[-0.0779,  0.1493]],\n",
      "\n",
      "        [[-0.1635,  0.2136]],\n",
      "\n",
      "        [[-0.0974,  0.1812]],\n",
      "\n",
      "        [[-0.0806,  0.2015]],\n",
      "\n",
      "        [[-0.1637,  0.2464]],\n",
      "\n",
      "        [[-0.1546,  0.2473]],\n",
      "\n",
      "        [[-0.2032,  0.2757]],\n",
      "\n",
      "        [[-0.1551,  0.2264]],\n",
      "\n",
      "        [[-0.0975,  0.2193]],\n",
      "\n",
      "        [[-0.0425,  0.0930]]], grad_fn=<ViewBackward0>)\n",
      "tensor([[[-0.7760, -0.6166]],\n",
      "\n",
      "        [[-0.8112, -0.5876]],\n",
      "\n",
      "        [[-0.7949, -0.6008]],\n",
      "\n",
      "        [[-0.8179, -0.5822]],\n",
      "\n",
      "        [[-0.7934, -0.6020]],\n",
      "\n",
      "        [[-0.7811, -0.6123]],\n",
      "\n",
      "        [[-0.8132, -0.5860]],\n",
      "\n",
      "        [[-0.8994, -0.5223]],\n",
      "\n",
      "        [[-0.8422, -0.5635]],\n",
      "\n",
      "        [[-0.8441, -0.5620]],\n",
      "\n",
      "        [[-0.9191, -0.5090]],\n",
      "\n",
      "        [[-0.9141, -0.5123]],\n",
      "\n",
      "        [[-0.9610, -0.4821]],\n",
      "\n",
      "        [[-0.9020, -0.5205]],\n",
      "\n",
      "        [[-0.8640, -0.5472]],\n",
      "\n",
      "        [[-0.7632, -0.6277]]], grad_fn=<LogSoftmaxBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [32], line 13\u001b[0m\n\u001b[1;32m      3\u001b[0m model \u001b[38;5;241m=\u001b[39m IronyDetector(        \n\u001b[1;32m      4\u001b[0m         input_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m50\u001b[39m,\n\u001b[1;32m      5\u001b[0m         hidden_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m25\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      8\u001b[0m         output_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mtraining_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencode_tokenized_batch_train_sentences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mtrain_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencode_tokenized_batch_train_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdev_features\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencode_tokenized_batch_dev_sentences\u001b[49m\u001b[43m \u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     17\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mdev_labels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mencode_tokenized_batch_dev_labels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[43m                      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn [31], line 29\u001b[0m, in \u001b[0;36mtraining_loop\u001b[0;34m(num_epochs, train_features, train_labels, dev_features, dev_labels, optimizer, model)\u001b[0m\n\u001b[1;32m     27\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(preds, labels)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Backpropogate the loss through our model\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     31\u001b[0m losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/_tensor.py:396\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    389\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    390\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    394\u001b[0m         create_graph\u001b[38;5;241m=\u001b[39mcreate_graph,\n\u001b[1;32m    395\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs)\n\u001b[0;32m--> 396\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/torch/autograd/__init__.py:173\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    168\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    170\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    172\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 173\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# TODO: Load the model and run the training loop \n",
    "#       on your train/dev splits. Set and tweak hyperparameters.\n",
    "model = IronyDetector(        \n",
    "        input_dim=50,\n",
    "        hidden_dim=25,\n",
    "        embeddings_tensor=embeddings,\n",
    "        pad_idx=word2i['<PAD>'],\n",
    "        output_size=2\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "model = training_loop(num_epochs = 10,\n",
    "                      train_features = encode_tokenized_batch_train_sentences,\n",
    "                      train_labels = encode_tokenized_batch_train_labels,\n",
    "                      dev_features = encode_tokenized_batch_dev_sentences ,\n",
    "                      dev_labels = encode_tokenized_batch_dev_labels,\n",
    "                      optimizer = optimizer,\n",
    "                      model = model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written Assignment (30 Points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Describe what the task is, and how it could be useful."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. implement average f1 score, it can minimize the biase for using f1-score only, espcially for imbalanced dataset\n",
    "2. Create a Tokenizer with Padding, tokenizing and padding batches of inputs sentences, pad make every list of tokens is the same length, make model easier.  \n",
    "3. Extracting word vectors from GloVe, we load the created vocabulary, and get embeddings from the existing 1.2 million words from GloVe file, so we have generated our embeddings based on our own vocabulary. \n",
    "4. Update the embeddings with oov words, xavier initialization for the embedidings of words in train, and add the oov words to the dict, assigning a new index to each. So we have a dictionary for word to index and a torch tensor containing the embeddings.  \n",
    "5. Make_batches, we batch train/dev set and labels along with tokenizer and encode methods. So the model can directly use these inputs \n",
    "6. Get the predictions for the dev_sequences using the model, we use torch argmax to get prediction result because the model forward method return a softmax result so we need torch argmax to determine index 0 or 1 for the result. \n",
    "7. Load the model and run the training loop on your train/dev splits. Set and tweak hyperparameters. Set epochs as 10 for feasible time, the parameter we can change is learning rate and batch size, please see question 5 for result table. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Describe, at the high level, that is, without mathematical rigor, how pretrained word embeddings like the ones we relied on here are computed. Your description can discuss the Word2Vec class of algorithms, GloVe, or a similar method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Vec is a simple neural network with a single hidden layer, and like all neural networks, it has weights, and during training, its goal is to adjust those weights to reduce a loss function. It takes as its input a large corpus of words and produces a vector space, typically of several hundred dimensions, with each unique word in the corpus being assigned a corresponding vector in the space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. What are some of the benefits of using word embeddings instead of e.g. a bag of words?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. They retain semantic similarity\n",
    "2. They have dense vectors\n",
    "3. They have a constant vector size\n",
    "4. Their Vector representations are absolute\n",
    "5. They have multiple embedding models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. What is the difference between Binary Cross Entropy loss and the negative log likelihood loss we used here (`torch.nn.NLLLoss`)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cross_entropy combines nn.LogSoftmax() and nn.NLLLoss() in one single class. If we use NLLLoss we need to use softmax manually to transform the output.  \n",
    "\n",
    "Use NLLLoss if two-dimensional input encodes log-likelihood, it essentially performs the masking step followed by mean reduction. Use CrossEntropyLoss if two-dimensional input encodes raw prediction values that need to be activated using the softmax function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Show your experimental results. Indicate any changes to hyperparameters, data splits, or architectural changes you made, and how those effected results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| --- | loss |  Dev F1 | Avf Dev F1 |  \n",
    "|-----------|----------- |----------- |----------- |  \n",
    "| lr = 0.01 & batch = 8  | 0.5908 |0.5997 | 0.6355 |  \n",
    "| lr = 0.01 & batch = 16 | 0.5690 | 0.5749 |   0.6381 |  \n",
    "| lr = 0.01 & batch = 4 | 0.6312 | 0.5594 |   0.6532 |  \n",
    "| lr = 0.001 & batch = 8  | 0.5723 |0.5932 | 0.6291 |  \n",
    "| lr = 0.001 & batch = 16 | 0.5833 | **0.6779** |  **0.7252**  |  \n",
    "| lr = 0.001 & batch = 4 | **0.5553** | 0.6177 |   0.6721 |  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
